CROSS VALÄ°DATÄ°ON NEDÄ°R ?
-- Cross-validation (Ã§apraz doÄŸrulama), makine Ã¶ÄŸrenmesi modellerinin genelleme performansÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±lan bir tekniktir. Modelin belirli bir veri kÃ¼mesi Ã¼zerinde aÅŸÄ±rÄ± Ã¶ÄŸrenmesini (overfitting) veya eksik Ã¶ÄŸrenmesini (underfitting) engellemek iÃ§in veriyi farklÄ± bÃ¶lmelere ayÄ±rarak test eder.

Neden KullanÄ±lÄ±r?
âœ… Modelin farklÄ± veri bÃ¶lÃ¼mlerinde nasÄ±l performans gÃ¶sterdiÄŸini Ã¶lÃ§er.
âœ… AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi (overfitting) tespit etmeye yardÄ±mcÄ± olur.
âœ… Model seÃ§imi ve hiperparametre ayarÄ± iÃ§in gÃ¼venilir bir deÄŸerlendirme saÄŸlar.
----------------------------------------------------------------------------------------------------
			---- Kodlarla daya iyi anlayalÄ±m ----

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error
import numpy as np

# 1. Veri setini eÄŸitim ve test kÃ¼melerine ayÄ±rma
# %70 eÄŸitim, %30 test olacak ÅŸekilde bÃ¶lme iÅŸlemi gerÃ§ekleÅŸtirilir.
X_train, x_tv, y_train, y_tv = train_test_split(x, y, test_size=0.3, random_state=9)

# Test kÃ¼mesinin %50'sini modelin deÄŸerlendirme (validation) aÅŸamasÄ± iÃ§in ayÄ±rÄ±yoruz.
# Geri kalan %50'si ise modelin son test aÅŸamasÄ±nda kullanÄ±lacaktÄ±r.
x_eval, x_test, y_eval, y_test = train_test_split(x_tv, y_tv, test_size=0.5, random_state=9)

# Veri kÃ¼mesi boyutlarÄ±nÄ± kontrol etme
print("EÄŸitim kÃ¼mesi boyutu:", X_train.shape)
print("DeÄŸerlendirme kÃ¼mesi boyutu:", x_eval.shape)
print("Test kÃ¼mesi boyutu:", x_test.shape)

# 2. Veriyi Ã¶lÃ§eklendirme
# Modelin daha saÄŸlÄ±klÄ± Ã¶ÄŸrenmesi iÃ§in verileri standart Ã¶lÃ§eklendirme iÅŸlemine tabi tutuyoruz.
scaler = StandardScaler()
scaler.fit(X_train)  # Ã–lÃ§eklendirmeyi eÄŸitim verisi Ã¼zerinden hesaplÄ±yoruz.
X_train = scaler.transform(X_train)
x_eval = scaler.transform(x_eval)
x_test = scaler.transform(x_test)

# 3. Modelin oluÅŸturulmasÄ± ve eÄŸitilmesi
# Ridge regresyon modeli belirlenen alfa (regularization) parametresi ile oluÅŸturuluyor.
model = Ridge(alpha=103)
model.fit(X_train, y_train)  # Model eÄŸitim verisi ile eÄŸitiliyor.

# 4. Modelin deÄŸerlendirme kÃ¼mesi Ã¼zerinde test edilmesi
# Modelin x_eval Ã¼zerinde yaptÄ±ÄŸÄ± tahminler hesaplanÄ±r.
y_eval_pred = model.predict(x_eval)

# KÃ¶k Ortalama Kare HatasÄ± (RMSE) hesaplanarak modelin deÄŸerlendirme performansÄ± Ã¶lÃ§Ã¼lÃ¼r.
rmse_eval = np.sqrt(mean_squared_error(y_eval, y_eval_pred))
print("DeÄŸerlendirme RMSE:", rmse_eval)

# 5. Modelin test kÃ¼mesi Ã¼zerinde test edilmesi
# Model x_test verisi ile tahmin yaparak son performansÄ± Ã¶lÃ§Ã¼lÃ¼r.
y_final = model.predict(x_test)

# Test kÃ¼mesi iÃ§in RMSE hesaplanarak modelin genel baÅŸarÄ±sÄ± deÄŸerlendirilir.
rmse_test = np.sqrt(mean_squared_error(y_test, y_final))
print("Test RMSE:", rmse_test)

				      ğŸ“Œ Kodun AmacÄ±:

Bu kod, bir makine Ã¶ÄŸrenmesi modelinin performansÄ±nÄ± deÄŸerlendirmek iÃ§in standart bir iÅŸlem sÄ±rasÄ±nÄ± takip etmektedir:

1-) Veri kÃ¼mesini eÄŸitim, deÄŸerlendirme ve test kÃ¼melerine ayÄ±rma
2-) Veriyi Ã¶lÃ§eklendirme
3-) Ridge regresyon modelini eÄŸitme
4-) DeÄŸerlendirme (validation) kÃ¼mesi ile ara test yapma
5-) Son olarak test kÃ¼mesi ile genel model baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§me
----------------------------------------------------------------------------------------------------

		---- Standart Scaler kullanÄ±mÄ± zorunlu mudur ?  ---

ğŸ“Œ 1. Neden StandardScaler KullandÄ±k?
1ï¸âƒ£ Ridge Regression, aÄŸÄ±rlÄ±k katsayÄ±larÄ±nÄ± kÃ¼Ã§Ã¼ltmeye Ã§alÄ±ÅŸÄ±r.

Ridge regresyonunun amacÄ±, bÃ¼yÃ¼k aÄŸÄ±rlÄ±klarÄ± cezalandÄ±rarak aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi (overfitting) Ã¶nlemektir.
EÄŸer verinin Ã¶lÃ§ekleri farklÄ±ysa, bÃ¼yÃ¼k deÄŸerlere sahip Ã¶zellikler daha bÃ¼yÃ¼k aÄŸÄ±rlÄ±k katsayÄ±larÄ±na sahip olabilir ve model bunlarÄ± Ã¶ncelikli olarak Ã¶ÄŸrenebilir.
StandardScaler kullanarak tÃ¼m Ã¶zellikleri aynÄ± Ã¶lÃ§eÄŸe getirdiÄŸimizde, Ridge regresyonu her Ã¶zelliÄŸi eÅŸit ÅŸekilde deÄŸerlendirir.
2ï¸âƒ£ Gradient Descent (Gradyan Ä°niÅŸi) Daha HÄ±zlÄ± ve Verimli Ã‡alÄ±ÅŸÄ±r.

Ridge regresyonu arka planda Gradient Descent kullanarak katsayÄ±larÄ± optimize eder.
EÄŸer Ã¶zellikler farklÄ± Ã¶lÃ§eklerdeyse, optimizasyon sÃ¼reci dengesiz olur ve model daha yavaÅŸ ve dÃ¼zensiz Ã¶ÄŸrenir.
Ã–zellikleri standartlaÅŸtÄ±rarak gradyan iniÅŸinin daha stabil Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlarÄ±z.
3ï¸âƒ£ Ã–zellikle Mesafe Temelli Algoritmalarda Ã–nemlidir.

Ridge regresyonu Ã–klid mesafesi gibi hesaplamalara dayalÄ± olduÄŸu iÃ§in farklÄ± Ã¶lÃ§eklerdeki veriler modelin yanlÄ±ÅŸ Ã¶ÄŸrenmesine neden olabilir.
StandardScaler kullanarak tÃ¼m Ã¶zellikleri eÅŸit Ã¶neme sahip hale getiririz.

ğŸ“Œ 2. StandartlaÅŸtÄ±rma YapÄ±lmazsa Ne Olur?
EÄŸer StandardScaler kullanmazsan, ÅŸu problemler yaÅŸanabilir:
âŒ BÃ¼yÃ¼k deÄŸerli Ã¶zellikler (Ã¶rneÄŸin yÄ±llÄ±k maaÅŸ) modelin Ã¶ÄŸrenme sÃ¼recinde baskÄ±n hale gelir.
âŒ Modelin optimizasyon sÃ¼reci yavaÅŸ ve dengesiz olabilir.
âŒ Ridge Regression aÄŸÄ±rlÄ±klarÄ± kÃ¼Ã§Ã¼ltmekte zorlanabilir ve model kÃ¶tÃ¼ genelleme yapabilir.

ğŸ“Œ 3. StandartlaÅŸtÄ±rma Her Zaman Gerekli mi?
HayÄ±r! BazÄ± durumlarda StandardScaler kullanmaya gerek yoktur:
âœ… Karar aÄŸaÃ§larÄ± (Decision Tree, Random Forest, XGBoost) gibi aÄŸaÃ§ tabanlÄ± algoritmalar, verinin Ã¶lÃ§eÄŸinden baÄŸÄ±msÄ±z Ã§alÄ±ÅŸÄ±r.
âœ… Lineer olmayan algoritmalar (Ã¶rneÄŸin Naive Bayes) Ã¶lÃ§eklendirme gerektirmeyebilir.
âœ… EÄŸer tÃ¼m Ã¶zellikler zaten aynÄ± Ã¶lÃ§ek aralÄ±ÄŸÄ±ndaysa, StandardScaler gereksiz olabilir.

----------------------------------------------------------------------------------------------------

ğŸ“Œ Kodunun Ãœzerinde Cross-Validation Uygulama AdÄ±mlarÄ±:

ğŸ“Œ AdÄ±m AdÄ±m Cross-Validation UygulamasÄ±:

from sklearn.model_selection import cross_val_score
from sklearn.linear_model import Ridge
from sklearn.preprocessing import StandardScaler
import numpy as np

# Veriyi eÄŸitim ve test kÃ¼melerine ayÄ±rÄ±yoruz
X_train, x_tv, y_train, y_tv = train_test_split(x, y, test_size=0.3, random_state=9)
x_eval, x_test, y_eval, y_test = train_test_split(x_tv, y_tv, test_size=0.5, random_state=9)

# Veriyi Ã¶lÃ§eklendirme
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
x_eval = scaler.transform(x_eval)
x_test = scaler.transform(x_test)

# Ridge regresyon modelini oluÅŸturuyoruz
model = Ridge(alpha=103)

# 5-Fold Cross Validation iÅŸlemi
# Veriyi 5 parÃ§aya bÃ¶ler ve her parÃ§ada eÄŸitip test ederiz.
cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring="neg_mean_squared_error")

# SonuÃ§larÄ± RMSE formatÄ±nda gÃ¶rmek iÃ§in karekÃ¶kÃ¼nÃ¼ alÄ±yoruz
rmse_cv_scores = np.sqrt(-cv_scores)

# Cross-validation sonuÃ§larÄ±
print("Cross-validation RMSE Scores: ", rmse_cv_scores)
print("Ortalama Cross-validation RMSE: ", rmse_cv_scores.mean())

----------------------------------------------------------------------------------------------------

1. Veri KÃ¼mesinin BÃ¶lÃ¼nmesi ğŸ“Š:
Veri, eÄŸitim (X_train, y_train) ve test kÃ¼melerine ayrÄ±lÄ±r. Cross-validation, sadece eÄŸitim kÃ¼mesi Ã¼zerinde yapÄ±lÄ±r. Test verisi son deÄŸerlendirme iÃ§in kullanÄ±lÄ±r, yani cross-validationâ€™a dahil edilmez.

2. Modelin Ã–lÃ§eklendirilmesi ğŸ“:
FarklÄ± birimlerdeki Ã¶zellikler modelin doÄŸru Ã¶ÄŸrenmesini engelleyebilir. StandardScaler kullanarak veriyi aynÄ± Ã¶lÃ§eÄŸe getiririz, bÃ¶ylece model her Ã¶zelliÄŸi eÅŸit ÅŸekilde deÄŸerlendirir ve daha doÄŸru Ã¶ÄŸrenir.

3. Cross-Validation (Ã‡apraz DoÄŸrulama) ğŸ”„:
Cross-validation, modelin farklÄ± veri bÃ¶lmelerinde test edilmesini saÄŸlar. 5 katmanlÄ± cross-validation kullanarak modelin genelleme baÅŸarÄ±sÄ±nÄ± daha gÃ¼venilir bir ÅŸekilde Ã¶lÃ§eriz. Her foldâ€™da model eÄŸitilir ve test edilir.

4. scoring="neg_mean_squared_error" ğŸ”:
MSE (Mean Squared Error), modelin hatalarÄ±nÄ± Ã¶lÃ§er, ancak negatif bir deÄŸer dÃ¶ndÃ¼rÃ¼r. Sklearn maksimize etmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ± iÃ§in, neg_mean_squared_error kullanarak, MSEâ€™nin negatifini alÄ±p doÄŸru ÅŸekilde deÄŸerlendirme yaparÄ±z.

GENEL OLARAK CROSS VALÄ°DATÄ°ON MANTIÄI ;

Ã–rnek: 5-Fold Cross Validation
ğŸ“Š EÄŸer 100 verimiz varsa ve 5-Fold CV kullanÄ±yorsak:

Fold	EÄŸitim Verisi (80%)     Test Verisi (20%)
1. Kat	Fold 2, 3, 4, 5		Fold 1
2. Kat	Fold 1, 3, 4, 5		Fold 2
3. Kat	Fold 1, 2, 4, 5		Fold 3
4. Kat	Fold 1, 2, 3, 5		Fold 4
5. Kat	Fold 1, 2, 3, 4		Fold 5
SonuÃ§ olarak:
ğŸ“Œ Model 5 kez eÄŸitilir ve test edilir.
ğŸ“Œ 5 farklÄ± test sonucu alÄ±nÄ±r ve ortalamasÄ± hesaplanÄ±r.

----------------------------------------------------------------------------------------------------

ğŸ“Š SON KEZ TEKRAR EDELÄ°M

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge		== Ä°MPORT
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error
import numpy as np

ğŸ“Š 1. Veri KÃ¼mesini BÃ¶lme
# Veri kÃ¼mesini eÄŸitim ve test kÃ¼melerine ayÄ±rÄ±yoruz
X_train, x_tv, y_train, y_tv = train_test_split(x, y, test_size=0.3, random_state=9)

 Test kÃ¼mesinin yarÄ±sÄ±nÄ± validation (deÄŸerlendirme) kÃ¼mesi iÃ§in ayÄ±rÄ±yoruz
x_eval, x_test, y_eval, y_test = train_test_split(x_tv, y_tv, test_size=0.5, random_state=9)

 ğŸ“ 2. Veriyi Ã–lÃ§eklendirme
# StandardScaler ile veriyi Ã¶lÃ§eklendiriyoruz
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
x_eval = scaler.transform(x_eval)
x_test = scaler.transform(x_test)

ğŸ”„ 3. Modeli EÄŸitme ve Cross-Validation Uygulama
# Ridge regresyon modelini oluÅŸturuyoruz
model = Ridge(alpha=103)

# 5 katmanlÄ± cross-validation uyguluyoruz
cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring="neg_mean_squared_error")

# SonuÃ§larÄ± RMSE formatÄ±nda gÃ¶rmek iÃ§in karekÃ¶kÃ¼nÃ¼ alÄ±yoruz
rmse_cv_scores = np.sqrt(-cv_scores)

ğŸ“Š Cross-validation sonuÃ§larÄ±
print("Cross-validation RMSE Scores: ", rmse_cv_scores)
print("Ortalama Cross-validation RMSE: ", rmse_cv_scores.mean())




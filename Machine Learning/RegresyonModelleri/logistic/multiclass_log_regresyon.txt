		--  MULTICLASS LOGISTIC REGRESYON -- 

Multi-class logistic regression, bir verinin hangi sÄ±nÄ±fa ait olduÄŸunu belirlemek iÃ§in kullanÄ±lÄ±r. Ä°ÅŸte bazÄ± kullanÄ±m alanlarÄ±:

ðŸ“· GÃ¶rÃ¼ntÃ¼ SÄ±nÄ±flandÄ±rma ðŸ¶ðŸ±ðŸ¦ (Bir fotoÄŸraftaki objenin kedi, kÃ¶pek veya kuÅŸ olup olmadÄ±ÄŸÄ±nÄ± tahmin eder.)

ðŸ”  El YazÄ±sÄ± TanÄ±ma âœï¸ðŸ“– (Bir harfin "A", "B" veya "C" olduÄŸunu belirler.)

ðŸŽµ MÃ¼zik TÃ¼rÃ¼ TanÄ±ma ðŸŽ¸ðŸŽ¶ðŸŽ» (Bir ÅŸarkÄ±nÄ±n rock, pop veya klasik mÃ¼zik tÃ¼rÃ¼nde olup olmadÄ±ÄŸÄ±nÄ± bulur.)

ðŸ“§ E-posta SÄ±nÄ±flandÄ±rma ðŸ“©âš ï¸ðŸ—‘ï¸ (Bir e-postanÄ±n spam, Ã¶nemli veya promosyon olup olmadÄ±ÄŸÄ±nÄ± belirler.)

âš½ Spor Tahminleri ðŸ€âš¾âš½ (Bir maÃ§Ä±n sonucunu veya takÄ±mÄ±n performansÄ±nÄ± tahmin edebilir.)

KÄ±sacasÄ±, veriyi analiz edip, en uygun sÄ±nÄ±fa atayan bir algoritmadÄ±r! ðŸ¤–ðŸŽ¯

*****************************************************************************

		ðŸ“Š Multi-Class Logistic Regression ðŸ“Š

1ï¸âƒ£ Girdi Verisi (Input Data) ðŸ ðŸš—ðŸ¶ðŸ“· (FarklÄ± kategorilere ait veriler var)
2ï¸âƒ£ Ã–zellik Ã‡Ä±kartma (Feature Extraction) ðŸ”ðŸ“ˆ (Veriler sayÄ±sal hale getiriliyor)
3ï¸âƒ£ Model EÄŸitimi (Training the Model) ðŸ§ âž¡ï¸ðŸ”„ (Model, hangi verinin hangi sÄ±nÄ±fa ait olduÄŸunu Ã¶ÄŸreniyor)
4ï¸âƒ£ OlasÄ±lÄ±k Hesaplama (Probability Calculation) ðŸŽ²ðŸ“‰ (Her sÄ±nÄ±fa ait olasÄ±lÄ±klar hesaplanÄ±yor, toplamÄ± 1 olacak ÅŸekilde)
5ï¸âƒ£ Tahmin (Prediction) ðŸŽ¯ðŸ¤– (Veri, en yÃ¼ksek olasÄ±lÄ±ÄŸÄ± olan sÄ±nÄ±fa atanÄ±yor!)

Ã–zetle, multi-class logistic regression, bir nesnenin birden fazla sÄ±nÄ±ftan birine ait olup olmadÄ±ÄŸÄ±nÄ± olasÄ±lÄ±klarla hesaplayan bir makine Ã¶ÄŸrenmesi algoritmasÄ±dÄ±r! 

*****************************************************************************
ðŸŽ£ Multi-Class Logistic Regression ile Fish DataFrame Analizi ðŸŽ£

ðŸ“¥ Veriyi YÃ¼kleyelim

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Veri setini iÃ§e aktaralÄ±m
df = pd.read_csv("Fish.csv")

# Ä°lk beÅŸ satÄ±rÄ± gÃ¶relim
df.head()

ðŸ§ Veri Setini TanÄ±yalÄ±m
# Veri hakkÄ±nda genel bilgiler
df.info()

# Ä°statistiksel Ã¶zet
df.describe()

ðŸŽ¯ Tahmin Edilecek Kolon: "Species"

df["Species"].unique()
ðŸ“Œ Bu komut, veri setindeki tÃ¼m balÄ±k tÃ¼rlerini gÃ¶sterir.

Her TÃ¼rden KaÃ§ Tane Var?

df["Species"].value_counts()
ðŸ“Œ BalÄ±k tÃ¼rlerinin daÄŸÄ±lÄ±mÄ±nÄ± sayÄ±sal olarak gÃ¶sterir.

ðŸ“Š Verileri GÃ¶rselleÅŸtirelim

1ï¸âƒ£ BalÄ±k TÃ¼rlerinin DaÄŸÄ±lÄ±m GrafiÄŸi
sns.countplot(x=df["Species"])
plt.xticks(rotation=45)
plt.title("BalÄ±k TÃ¼rlerinin DaÄŸÄ±lÄ±mÄ±")
plt.show()

2ï¸âƒ£ AÄŸÄ±rlÄ±k ve YÃ¼kseklik DaÄŸÄ±lÄ±mÄ±
sns.scatterplot(x="Weight", y="Height", data=df, hue="Species")
plt.title("AÄŸÄ±rlÄ±k - YÃ¼kseklik DaÄŸÄ±lÄ±mÄ±")
plt.show()

3ï¸âƒ£ BÃ¼tÃ¼n DaÄŸÄ±lÄ±mlara BakalÄ±m
sns.pairplot(df, hue="Species")
plt.show()
ðŸ“Œ TÃ¼m deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkiyi incelememizi saÄŸlar.

4ï¸âƒ£ Korelasyon HaritasÄ± (Heatmap)
sns.heatmap(df.select_dtypes(include=[np.number]).corr(), annot=True, cmap="coolwarm", linewidths=0.5)
plt.title("Ã–zellikler ArasÄ±ndaki Korelasyon")
plt.show()

ðŸ“Œ SayÄ±sal deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkileri inceleriz. YÃ¼ksek korelasyon, deÄŸiÅŸkenler arasÄ±nda gÃ¼Ã§lÃ¼ bir iliÅŸki olduÄŸunu gÃ¶sterir.

*****************************************************************************
ðŸ”„ Train-Test Split Ä°ÅŸlemi & Veriyi Ã–lÃ§eklendirme

ðŸ“Œ Hedef DeÄŸiÅŸken ve Ã–zelliklerin AyrÄ±lmasÄ±
"Species" kolonunu tahmin etmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in baÄŸÄ±msÄ±z deÄŸiÅŸkenleri (X) ve baÄŸÄ±mlÄ± deÄŸiÅŸkeni (y) ayÄ±ralÄ±m:

# X: BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (Species kolonu hariÃ§ tÃ¼m Ã¶zellikler)
x = df.drop("Species", axis=1)

# y: BaÄŸÄ±mlÄ± deÄŸiÅŸken (Tahmin edeceÄŸimiz balÄ±k tÃ¼rÃ¼)
y = df["Species"]

âœ‚ï¸ Veriyi EÄŸitim ve Test Olarak AyÄ±rma
from sklearn.model_selection import train_test_split

# %70 eÄŸitim, %30 test olarak bÃ¶lme iÅŸlemi
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=9)

ðŸ“Œ Veriyi ayÄ±rÄ±rken random_state=9 kullanarak sonuÃ§larÄ±n tutarlÄ± olmasÄ±nÄ± saÄŸlÄ±yoruz.

âš–ï¸ Veriyi Ã–lÃ§eklendirme (Standardizasyon)
from sklearn.preprocessing import StandardScaler

# StandardScaler nesnesini oluÅŸtur
scaler = StandardScaler()

# EÄŸitim verisini fit & transform et
scaled_X_train = scaler.fit_transform(X_train)

# Test verisini transform et
scaled_X_test = scaler.transform(X_test)

ðŸ“Œ Bu iÅŸlem, veriyi ortalamasÄ± 0, standart sapmasÄ± 1 olacak ÅŸekilde Ã¶lÃ§eklendirir. Modelin daha iyi Ã¶ÄŸrenmesine yardÄ±mcÄ± olur.

ðŸš€ Bir sonraki adÄ±m: Modeli oluÅŸturup eÄŸitmeye geÃ§ebiliriz! ðŸŽ¯


*****************************************************************************

ðŸ¤– Logistic Regression Ä°ÅŸlemi (Model EÄŸitimi & Optimizasyon)

ðŸ“¥ Gerekli KÃ¼tÃ¼phaneleri Ä°Ã§e AktaralÄ±m
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
import numpy as np

ðŸ“Œ Model oluÅŸturmak ve en iyi parametreleri bulmak iÃ§in LogisticRegression ve GridSearchCV kullanacaÄŸÄ±z.

ðŸ”§ Modeli TanÄ±mlayalÄ±m

# Lojistik Regresyon Modeli
log_model = LogisticRegression(solver='saga', multi_class='ovr', max_iter=5000)

ðŸ“Œ Burada:
âœ”ï¸ solver='saga' â†’ BÃ¼yÃ¼k veri setlerinde iyi Ã§alÄ±ÅŸan bir optimizasyon yÃ¶ntemi kullanÄ±ldÄ±.
âœ”ï¸ multi_class='ovr' â†’ "One-vs-Rest" yÃ¶ntemiyle Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma yapÄ±ldÄ±.
âœ”ï¸ max_iter=5000 â†’ Modelin daha iyi optimize olabilmesi iÃ§in iterasyon sayÄ±sÄ± artÄ±rÄ±ldÄ±.

ðŸ” Hiperparametre Optimizasyonu (GridSearchCV KullanÄ±mÄ±)

Ceza (Penalty) ve C DeÄŸeri TanÄ±mlama :

penalty = ["l1", "l2"]  # L1: Lasso, L2: Ridge

C = np.logspace(0, 5, 16)  
# C > 1 â†’ Model train setine Ã§ok dikkat eder (overfitting riski artar).
# C < 1 â†’ Model train seti daha az Ã¶nemser, kÃ¼Ã§Ã¼k coefâ€™ler oluÅŸturup cezalandÄ±rÄ±r (daha iyi genelleme saÄŸlar).

Grid Search ile En Ä°yi Parametreyi Bulma

grid_model = GridSearchCV(
    log_model,
    param_grid={"C": C, "penalty": penalty},  
    cv=5,  # 5 katlÄ± Ã§apraz doÄŸrulama
    n_jobs=-1,  # Paralel iÅŸlem yaparak daha hÄ±zlÄ± Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlÄ±yoruz.
    verbose=1  # Ä°ÅŸlem sÃ¼recini takip edebilmek iÃ§in
)

# Modeli EÄŸitme
grid_model.fit(scaled_X_train, y_train)
ðŸ“Œ Bu iÅŸlem, en iyi C ve penalty deÄŸerlerini bulmak iÃ§in Grid Search yÃ¶ntemini kullanÄ±r.

ðŸ† En Ä°yi Parametreleri GÃ¶rÃ¼ntÃ¼leme
grid_model.best_params_

ðŸ“Œ Bu, modelin en iyi sonucu verdiÄŸi parametre kombinasyonunu gÃ¶sterir.

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
		ðŸ› ï¸ Penalty ve C Parametrelerinde DeÄŸiÅŸiklik YaparsanÄ±z Ne Olur?

Logistic Regression modelinizde bu iki parametre, modelin Ã¶ÄŸrenme biÃ§imini doÄŸrudan etkiler:

ðŸ“Œ 1. penalty = ["l1", "l2"] DeÄŸiÅŸirse Ne Olur?
penalty=["l1"]:
âœ”ï¸ Sadece Ã¶nemli Ã¶zellikleri tutar, gereksiz olanlarÄ± sÄ±fÄ±ra Ã§eker (Ã¶zellik seÃ§imi saÄŸlar).
âœ”ï¸ Daha sade ve aÃ§Ä±klanabilir bir model oluÅŸturur.
âš ï¸ Multicollinearity varsa daha iyi sonuÃ§ verir.

penalty=["l2"]:
âœ”ï¸ TÃ¼m Ã¶zellikleri korur, ancak katsayÄ±larÄ±nÄ± kÃ¼Ã§Ã¼ltÃ¼r (overfitting Ã¶nler).
âœ”ï¸ BÃ¼yÃ¼k ve Ã§ok boyutlu veri setlerinde daha stabil Ã§alÄ±ÅŸÄ±r.
âš ï¸ Yorumlanabilirlik dÃ¼ÅŸebilir.

Her Ä°kisi (["l1", "l2"]) Birlikte:
âœ”ï¸ GridSearchCV, her iki yÃ¶ntemi de dener ve hangi dÃ¼zenlileÅŸtirmenin daha iyi sonuÃ§ verdiÄŸini otomatik olarak seÃ§er.

ðŸ“Œ 2. C = np.logspace(0,5,16) DeÄŸiÅŸirse Ne Olur?

C parametresi regularization strength (dÃ¼zenleme gÃ¼cÃ¼) olarak bilinir:
C kÃ¼Ã§Ã¼kse: Daha fazla dÃ¼zenlileÅŸtirme â†’ AÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) azalÄ±r, ancak model az Ã¶ÄŸrenebilir (underfitting).
C bÃ¼yÃ¼kse: Daha az dÃ¼zenlileÅŸtirme â†’ Model train setine daha fazla uyum saÄŸlar, ancak overfitting riski artar.

ðŸŸ¡ EÄŸer C DeÄŸerlerini DeÄŸiÅŸtirirseniz:
C = np.logspace(-3, 3, 10):
âœ”ï¸ Daha geniÅŸ bir aralÄ±k dener (0.001'den 1000'e kadar)
âœ”ï¸ Hem kÃ¼Ã§Ã¼k hem bÃ¼yÃ¼k dÃ¼zenlileÅŸtirme gÃ¼Ã§lerini test eder

C = np.linspace(0.1, 10, 20):
âœ”ï¸ Dar bir aralÄ±kta ince ayar yapar (0.1'den 10'a kadar)
âœ”ï¸ EÄŸer veri seti kÃ¼Ã§Ã¼kse daha verimli olur

ðŸŸ  C DeÄŸerinde AÅŸÄ±rÄ± ArtÄ±ÅŸ veya Azalma:
Ã‡ok bÃ¼yÃ¼k C â†’ Model train setine aÅŸÄ±rÄ± uyum saÄŸlar (overfit).
Ã‡ok kÃ¼Ã§Ã¼k C â†’ Model yeterince Ã¶ÄŸrenemez (underfit).

ðŸš€ Ã–zet:
penalty: l1 Ã¶zelliÄŸi azaltÄ±r, l2 stabilite saÄŸlar. Ä°kisini birlikte GridSearch ile kullanmak daha iyi.
C: C deÄŸerlerini geniÅŸ bir aralÄ±kta denemek (logspace) daha iyidir.
En Ä°yi YÃ¶ntem: Sizin yaptÄ±ÄŸÄ±nÄ±z gibi GridSearchCV kullanarak tÃ¼m kombinasyonlarÄ± test etmek. âœ…

np.logspace(start, stop, num, base=10)

start: BaÅŸlangÄ±Ã§ deÄŸeri (logaritmanÄ±n Ã¼ssÃ¼ olarak)
stop: BitiÅŸ deÄŸeri (logaritmanÄ±n Ã¼ssÃ¼ olarak)
num: Ãœretilecek sayÄ±larÄ±n miktarÄ±
base: Logaritma tabanÄ± (varsayÄ±lan olarak 10)

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
ðŸ“Š En Ä°yi Modelin KatsayÄ±larÄ±nÄ± GÃ¶rÃ¼ntÃ¼leme

grid_model.best_estimator_  # En iyi lojistik regresyon modeli
grid_model.best_estimator_.coef_  # Ã–zellik katsayÄ±larÄ±nÄ± gÃ¶sterir

ðŸ“Œ Bu katsayÄ±lar, her bir Ã¶zelliÄŸin model tahminine olan etkisini gÃ¶sterir.

*****************************************************************************

ðŸ” Neden Grid Search CV KullanÄ±yoruz?

Grid Search CV (GridSearchCV) kullanmamÄ±zÄ±n sebebi, modelimizin en iyi hiperparametre kombinasyonunu otomatik olarak bulmasÄ±nÄ± saÄŸlamak.

ðŸ“Œ Hiperparametre Nedir?

Modelin Ã¶ÄŸrenme sÃ¼recini etkileyen, ancak doÄŸrudan verilerden Ã¶ÄŸrenilmeyen ayarlardÄ±r. Ã–rneÄŸin:

C (Regularization Strength): Modelin ne kadar katÄ± veya esnek olacaÄŸÄ±nÄ± belirler.
Penalty (Ceza TÃ¼rÃ¼): L1 (Lasso) ve L2 (Ridge) kullanÄ±larak aÄŸÄ±rlÄ±klarÄ±n sÄ±fÄ±ra yaklaÅŸmasÄ±nÄ± veya kÃ¼Ã§Ã¼lmesini saÄŸlarÄ±z.
Bu parametreleri manuel olarak denemek yerine, Grid Search CV ile farklÄ± kombinasyonlarÄ± dener ve en iyi sonucu veren ayarÄ± seÃ§eriz.

ðŸŽ¯ Grid Search KullanmanÄ±n AvantajlarÄ±

âœ… En Ä°yi Hiperparametreleri Otomatik Bulur
ðŸ‘‰ Manuel olarak her kombinasyonu denemek yerine, Grid Search tÃ¼m kombinasyonlarÄ± dener ve en iyisini seÃ§er.

âœ… Ã‡apraz DoÄŸrulama (Cross Validation) ile Daha SaÄŸlam Model
ðŸ‘‰ cv=5 ile veri setini 5 parÃ§aya ayÄ±rarak her parÃ§a iÃ§in model eÄŸitilir ve test edilir.
ðŸ‘‰ Bu sayede modelimizin farklÄ± veri bÃ¶lÃ¼mlerinde de iyi performans gÃ¶sterdiÄŸinden emin oluruz.

âœ… Overfitting Riskini AzaltÄ±r
ðŸ‘‰ YanlÄ±ÅŸ hiperparametre seÃ§imi overfitting (aÅŸÄ±rÄ± Ã¶ÄŸrenme) veya underfitting (eksik Ã¶ÄŸrenme) riskine yol aÃ§abilir.
ðŸ‘‰ Grid Search, modelin en iyi dengeyi bulmasÄ±nÄ± saÄŸlar.

ðŸš€ SonuÃ§: Grid Search CV, modelimizin en iyi performansÄ± vermesi iÃ§in en uygun ayarlarÄ± seÃ§memizi saÄŸlayan gÃ¼Ã§lÃ¼ bir araÃ§tÄ±r.

*****************************************************************************
ðŸ“Š Performans Metrikleri ile Model DeÄŸerlendirme

ðŸ“¥ Gerekli KÃ¼tÃ¼phaneleri Ä°Ã§eri Aktarma

from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, classification_report
ðŸ“Œ Bu metrikler modelimizin ne kadar baÅŸarÄ±lÄ± olduÄŸunu Ã¶lÃ§memizi saÄŸlar.

ðŸŽ¯ Modelin Test Verisi Ãœzerindeki Tahminlerini AlalÄ±m

fish_pred = grid_model.predict(scaled_X_test)  # Modelin tahminlerini alÄ±yoruz
âœ… DoÄŸruluk Skoru (Accuracy Score) Hesaplama

accuracy = accuracy_score(y_test, fish_pred)
print(f"Model DoÄŸruluk Skoru: {accuracy:.4f}")
ðŸ“Œ Accuracy, modelin kaÃ§ doÄŸru tahminde bulunduÄŸunu gÃ¶sterir. Ancak dengesiz veri setlerinde yanÄ±ltÄ±cÄ± olabilir!

ðŸ“Š Confusion Matrix (KarmaÅŸÄ±klÄ±k Matrisi) GÃ¶rselleÅŸtirme

-- Ham DeÄŸerlerle Confusion Matrix
ConfusionMatrixDisplay.from_estimator(grid_model, scaled_X_test, y_test)
ðŸ“Œ Bu grafik, modelin hangi sÄ±nÄ±flarÄ± doÄŸru ve yanlÄ±ÅŸ tahmin ettiÄŸini gÃ¶sterir.

-- Oransal Confusion Matrix (Normalize EdilmiÅŸ Hali)
ConfusionMatrixDisplay.from_estimator(grid_model, scaled_X_test, y_test, normalize="true")

ðŸ“Œ Normalize edilmiÅŸ matris, her sÄ±nÄ±f iÃ§in hatalarÄ±n oransal daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶sterir. Yani model hangi sÄ±nÄ±fÄ± daha fazla veya az yanlÄ±ÅŸ tahmin ediyor, bunu gÃ¶rebiliriz.

ðŸ”Ž Grafik Yorumu (Ã–rnek Durum: Whitefish vs. Perch)

ðŸ“Œ DaÄŸÄ±lÄ±m grafiÄŸine bakÄ±ldÄ±ÄŸÄ±nda, bazÄ± Whitefishâ€™lerin Perch olarak tahmin edildiÄŸi gÃ¶rÃ¼lÃ¼yor. Bunun sebebi, scatter plotâ€™ta Whitefishâ€™lerin Perch Ã¼zerine daÄŸÄ±lmasÄ±ndan kaynaklanÄ±yor.

ðŸ“„ Classification Report ile DetaylÄ± DeÄŸerlendirme

print(classification_report(y_test, fish_pred))

ðŸ“Œ Bu rapor, her sÄ±nÄ±f iÃ§in
âœ”ï¸ Precision (Kesinlik) â€“ YanlÄ±ÅŸ pozitifleri ne kadar az yaptÄ±ÄŸÄ±mÄ±zÄ± gÃ¶sterir.
âœ”ï¸ Recall (DuyarlÄ±lÄ±k) â€“ GerÃ§ek pozitifleri ne kadar iyi yakaladÄ±ÄŸÄ±mÄ±zÄ± gÃ¶sterir.
âœ”ï¸ F1-score â€“ Precision ve Recallâ€™un dengeli bir Ã¶lÃ§Ã¼sÃ¼nÃ¼ verir.

SonuÃ§:
âœ”ï¸ Precision deÄŸerine bakarak modelimizin tahmin gÃ¼cÃ¼nÃ¼ deÄŸerlendiriyoruz.
âœ”ï¸ Hangi balÄ±k tÃ¼rlerinin daha Ã§ok karÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nÄ± analiz ederek modelin iyileÅŸtirilmesi gereken noktalarÄ±nÄ± belirliyoruz.

*****************************************************************************
ðŸ” Genel Tekrar: Multi-Class Logistic Regression ile BalÄ±k TÃ¼rÃ¼ Tahmini

1ï¸âƒ£ Veri Setinin Ä°ncelenmesi

import pandas as pd
import seaborn as sns
import numpy as np

# Veri setini yÃ¼kleyelim
df = pd.read_csv("Fish.csv")

# DataFrame'e genel bakÄ±ÅŸ
df.head()
df.info()
df.describe()

# Species kolonu iÃ§indeki benzersiz balÄ±k tÃ¼rleri
df["Species"].unique()

# Species kolonu iÃ§indeki her tÃ¼rÃ¼n sayÄ±sÄ±
df["Species"].value_counts()

# TÃ¼rlerin daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rselleÅŸtirelim
sns.countplot(x=df["Species"])

# DaÄŸÄ±lÄ±mÄ± daha iyi gÃ¶rmek iÃ§in scatter plot
sns.scatterplot(x="Weight", y="Height", data=df, hue="Species")

# TÃ¼m deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkileri gÃ¶rselleÅŸtirelim
sns.pairplot(df, hue="Species")

# KorelasyonlarÄ± gÃ¶rmek iÃ§in heatmap
sns.heatmap(df.select_dtypes(include=[np.number]).corr(), annot=True)

2ï¸âƒ£ Train-Test Split ve Veri Standardizasyonu

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±ralÄ±m
x = df.drop("Species", axis=1)
y = df["Species"]

# Veri setini eÄŸitim ve test olarak bÃ¶lelim
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=9)

# Veriyi standartlaÅŸtÄ±ralÄ±m (standart sapma 1, ortalama 0 olacak ÅŸekilde)
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

3ï¸âƒ£ Lojistik Regresyon Modelinin EÄŸitilmesi

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV

# Lojistik regresyon modelini tanÄ±mlayalÄ±m
log_model = LogisticRegression(solver='saga', multi_class='ovr', max_iter=5000)

# Hiperparametreleri belirleyelim
penalty = ["l1", "l2"]
C = np.logspace(0, 5, 16)  # Ceza parametresi ve C deÄŸerleri

# GridSearchCV ile en iyi parametreyi bulalÄ±m
grid_model = GridSearchCV(
    log_model,
    param_grid={"C": C, "penalty": penalty}
)

# Modeli eÄŸitelim
grid_model.fit(scaled_X_train, y_train)

# En iyi parametreleri gÃ¶relim
grid_model.best_params_

# En iyi modelin katsayÄ±larÄ±nÄ± inceleyelim
grid_model.best_estimator_.coef_

4ï¸âƒ£ Modelin PerformansÄ±nÄ± DeÄŸerlendirme

from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, classification_report

# Test setinde tahmin yapalÄ±m
fish_pred = grid_model.predict(scaled_X_test)

# DoÄŸruluk skoru (accuracy score) hesaplayalÄ±m
accuracy = accuracy_score(y_test, fish_pred)
print(f"Model DoÄŸruluk Skoru: {accuracy:.4f}")

# Confusion Matrix gÃ¶rselleÅŸtirelim
ConfusionMatrixDisplay.from_estimator(grid_model, scaled_X_test, y_test)

# Normalize edilmiÅŸ Confusion Matrix
ConfusionMatrixDisplay.from_estimator(grid_model, scaled_X_test, y_test, normalize="true")

# Classification Report'u yazdÄ±ralÄ±m
print(classification_report(y_test, fish_pred))

5ï¸âƒ£ Grafik ve Model YorumlarÄ±
Grafik Yorumu:
DaÄŸÄ±lÄ±m grafiÄŸine bakÄ±ldÄ±ÄŸÄ±nda, Whitefish tÃ¼rlerinin Perch tÃ¼rÃ¼ olarak tahmin edildiÄŸi gÃ¶rÃ¼lÃ¼yor. Bunun nedeni, scatter plotâ€™ta Whitefishâ€™lerin Perch Ã¼zerine daÄŸÄ±lmasÄ±ndan kaynaklanÄ±yor olabilir.

Precision:
Modelin tahmin doÄŸruluÄŸu, Ã¶zellikle doÄŸru pozitiflerin oranÄ± hakkÄ±nda bilgi verir.

*****************************************************************************

ðŸš€ Multi-Class Logistic Regression ile BalÄ±k TÃ¼rÃ¼ Tahmini â€“ Ã–zet
Bu rehberde, Multi-Class Logistic Regression kullanarak balÄ±k tÃ¼rÃ¼ tahmini gerÃ§ekleÅŸtirdik. Ä°ÅŸte genel bir Ã¶zet:

1ï¸âƒ£ Veri Ä°ncelemesi:
Veri setini inceledik, Species kolonu Ã¼zerinden balÄ±k tÃ¼rlerini ve daÄŸÄ±lÄ±mlarÄ±nÄ± gÃ¶rselleÅŸtirdik. Ã–zellikler arasÄ±ndaki iliÅŸkileri ve korelasyonlarÄ± heatmap ve scatter plot kullanarak analiz ettik.

2ï¸âƒ£ Veri HazÄ±rlÄ±ÄŸÄ±:
BaÄŸÄ±msÄ±z ve baÄŸÄ±mlÄ± deÄŸiÅŸkenleri ayÄ±rdÄ±k, ardÄ±ndan veri setini eÄŸitim ve test setlerine bÃ¶ldÃ¼k. Veriyi standardize ederek modelin daha verimli Ã¶ÄŸrenmesini saÄŸladÄ±k.

3ï¸âƒ£ Model EÄŸitimi:
Lojistik Regresyon modelini tanÄ±mladÄ±k ve GridSearchCV kullanarak en uygun penalty ve C parametrelerini bulduk. Modelimizi saga Ã§Ã¶zÃ¼mleyici ve one-vs-rest (ovr) Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma yaklaÅŸÄ±mÄ± ile eÄŸittik.

4ï¸âƒ£ Performans DeÄŸerlendirmesi:
Modelin doÄŸruluÄŸunu accuracy score ile Ã¶lÃ§tÃ¼k. Confusion matrix ile modelin doÄŸru ve yanlÄ±ÅŸ tahminlerini gÃ¶rselleÅŸtirdik. Classification report ile precision, recall ve f1-score deÄŸerlerini inceledik.

5ï¸âƒ£ Grafik ve Yorumlar:
Grafikleri yorumladÄ±k ve Whitefish tÃ¼rÃ¼nÃ¼n bazen Perch olarak tahmin edildiÄŸini fark ettik. Bu hatanÄ±n daÄŸÄ±lÄ±m grafiklerinden kaynaklandÄ±ÄŸÄ±nÄ± gÃ¶zlemledik.

*****************************************************************************
    ðŸ”§ Lojistik Regresyon Modelinin TanÄ±mlanmasÄ± ve Parametre SeÃ§imi

log_model = LogisticRegression(solver='saga', multi_class='ovr', max_iter=500

1ï¸âƒ£ solver='saga'
solver parametresi, lojistik regresyonun optimizasyon algoritmasÄ±nÄ± seÃ§er. Bu parametrede Ã§eÅŸitli seÃ§enekler bulunur:

'newton-cg': Newton-Raphson yÃ¶ntemini kullanÄ±r, genellikle kÃ¼Ã§Ã¼k veri setlerinde iyi performans gÃ¶sterir.
'lbfgs': Limited-memory Broydenâ€“Fletcherâ€“Goldfarbâ€“Shanno (LBFGS) algoritmasÄ±nÄ± kullanÄ±r. KÃ¼Ã§Ã¼k veri setleri iÃ§in iyidir.
'liblinear': KÃ¼Ã§Ã¼k veri setlerinde L1 ve L2 cezasÄ± uygulandÄ±ÄŸÄ±nda genellikle kullanÄ±lÄ±r.
'saga': Stochastic Average Gradient Descent algoritmasÄ±, bÃ¼yÃ¼k veri setleri iÃ§in Ã¶nerilir. Bu yÃ¶ntem, L1 ve L2 cezasÄ±nÄ± daha verimli ÅŸekilde iÅŸler ve Ã§oklu sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma iÃ§in uygundur.
Neden 'saga' kullanÄ±ldÄ±?

BÃ¼yÃ¼k veri setlerinde verimli Ã§alÄ±ÅŸÄ±r ve hem L1 hem de L2 ceza terimlerini destekler. Bu nedenle saga, Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma (multi_class='ovr') iÃ§in iyi bir tercihtir.

2ï¸âƒ£ multi_class='ovr'
multi_class parametresi, Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma yÃ¶ntemini belirler. Ä°ki farklÄ± seÃ§enek bulunur:

'ovr' (One-vs-Rest): Her sÄ±nÄ±f iÃ§in ayrÄ± bir ikili sÄ±nÄ±flandÄ±rÄ±cÄ± oluÅŸturur. Bu yÃ¶ntemde, model her bir sÄ±nÄ±fÄ± diÄŸerlerinden ayÄ±rmaya Ã§alÄ±ÅŸÄ±r.
'multinomial': TÃ¼m sÄ±nÄ±flar arasÄ±nda tek bir model ile optimizasyon yapÄ±lÄ±r, yani Ã§oklu sÄ±nÄ±f iÃ§in ortak bir model Ã¶ÄŸrenilir. Bu genellikle L2 cezasÄ± ile daha iyi sonuÃ§lar verir.

Neden 'ovr' kullanÄ±ldÄ±?

'ovr' genellikle daha yaygÄ±n kullanÄ±lÄ±r, Ã§Ã¼nkÃ¼ her sÄ±nÄ±f iÃ§in ayrÄ± bir ikili model eÄŸitildiÄŸinden, sÄ±nÄ±flar arasÄ±ndaki karmaÅŸayÄ± azaltabilir.
'multinomial' kullanmak, bÃ¼yÃ¼k veri setlerinde daha karmaÅŸÄ±k olabilir ve Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma iÃ§in daha hassas optimizasyon gerektirebilir.

3ï¸âƒ£ max_iter=5000
max_iter, modelin eÄŸitim sÄ±rasÄ±nda kaÃ§ iterasyon yapÄ±lacaÄŸÄ±nÄ± belirler. Bu parametre, modelin optimizasyon sÃ¼recinin bitmesi iÃ§in gerekli olan iterasyon sayÄ±sÄ±nÄ± kontrol eder.

VarsayÄ±lan deÄŸer genellikle 100'dÃ¼r.
Daha bÃ¼yÃ¼k veri setlerinde ve karmaÅŸÄ±k modellerde iterasyon sayÄ±sÄ±nÄ±n artÄ±rÄ±lmasÄ± gerekebilir.

Neden 5000 kullanÄ±ldÄ±?

BÃ¼yÃ¼k veri setleri ve karmaÅŸÄ±k iliÅŸkiler iÃ§in modelin doÄŸru ÅŸekilde optimize edilmesi adÄ±na iterasyon sayÄ±sÄ± artÄ±rÄ±ldÄ±. Bu, modelin daha fazla zaman harcayarak daha iyi sonuÃ§lar Ã¼retmesini saÄŸlar.
EÄŸer 500 olursa ne olur?

EÄŸer max_iter=500 gibi daha kÃ¼Ã§Ã¼k bir deÄŸer kullanÄ±lÄ±rsa, model daha erken durur ve bazen optimize olmamÄ±ÅŸ sonuÃ§lar verebilir. Ã–zellikle bÃ¼yÃ¼k veri setlerinde ve karmaÅŸÄ±k iliÅŸkilerde modelin daha fazla iterasyona ihtiyacÄ± olabilir.

4ï¸âƒ£ penalty (Ceza Terimi)
penalty parametresi, modelin regularization (ceza) tÃ¼rÃ¼nÃ¼ belirler. Regularization, modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± azaltarak overfitting riskini engeller. Ä°ki tÃ¼r penalty seÃ§eneÄŸi vardÄ±r:

'l1': Lasso regularization. Ã–zelliklerin Ã§oÄŸunu sÄ±fÄ±ra Ã§ekmeye Ã§alÄ±ÅŸÄ±r. Ã–zellik seÃ§imi saÄŸlar.
'l2': Ridge regularization. AÄŸÄ±rlÄ±klarÄ± kÃ¼Ã§Ã¼ltÃ¼r, ancak sÄ±fÄ±ra Ã§ekmez.
'none': Regularization uygulanmaz.

Neden L1 KullanÄ±ldÄ±? ðŸ¤”

L1 (Lasso Regularization), Ã¶zellik seÃ§imi (feature selection) saÄŸladÄ±ÄŸÄ± iÃ§in tercih edilmiÅŸ olabilir. Ä°ÅŸte detaylÄ± aÃ§Ä±klamasÄ±:

ðŸ’¡ L1 (Lasso) Regularizasyonunun AvantajlarÄ±:

1ï¸âƒ£.1ï¸âƒ£ Ã–zellik SeÃ§imi (Feature Selection):

L1 dÃ¼zenlileÅŸtirme, bazÄ± koefisiyentleri sÄ±fÄ±ra Ã§eker, bÃ¶ylece gereksiz Ã¶zellikleri otomatik olarak elemine eder.
Ã‡ok fazla Ã¶zelliÄŸin olduÄŸu veya bazÄ± Ã¶zelliklerin gereksiz olduÄŸu durumlarda daha iyi performans gÃ¶sterir.
2ï¸âƒ£.2ï¸âƒ£ Seyrek Modeller (Sparse Models):

L1, seyrek (sparse) bir model oluÅŸturur. Bu, daha az bellek kullanÄ±mÄ± ve daha hÄ±zlÄ± tahmin anlamÄ±na gelir.
3ï¸âƒ£.3ï¸âƒ£ AÅŸÄ±rÄ± Ã–ÄŸrenmeyi (Overfitting) Ã–nleme:

Ã–zellikle Ã§ok boyutlu (high-dimensional) veri setlerinde modelin genelleme yeteneÄŸini artÄ±rÄ±r.

ðŸš« Neden L2 KullanÄ±lmadÄ±?

L2 (Ridge Regularization) gÃ¼Ã§lÃ¼ bir dÃ¼zenlileÅŸtirme yÃ¶ntemi olsa da, bazÄ± durumlarda uygun bir tercih olmayabilir. Ä°ÅŸte nedenleri:

ðŸŸ¡ 1. Ã–zellik SeÃ§imi YapÄ±lamamasÄ±:
L2, tÃ¼m Ã¶zelliklerin katsayÄ±larÄ±nÄ± kÃ¼Ã§Ã¼ltÃ¼r ancak hiÃ§birini sÄ±fÄ±ra indirmez.
EÄŸer veri setinde gereksiz Ã¶zellikler veya gÃ¼rÃ¼ltÃ¼lÃ¼ veriler varsa, L2 bu Ã¶zellikleri tamamen devre dÄ±ÅŸÄ± bÄ±rakmaz.
Bu durumda L1 daha etkili olur, Ã§Ã¼nkÃ¼ gereksiz Ã¶zellikleri tamamen ortadan kaldÄ±rÄ±r.


ðŸ†š L1 ve L2 FarkÄ±nÄ±n Ã–zet Tablosu:


Ã–zellik					L1 (Lasso)		    L2 (Ridge)

AmaÃ§				Gereksiz Ã¶zellikleri sÄ±fÄ±rlamak	Koefisiyentleri kÃ¼Ã§Ã¼ltmek
Ã–zellik SeÃ§imi				âœ… Var			âŒ Yok
Multicollinearity			Daha etkili Ã§Ã¶zÃ¼m			Ã–zellikleri kÃ¼Ã§Ã¼ltÃ¼r ama tutar
Model YorumlanabilirliÄŸi			âœ… YÃ¼ksek	         âŒ DÃ¼ÅŸÃ¼k
Ã‡oklu SÄ±nÄ±f (OvR)				âœ… Ä°yi		         ðŸŸ¡ Orta 
BÃ¼yÃ¼k Veri DesteÄŸi (saga ile)		âœ… Ã‡ok Ä°yi	         ðŸŸ¡ Orta


5ï¸âƒ£ C (Regularization Strength)
C parametresi, regularization gÃ¼cÃ¼nÃ¼ kontrol eder. DÃ¼ÅŸÃ¼k C deÄŸeri, daha gÃ¼Ã§lÃ¼ regularization anlamÄ±na gelir, yani model daha basitleÅŸir. YÃ¼ksek C deÄŸeri ise daha az regularization ve daha fazla esneklik saÄŸlar.

KÃ¼Ã§Ã¼k C â†’ Model daha basitleÅŸir, overfitting engellenir.
BÃ¼yÃ¼k C â†’ Model daha karmaÅŸÄ±k olur, overfitting riski artar.
Neden C=1 kullanÄ±ldÄ±?

Bu deÄŸeri logaritmik bir aralÄ±kta (Ã¶rneÄŸin, np.logspace) geniÅŸletmek genellikle daha iyi sonuÃ§lar verir. C=1 genellikle baÅŸlangÄ±Ã§ iÃ§in uygun bir seÃ§imdir.
6ï¸âƒ£ tol (Tolerance)
tol parametresi, modelin optimizasyonunun sonlanmasÄ± iÃ§in kabul edilen hata toleransÄ±nÄ± belirler.

KÃ¼Ã§Ã¼k tol deÄŸeri, daha hassas bir optimizasyon saÄŸlar, ancak daha fazla zaman alabilir.
Neden tol=1e-4 kullanÄ±ldÄ±?

Ã‡oÄŸu durumda bu deÄŸer yeterli olur ve modelin eÄŸitim sÃ¼recini makul bir ÅŸekilde sonlandÄ±rÄ±r.
7ï¸âƒ£ warm_start
warm_start, Ã¶nceki modelin sonuÃ§larÄ±nÄ± kullanarak eÄŸitime devam etmek iÃ§in kullanÄ±lÄ±r.

True: EÄŸitilen modelin sonuÃ§larÄ± bir sonraki iterasyona aktarÄ±lÄ±r.
False: Model sÄ±fÄ±rdan baÅŸlar.
Neden warm_start=False kullanÄ±ldÄ±?

Modelin sÄ±fÄ±rdan Ã¶ÄŸrenmesi istendi, bÃ¶ylece her seferinde yeni baÅŸtan baÅŸlar ve farklÄ± parametrelerle daha gÃ¼venilir sonuÃ§lar elde edilir.
Ã–zet:
'saga' solver'Ä± bÃ¼yÃ¼k veri setlerinde iyi Ã§alÄ±ÅŸÄ±r.
'ovr' Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma iÃ§in yaygÄ±n bir tercihtir.
max_iter=5000 iterasyon sayÄ±sÄ± daha bÃ¼yÃ¼k veri setlerinde modelin daha iyi optimizasyon yapmasÄ±nÄ± saÄŸlar.
penalty='l2' ve C=1 genellikle dengeli sonuÃ§lar verir.
Hangi parametrelerin kullanÄ±lacaÄŸÄ±nÄ± belirlemek, modelin genel doÄŸruluÄŸu ve performansÄ±nÄ± etkileyebilir.









			


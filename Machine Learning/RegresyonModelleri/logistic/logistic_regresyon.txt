Lojistik Regresyon Neden KullanÄ±lÄ±r? ğŸ¤”

Ä°kili SÄ±nÄ±flandÄ±rma (Binary Classification):
ğŸ“¨ â¡ï¸ ğŸ’» Spam / Spam DeÄŸil
ğŸ’” â¡ï¸ â¤ï¸ HastalÄ±k / SaÄŸlÄ±k

OlasÄ±lÄ±k Verir:
ğŸ¤” â¡ï¸ %70 (Evet, spam) / %30 (HayÄ±r, spam deÄŸil)

Basit ve Yorumlanabilir:
ğŸ¯ AÄŸÄ±rlÄ±klar (weights) ile neyin Ã¶nemli olduÄŸunu aÃ§Ä±kÃ§a gÃ¶rÃ¼rsÃ¼nÃ¼z:
ğŸ” YaÅŸ, Gelir gibi Ã¶zelliklerin etkilerini anlamak kolay.

HÄ±zlÄ± ve Verimli:
âš¡ï¸ KÃ¼Ã§Ã¼k Veri Setleri veya BÃ¼yÃ¼k Veri Setleri iÃ§in uygun.

Ã‡oklu SÄ±nÄ±f Problemleri:
ğŸ / ğŸŒ / ğŸ‰ Elma, Muz, Kavun gibi seÃ§enekler arasÄ±ndan hangisi?
â¡ï¸ Softmax ile Ã§Ã¶zÃ¼lebilir.

Ã–zetle:
Lojistik regresyon, ikili kararlar verirken ve olasÄ±lÄ±klarÄ± tahmin ederken oldukÃ§a pratik ve anlaÅŸÄ±lÄ±r bir yÃ¶ntemdir! ğŸ¯

Bu regresyon modelinde gÃ¶rselleÅŸtirmeye biraz daha dikkat etmemiz gerekli.Hangi deÄŸerin ne kadar neyi etkilediÄŸi gÃ¶z Ã¶nÃ¼ne sermek logistic regresyon iÃ§in gÃ¼zel bir uygulama olacaktÄ±r.

**********************************************************************

  		     --  GÃ–RSELLEÅTÄ°RME --
ğŸ“ŠğŸ”¥ IsÄ± HaritasÄ± ZamanÄ±!

plt.figure(figsize=(7,8))
sns.heatmap(df.corr() , annot=True)

Kodun yaptÄ±ÄŸÄ±:

ğŸ–¼ï¸ plt.figure(figsize=(7,8)) â†’ Grafik boyutunu 7x8 inÃ§ olarak ayarlar.
ğŸŒ¡ï¸ sns.heatmap(df.corr(), annot=True) â†’ ğŸ“Š Korelasyon matrisi iÃ§in Ä±sÄ± haritasÄ± oluÅŸturur.
ğŸ” df.corr() â†’ Verilerin korelasyonlarÄ±nÄ± hesaplar.
ğŸ“ annot=True â†’ HÃ¼crelere sayÄ±sal deÄŸerleri ekler.
ğŸ’¡ SonuÃ§: Verilerin birbirleriyle olan iliÅŸkisini renkli ve okunaklÄ± bir ÅŸekilde gÃ¶steren bir grafik elde edilir! ğŸ¨âœ¨


ğŸ“Šâœ¨ DaÄŸÄ±lÄ±m GrafiÄŸi ZamanÄ±!

sns.scatterplot(x="HP" , y="Legendary" , data=df) 

Kodun yaptÄ±ÄŸÄ±:
ğŸ“ˆ DaÄŸÄ±lÄ±m grafiÄŸi (scatter plot) oluÅŸturur.
ğŸ·ï¸ x="Total" â†’ X eksenine Total sÃ¼tununu koyar.
ğŸ·ï¸ y="Legendary" â†’ Y eksenine Legendary sÃ¼tununu koyar.
ğŸ“Š data=df â†’ df adlÄ± veri Ã§erÃ§evesinden (DataFrame) verileri kullanÄ±r.
ğŸ’¡ SonuÃ§: Her veri noktasÄ±nÄ± bir nokta olarak gÃ¶steren bir grafik elde edilir. Veriler arasÄ±ndaki iliÅŸkileri analiz etmeye yardÄ±mcÄ± olur! ğŸ”ğŸ¯

ğŸ“ŠğŸ‰ Scatter Plot ile Veri KeÅŸfi!

sns.scatterplot(x="HP" , y="Legendary" , data=df) 

Kodun yaptÄ±ÄŸÄ±:

sns.scatterplot(x="HP", y="Legendary", data=df)
ğŸ”µ HP (Can DeÄŸeri) ile Efsanevi Olma Durumu arasÄ±ndaki iliÅŸkiyi gÃ¶sterir.
ğŸ·ï¸ x="HP" â†’ X ekseninde PokÃ©mon'un HP (Can PuanÄ±) yer alÄ±r.
ğŸ·ï¸ y="Legendary" â†’ Y ekseninde PokÃ©mon'un Efsanevi olup olmadÄ±ÄŸÄ± (Legendary: 0 veya 1) gÃ¶sterilir.
ğŸ“Š data=df â†’ Veriler df adlÄ± DataFrame'den alÄ±nÄ±r.
ğŸ’¡ SonuÃ§:

Efsanevi PokÃ©monâ€™larÄ±n (Legendary = 1) HPâ€™si yÃ¼ksek mi? ğŸ›¡ï¸
Normal PokÃ©monâ€™lar (Legendary = 0) genellikle hangi HP aralÄ±ÄŸÄ±nda? ğŸ“
Belirgin bir daÄŸÄ±lÄ±m var mÄ±? ğŸ“‰ğŸ“ˆ


ğŸ› Bar Plot ile Veriler

sns.barplot(x=coef.index, y=coef.values, palette="bright")

ğŸ“Š Ã–zelliklerin model Ã¼zerindeki etkisini gÃ¶rselleÅŸtirir.
ğŸ¯ En bÃ¼yÃ¼k pozitif katsayÄ±lar = Efsanevi olmayÄ± en Ã§ok etkileyen Ã¶zellikler
ğŸ”» En bÃ¼yÃ¼k negatif katsayÄ±lar = Efsanevi olmamayÄ± etkileyen Ã¶zellikler

**********************************************************************
		      -- TRAÄ°N TEST SPLÄ°T --
ğŸ›  Kod AÃ§Ä±klamasÄ± AdÄ±m AdÄ±m

1ï¸âƒ£ Veriyi HazÄ±rlama
x = df.drop("Legendary", axis=1)  # 'Legendary' sÃ¼tununu Ã§Ä±kararak baÄŸÄ±msÄ±z deÄŸiÅŸkenleri belirler
y = df["Legendary"]  # 'Legendary' sÃ¼tununu baÄŸÄ±mlÄ± deÄŸiÅŸken (etiket) olarak atar
x.iloc[3:8]  # 3. ve 8. indeksler arasÄ±ndaki deÄŸerleri getirir.

ğŸ“Œ AmaÃ§:
X (BaÄŸÄ±msÄ±z deÄŸiÅŸkenler): PokÃ©monâ€™un istatistikleri (HP, Attack, Speed vb.)
Y (BaÄŸÄ±mlÄ± deÄŸiÅŸken): PokÃ©monâ€™un efsanevi olup olmadÄ±ÄŸÄ± (1 = Efsanevi, 0 = Normal)

2ï¸âƒ£ Train-Test Split (Veriyi BÃ¶lme)
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X_train, X_test, y_train, y_test = train_test_split(
    x, y, test_size=0.4, random_state=9)
ğŸ”¹ test_size=0.4 â†’ Verinin %40'Ä± test, %60'Ä± eÄŸitim iÃ§in ayrÄ±ldÄ±
ğŸ”¹ random_state=9 â†’ Tekrar Ã¼retilebilirlik iÃ§in sabit rastgelelik saÄŸlandÄ±

3ï¸âƒ£ Veriyi Ã–lÃ§eklendirme ğŸ”¢
scaler = StandardScaler()  # StandardScaler nesnesi oluÅŸtur
scaled_X_train = scaler.fit_transform(X_train)  # X_train verisini Ã¶lÃ§eklendir (mean=0, std=1)
scaled_X_test = scaler.transform(X_test)  # X_test verisini aynÄ± dÃ¶nÃ¼ÅŸÃ¼mle Ã¶lÃ§eklendir

ğŸ“Œ Neden gerekli?
BazÄ± sÃ¼tunlar (HP, Attack) bÃ¼yÃ¼k, bazÄ±larÄ± kÃ¼Ã§Ã¼k olabilir.
Lojistik Regresyon gibi modeller, Ã¶lÃ§eklendirilmemiÅŸ verilerde kÃ¶tÃ¼ performans gÃ¶sterir.
StandardScaler ğŸ“, tÃ¼m Ã¶zellikleri ortalamasÄ± 0, standart sapmasÄ± 1 olacak ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

4ï¸âƒ£ Lojistik Regresyon Modelini EÄŸitme ğŸ¤–
from sklearn.linear_model import LogisticRegression
log_model = LogisticRegression()  # Modeli oluÅŸtur
log_model.fit(scaled_X_train, y_train)  # Modeli eÄŸit

ğŸ“Œ Lojistik Regresyon nedir?

Ã‡Ä±ktÄ±sÄ± 0-1 aralÄ±ÄŸÄ±nda bir olasÄ±lÄ±k verir (Binary Classification iÃ§in uygun).
PokÃ©monâ€™un efsanevi olup olmadÄ±ÄŸÄ±nÄ± tahmin etmeye Ã§alÄ±ÅŸÄ±r.

5ï¸âƒ£ Modelin KatsayÄ±larÄ±nÄ± Analiz Etme ğŸ“Š
log_model.coef_
ğŸ”¹ Her Ã¶zelliÄŸin modele etkisini gÃ¶steren katsayÄ±larÄ± Ã§Ä±karÄ±r.
ğŸ”¹ KatsayÄ±lar pozitifse, Ã¶zellik efsanevi olma olasÄ±lÄ±ÄŸÄ±nÄ± artÄ±rÄ±r.
ğŸ”¹ KatsayÄ±lar negatifse, Ã¶zellik efsanevi olma olasÄ±lÄ±ÄŸÄ±nÄ± azaltÄ±r.

coef = pd.Series(index=x.columns, data=log_model.coef_[0])
ğŸ“Œ Seri olarak katsayÄ±larÄ± oluÅŸturur ve Ã¶zellik isimlerini indeks olarak kullanÄ±r.

6ï¸âƒ£ KatsayÄ±larÄ± KÃ¼Ã§Ã¼kten BÃ¼yÃ¼ÄŸe SÄ±ralama ğŸ“‰
coef.sort_values(inplace=True)
ğŸ”¹ Hangi Ã¶zelliklerin en Ã¶nemli olduÄŸunu gÃ¶rmek iÃ§in sÄ±ralama yapar

7ï¸âƒ£ Ã–zelliklerin Etkisini GÃ¶rselleÅŸtirme ğŸ¨
sns.barplot(x=coef.index, y=coef.values, palette="bright")

ğŸ“Œ Barplot Ne Ä°ÅŸe Yarar?
ğŸ“Š Ã–zelliklerin model Ã¼zerindeki etkisini gÃ¶rselleÅŸtirir.
ğŸ¯ En bÃ¼yÃ¼k pozitif katsayÄ±lar = Efsanevi olmayÄ± en Ã§ok etkileyen Ã¶zellikler
ğŸ”» En bÃ¼yÃ¼k negatif katsayÄ±lar = Efsanevi olmamayÄ± etkileyen Ã¶zellikler

ğŸ¯ Ã–zet:
1ï¸âƒ£ Veri hazÄ±rlanÄ±r (Legendary sÃ¼tunu ayrÄ±lÄ±r).
2ï¸âƒ£ EÄŸitim ve test setlerine bÃ¶lÃ¼nÃ¼r (%60 train, %40 test).
3ï¸âƒ£ Ã–zellikler StandardScaler ile Ã¶lÃ§eklendirilir.
4ï¸âƒ£ Lojistik regresyon modeli eÄŸitilir.
5ï¸âƒ£ Ã–zelliklerin Ã¶nem derecesi analiz edilir.
6ï¸âƒ£ SonuÃ§lar barplot ile gÃ¶rselleÅŸtirilir.

**********************************************************************
			-- PERFORMANS METRÄ°KLERÄ° --

ğŸ“Šâœ¨ Lojistik Regresyon Modelinin Performans Analizi! ğŸš€

ğŸ” Kod AÃ§Ä±klamasÄ± AdÄ±m AdÄ±m

1ï¸âƒ£ Performans Ã–lÃ§Ã¼mleri Ä°Ã§in Gerekli KÃ¼tÃ¼phaneleri Ä°Ã§e Aktarma

from sklearn.metrics import accuracy_score, confusion_matrix 
from sklearn.metrics import ConfusionMatrixDisplay, classification_report

ğŸ“Œ Bu kÃ¼tÃ¼phaneler ne iÅŸe yarar?
accuracy_score â†’ Modelin doÄŸruluk oranÄ±nÄ± hesaplar. ğŸ¯
confusion_matrix â†’ GerÃ§ek vs. tahmin edilen deÄŸerleri karÅŸÄ±laÅŸtÄ±ran bir matris oluÅŸturur. ğŸ”¢
ConfusionMatrixDisplay â†’ KarmaÅŸÄ±klÄ±k matrisini grafik olarak gÃ¶sterir. ğŸ“Š
classification_report â†’ Precision, recall ve F1-score gibi metrikleri iÃ§erir. ğŸ“

# Precision = Benim tahmin ettiklerimden kaÃ§Ä± doÄŸru
# Recall = DoÄŸru olanlardan ben kaÃ§Ä±nÄ± tahmin edebildim

2ï¸âƒ£ Test Verisi Ãœzerinde Tahmin Yapma
legend_pred = log_model.predict(scaled_X_test)

ğŸ“Œ Ne yapÄ±yor?
log_model.predict(scaled_X_test) â†’ Test setindeki PokÃ©monâ€™lar iÃ§in efsanevi olup olmadÄ±ÄŸÄ±nÄ± tahmin eder.
SonuÃ§: legend_pred â†’ 0 (normal PokÃ©mon) veya 1 (efsanevi PokÃ©mon) olarak tahmin edilen deÄŸerler

3ï¸âƒ£ Modelin DoÄŸruluk OranÄ±nÄ± Hesaplama
accuracy_score(y_test, legend_pred)

ğŸ“Œ DoÄŸruluk OranÄ± (Accuracy Score) Nedir?
DoÄŸru Tahminler / BÃ¼tÃ¼n Tahminler
â€‹
1.0 (100%) â†’ Model tÃ¼m tahminleri doÄŸru yapmÄ±ÅŸ ğŸ¯
0.5 (50%) â†’ Model rastgele tahmin yapÄ±yor olabilir ğŸ¤”
0.0 (0%) â†’ Model tamamen yanlÄ±ÅŸ tahminler yapÄ±yor âŒ

4ï¸âƒ£ KarmaÅŸÄ±klÄ±k Matrisi (Confusion Matrix) OluÅŸturma
confusion_matrix(y_test, legend_pred)

ğŸ“Œ KarmaÅŸÄ±klÄ±k Matrisi Nedir?
Bir sÄ±nÄ±flandÄ±rma modelinin doÄŸru ve yanlÄ±ÅŸ tahminlerini tablo halinde gÃ¶sterir.
Matris ÅŸu ÅŸekilde olur:

	   Tahmin Edilen 0	   Tahmin Edilen 1
GerÃ§ek 0	TN (DoÄŸru Negatif) âœ…	FP (YanlÄ±ÅŸ Pozitif) âŒ
GerÃ§ek 1	FN (YanlÄ±ÅŸ Negatif) âŒ	TP (DoÄŸru Pozitif) âœ…

ğŸ“Œ Terimler AÃ§Ä±klamasÄ±:

TN (True Negative) â†’ Normal PokÃ©monâ€™u doÄŸru tahmin etti âœ…
TP (True Positive) â†’ Efsanevi PokÃ©monâ€™u doÄŸru tahmin etti âœ…
FP (False Positive) â†’ Normal PokÃ©monâ€™a yanlÄ±ÅŸlÄ±kla "efsanevi" dedi âŒ
FN (False Negative) â†’ Efsanevi PokÃ©monâ€™a yanlÄ±ÅŸlÄ±kla "normal" dedi âŒ

******************************************************************* 

print(classification_report(y_test  , legend_pred)) kodu aÃ§Ä±klamasÄ± ;


              precision    recall  f1-score   support

           0       0.85      0.90      0.87       150
           1       0.88      0.80      0.84       100

    accuracy                           0.86       250
   macro avg       0.86      0.85      0.85       250
weighted avg       0.86      0.86      0.86       250

AÃ§Ä±klamalar:

# Precision = Benim tahmin ettiklerimden kaÃ§Ä± doÄŸru
# Recall = DoÄŸru olanlardan ben kaÃ§Ä±nÄ± tahmin edebildim

1ï¸âƒ£ Precision (Hassasiyet) - ğŸ¯
0 sÄ±nÄ±fÄ± iÃ§in 0.85: "Normal PokÃ©mon" tahminlerinde modelin ne kadar doÄŸru olduÄŸu. Yani, modelin "Normal" dediÄŸi PokÃ©monâ€™larÄ±n %85'i gerÃ§ekten normal.

1 sÄ±nÄ±fÄ± iÃ§in 0.88: "Efsanevi PokÃ©mon" tahminlerinde modelin ne kadar doÄŸru olduÄŸu. Yani, modelin "Efsanevi" dediÄŸi PokÃ©monâ€™larÄ±n %88'i gerÃ§ekten efsanevi.


2ï¸âƒ£ Recall (DuyarlÄ±lÄ±k) - ğŸ”
0 sÄ±nÄ±fÄ± iÃ§in 0.90: GerÃ§ek "Normal PokÃ©mon"larÄ±n %90'Ä±nÄ± doÄŸru tahmin etti. Yani, model normal PokÃ©monâ€™larÄ± %90 oranÄ±nda doÄŸru yakaladÄ±.

1 sÄ±nÄ±fÄ± iÃ§in 0.80: GerÃ§ek "Efsanevi PokÃ©mon"larÄ±n %80'ini doÄŸru tahmin etti. Yani, model efsanevi PokÃ©monâ€™larÄ±n %80'ini doÄŸru yakaladÄ±.

3ï¸âƒ£ F1-Score (Harmonik Ortalama) - 
0 sÄ±nÄ±fÄ± iÃ§in 0.87: Precision ve Recall arasÄ±nda dengeyi saÄŸlamak iÃ§in hesaplanan skor. Ä°yi bir dengeyi gÃ¶steriyor.

1 sÄ±nÄ±fÄ± iÃ§in 0.84: Efsanevi PokÃ©mon'lar iÃ§in de benzer ÅŸekilde, modelin genel performansÄ±nÄ± gÃ¶steriyor.

4ï¸âƒ£ Support (Destek) - ğŸ’ª
0 iÃ§in 150: 150 "Normal PokÃ©mon" Ã¶rneÄŸi.
1 iÃ§in 100: 100 "Efsanevi PokÃ©mon" Ã¶rneÄŸi.

5ï¸âƒ£ Accuracy (DoÄŸruluk) - âœ…
0.86: Modelin genel doÄŸruluk oranÄ±. Yani, test verisinin %86â€™sÄ±nÄ± doÄŸru tahmin etti.

6ï¸âƒ£ Macro Average (Makro Ortalama) - ğŸŒ
0.86: TÃ¼m sÄ±nÄ±flarÄ±n Precision, Recall ve F1 skorlarÄ±nÄ±n ortalamalarÄ±, her sÄ±nÄ±fa eÅŸit aÄŸÄ±rlÄ±k verir.

7ï¸âƒ£ Weighted Average (AÄŸÄ±rlÄ±klÄ± Ortalama) - âš–ï¸ğŸŒ
0.86: Her sÄ±nÄ±fÄ±n Ã¶rnek sayÄ±sÄ±na gÃ¶re aÄŸÄ±rlÄ±klÄ± ortalama. Bu, modelin genel performansÄ±nÄ± daha dengeli ÅŸekilde Ã¶lÃ§er.

ğŸ¯ SonuÃ§:
Precision ve Recall deÄŸerleri, modelin her sÄ±nÄ±fÄ± ne kadar doÄŸru tahmin ettiÄŸini gÃ¶steriyor.
F1-Score, Precision ve Recallâ€™un dengeli olup olmadÄ±ÄŸÄ±nÄ± gÃ¶steriyor.
Accuracy modelin genel doÄŸruluÄŸunu yansÄ±tÄ±yor.

****************************************************************************************************
		ğŸ“Š Yeni Metrikler ile Performans Analizi ğŸ“Š

1ï¸âƒ£ Precision-Recall EÄŸrisi ile Analiz ğŸ“‰

from sklearn.metrics import PrecisionRecallDisplay

# Precision-Recall eÄŸrisini Ã§izdiriyoruz
PrecisionRecallDisplay.from_estimator(log_model, scaled_X_test, y_test)
Precision ve Recall metriklerini daha iyi analiz etmek iÃ§in Precision-Recall eÄŸrisini Ã§izebiliriz. Bu eÄŸri, modelin farklÄ± karar eÅŸiklerinde precision ve recall deÄŸerlerinin nasÄ±l deÄŸiÅŸtiÄŸini gÃ¶sterir.

Precision (Hassasiyet): Modelin pozitif tahminlerinden ne kadarÄ±nÄ±n doÄŸru olduÄŸunu gÃ¶sterir. (Yani, modelin "efsanevi PokÃ©mon" dediÄŸi PokÃ©mon'larÄ±n ne kadarÄ±nÄ±n gerÃ§ekten efsanevi olduÄŸunu gÃ¶sterir.)

Recall (DuyarlÄ±lÄ±k): GerÃ§ek pozitif Ã¶rneklerin ne kadarÄ±nÄ± doÄŸru tahmin ettiÄŸini gÃ¶sterir. (Yani, gerÃ§ekten efsanevi PokÃ©mon olanlardan modelin kaÃ§Ä±nÄ± doÄŸru tahmin ettiÄŸini gÃ¶sterir.)

Bu eÄŸri, modelin ne kadar iyi olduÄŸunu gÃ¶sterir. EÄŸrinin saÄŸ Ã¼st kÃ¶ÅŸesi, yÃ¼ksek precision ve recall deÄŸerlerini temsil eder, yani model doÄŸru ve Ã§ok fazla pozitif tahmin yapÄ±yordur. Daha aÅŸaÄŸÄ±da ve sola kayarsa, modelin performansÄ±nÄ±n kÃ¶tÃ¼ olduÄŸunu gÃ¶sterir.

2ï¸âƒ£ ROC EÄŸrisi ile Analiz ğŸ“Š

from sklearn.metrics import RocCurveDisplay

# ROC eÄŸrisini Ã§izdiriyoruz
RocCurveDisplay.from_estimator(log_model, scaled_X_test, y_test)

ROC EÄŸrisi (Receiver Operating Characteristic) ve AUC (Area Under the Curve), modelin performansÄ±nÄ± farklÄ± karar eÅŸiklerinde analiz etmeye olanak tanÄ±r.

True Positive Rate (TPR), Recall ile aynÄ±dÄ±r ve gerÃ§ek pozitif Ã¶rneklerin doÄŸru tahmin edilme oranÄ±dÄ±r.
False Positive Rate (FPR), gerÃ§ek negatif Ã¶rneklerin yanlÄ±ÅŸlÄ±kla pozitif olarak tahmin edilme oranÄ±dÄ±r.
ROC EÄŸrisi, modelin False Positive Rate (FPR) ile True Positive Rate (TPR) arasÄ±ndaki dengeyi gÃ¶rselleÅŸtirir. EÄŸrinin Ã¼st kÄ±smÄ±nda olmak, modelin iyi performans gÃ¶sterdiÄŸini ifade eder. AUC (Area Under the Curve) deÄŸeri modelin genel doÄŸruluÄŸunu gÃ¶sterir:

AUC = 1: MÃ¼kemmel performans ğŸ¯
AUC = 0.5: Model rastgele tahmin yapÄ±yor âŒ
AUC < 0.5: Modelin tahminleri Ã§ok kÃ¶tÃ¼ ğŸš«

*****************************************************************************************************

5ï¸âƒ£ KarmaÅŸÄ±klÄ±k Matrisini GÃ¶rselleÅŸtirme
ConfusionMatrixDisplay.from_estimator(log_model, scaled_X_test, y_test)

ğŸ“Œ Ne yapÄ±yor?
Modelin tahmin ettiÄŸi deÄŸerler ile gerÃ§ek deÄŸerleri karÅŸÄ±laÅŸtÄ±rÄ±yor.
Matris grafiÄŸi olarak gÃ¶steriyor, bÃ¶ylece hangi sÄ±nÄ±flarda hata yapÄ±ldÄ±ÄŸÄ±nÄ± daha iyi anlayabiliyoruz. 

ğŸ¯ Ã–zet:
1ï¸âƒ£ Test verisiyle tahmin yapÄ±lÄ±r â†’ log_model.predict(scaled_X_test)
2ï¸âƒ£ DoÄŸruluk oranÄ± hesaplanÄ±r â†’ accuracy_score(y_test, legend_pred)
3ï¸âƒ£ KarmaÅŸÄ±klÄ±k matrisi oluÅŸturulur â†’ confusion_matrix(y_test, legend_pred)
4ï¸âƒ£ Matris grafik olarak gÃ¶rselleÅŸtirilir â†’ ConfusionMatrixDisplay.from_estimator(...)

*****************************************************************************************************
			- ğŸ•¹ï¸ğŸ“Š Yeni PokÃ©mon Tahmin ve Ã–lÃ§eklendirme - ğŸ•¹ï¸ğŸ“Š

poke_1 = [[620 , 150 , 130 , 150 , 170,100,160,2]]

ğŸ”¢ PokÃ©mon Ã–zellikleri:
Bu satÄ±rda bir PokÃ©mon'un Ã¶zellikleri liste ÅŸeklinde tanÄ±mlanÄ±yor. Bu PokÃ©monâ€™un sayÄ±sal verilerini iÃ§eriyor.

620: PokÃ©mon'un CP veya toplam gÃ¼cÃ¼. âš¡
150: SaldÄ±rÄ± gÃ¼cÃ¼. âš”ï¸
130: Savunma gÃ¼cÃ¼. ğŸ›¡ï¸
150: HÄ±z veya dayanÄ±klÄ±lÄ±k gibi baÅŸka bir Ã¶zellik. ğŸš€
170: PokÃ©monâ€™un saÄŸlÄ±k veya benzeri bir Ã¶zelliÄŸi. â¤ï¸
100: DiÄŸer bir Ã¶zellik. ğŸ’ª
160: PokÃ©monâ€™un Ã¶zel yeteneklerinden biri. ğŸŒŸ
2: PokÃ©monâ€™un sÄ±nÄ±fÄ± (efsanevi ya da normal). ğŸ”®
Bu deÄŸerler, PokÃ©monâ€™un Ã§eÅŸitli niteliklerine ait sayÄ±sal Ã¶zellikler.


poke_scaled_1 = scaler.transform(poke_1)

ğŸ”§ Ã–lÃ§eklendirme:
Burada scaler nesnesi, verinin normalizasyon veya standartlaÅŸtÄ±rma iÅŸlemi iÃ§in kullanÄ±lÄ±yor.

Bu iÅŸlem, verilerin farklÄ± Ã¶lÃ§eklerde olmasÄ±ndan kaynaklanabilecek hatalarÄ± engeller.
scaler.transform(poke_1) komutu, poke_1 listesindeki sayÄ±sal verileri eÄŸitim verisinde kullanÄ±lan Ã¶lÃ§eklendirme yÃ¶ntemine gÃ¶re yeniden Ã¶lÃ§eklendiriyor. ğŸ“‰

log_model.predict(poke_scaled_1)

ğŸ”® Tahmin Yapma:
SonrasÄ±nda, log_model isimli lojistik regresyon modelini kullanarak tahmin yapÄ±yorsun.

poke_scaled_1 ile Ã¶lÃ§eklendirilmiÅŸ olan PokÃ©mon verisi, modelin girdiÄŸi ve model tahmin yapÄ±yor.
Modelin sonucuna gÃ¶re:
1 dÃ¶nerse, PokÃ©mon efsanevi demektir. ğŸŒŸ
0 dÃ¶nerse, PokÃ©mon normal demektir. ğŸ¾

Ã–zet:
Bu kod, bir PokÃ©mon'un Ã¶zelliklerini modele verip, efsanevi olup olmadÄ±ÄŸÄ±nÄ± tahmin etmek iÃ§in kullanÄ±lÄ±yor. Model, verileri doÄŸru ÅŸekilde Ã¶lÃ§eklendirip, tahmin sonucunu 0 veya 1 olarak dÃ¶ndÃ¼rÃ¼yor. EÄŸer model 1 dÃ¶nerse, PokÃ©mon efsanevi olduÄŸunu belirtiyor! ğŸ‰

*****************************************************************************************************

			- ğŸ§‘â€ğŸš€ğŸ”® PokÃ©mon OlasÄ±lÄ±ÄŸÄ± ve Tahmin - ğŸ§‘â€ğŸš€ğŸ”®

log_model.predict_proba(poke_scaled_1)[0, 1] * 100
ğŸ” predict_proba ile OlasÄ±lÄ±k Hesaplama:
Bu satÄ±rda predict_proba fonksiyonu, PokÃ©mon'un efsanevi olma olasÄ±lÄ±ÄŸÄ±nÄ± hesaplamak iÃ§in kullanÄ±lÄ±yor.

poke_scaled_1: Bu, daha Ã¶nce Ã¶lÃ§eklendirdiÄŸimiz PokÃ©mon verisidir.
predict_proba fonksiyonu, modelin her iki sÄ±nÄ±f iÃ§in olasÄ±lÄ±klarÄ±nÄ± dÃ¶ndÃ¼rÃ¼yor. Yani:
SÄ±nÄ±f 0 (normal PokÃ©mon) olma olasÄ±lÄ±ÄŸÄ±,
SÄ±nÄ±f 1 (efsanevi PokÃ©mon) olma olasÄ±lÄ±ÄŸÄ±.
[0, 1]: Bu, efsanevi PokÃ©mon olma olasÄ±lÄ±ÄŸÄ±nÄ± (1. sÄ±nÄ±f) alÄ±yoruz.
* 100: OlasÄ±lÄ±ÄŸÄ± yÃ¼zde cinsinden almak iÃ§in Ã§arpÄ±yoruz.
ğŸ§‘â€ğŸ”¬ Ã–rnek Durum:
EÄŸer bu deÄŸer 95 dÃ¶nerse, bu PokÃ©mon'un efsanevi olma olasÄ±lÄ±ÄŸÄ± %95'tir! ğŸŒŸ

*****************************************************************************************************

				- ğŸ” YanlÄ±ÅŸ Tahminler Tespiti - ğŸ”

wrong = (y_test != legend_pred)

âŒ HatalÄ± Tahminlerin Belirlenmesi:
Bu satÄ±r, gerÃ§ek sÄ±nÄ±f (y_test) ile tahmin edilen sÄ±nÄ±f (legend_pred) arasÄ±ndaki farklarÄ± kontrol eder.

True: YanlÄ±ÅŸ tahmin edilmiÅŸ PokÃ©mon.
False: DoÄŸru tahmin edilmiÅŸ PokÃ©mon.

wrong_df = pd.DataFrame(wrong)

ğŸ“Š HatalÄ± Tahminleri DataFrameâ€™e DÃ¶nÃ¼ÅŸtÃ¼rme:
Burada, wrong (yanlÄ±ÅŸ tahminler) bir liste ya da diziyi DataFrame formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz. Bu, daha kolay analiz yapmamÄ±zÄ± saÄŸlar.


wrong_df

ğŸ” HatalÄ± Tahminlerin GÃ¶rÃ¼ntÃ¼lenmesi:
Bu satÄ±r, yanlÄ±ÅŸ tahmin edilen PokÃ©monâ€™larÄ± gÃ¶sterir. False olanlar doÄŸru tahmin edilmiÅŸ PokÃ©mon'lardÄ±r. ğŸ¯

wrong_df[wrong_df["Legendary"] == True]

ğŸ’¡ YanlÄ±ÅŸ Tahmin Edilen PokÃ©mon'larÄ± Bulma:
Bu satÄ±rda, yalnÄ±zca yanlÄ±ÅŸ tahmin edilen PokÃ©monâ€™larÄ± filtreliyoruz. Legendary sÃ¼tununda True olanlar, aslÄ±nda efsanevi olmasÄ± gereken PokÃ©mon'lardÄ±r, ancak model yanlÄ±ÅŸlÄ±kla normal olarak sÄ±nÄ±flandÄ±rmÄ±ÅŸ.

df.loc[[667, 737]]

ğŸ“œ YanlÄ±ÅŸ Tahmin Edilen PokÃ©monâ€™larÄ± DetaylÄ± Ä°nceleme:
Bu satÄ±rda, index 667 ve index 737 olan PokÃ©monâ€™larÄ±n Ã¶zelliklerini gÃ¶steriyoruz. Bu iki PokÃ©mon yanlÄ±ÅŸ tahmin edilenlerdir.

Ã–rnek 1 (Index 667):

PokÃ©mon efsanevi deÄŸilmiÅŸ, ancak model onu efsanevi olarak tahmin etmiÅŸ.
Ã–zellikler:
HP: 600
Attack: 71
Defense: 120
Sp. Atk: 95
Sp. Def: 120
Speed: 95
Generation: 5
Legendary: 0 (efsanevi deÄŸil)
Ã–rnek 2 (Index 737):

PokÃ©mon efsaneviymiÅŸ, ancak model onu normal olarak tahmin etmiÅŸ.
Ã–zellikler:
HP: 600
Attack: 108
Defense: 100
Sp. Atk: 121
Sp. Def: 81
Speed: 95
Generation: 6
Legendary: 1 (efsanevi)

Ã–zet:
1ï¸âƒ£ wrong deÄŸiÅŸkeni, doÄŸru ve yanlÄ±ÅŸ tahminleri kontrol eder. 2ï¸âƒ£ wrong_df DataFrame, yanlÄ±ÅŸ tahminlerin listelendiÄŸi yer. 3ï¸âƒ£ YanlÄ±ÅŸ tahmin edilen PokÃ©mon'lar efsanevi olmasÄ± gereken ama normal tahmin edilen ve normal olmasÄ± gereken ama efsanevi tahmin edilen PokÃ©mon'lardÄ±r. 4ï¸âƒ£ PokÃ©monâ€™larÄ±n Ã¶zellikleri veritabanÄ±nda detaylÄ±ca gÃ¶sterilir.


			------------ GENEL KODLAR --------------


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Veriyi yÃ¼kleyin
df = pd.read_csv("pokemon.csv")
df.head()

# Veride eksik deÄŸerler var mÄ± kontrol et
df.isna().any()
df.info()

# "Legendary" sÃ¼tununu 1/0 deÄŸerlerine dÃ¶nÃ¼ÅŸtÃ¼r
map_legend = {True: 1, False: 0}
df["Legendary"] = df["Legendary"].map(map_legend)

# "Type 1" sÃ¼tunundaki benzersiz deÄŸerler
df["Type 1"].unique()
df["Type 1"].nunique()

# Gereksiz sÃ¼tunlarÄ± Ã§Ä±kar
df.drop(["#", "Name", "Type 1", "Type 2"], axis=1, inplace=True)

# Verinin daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rselleÅŸtirme
sns.pairplot(df, hue="Legendary")
plt.figure(figsize=(7, 8))
sns.heatmap(df.corr(), annot=True)

# Ã–zellikler ve hedef deÄŸiÅŸken
x = df.drop("Legendary", axis=1)
y = df["Legendary"]

# EÄŸitim ve test verisi olarak ayÄ±r
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=9)

# Veriyi standartlaÅŸtÄ±r
scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

# Lojistik Regresyon modeli
from sklearn.linear_model import LogisticRegression

log_model = LogisticRegression()
log_model.fit(scaled_X_train, y_train)

# Modelin katsayÄ±larÄ±nÄ± gÃ¶rselleÅŸtirme
coef = pd.Series(index=x.columns, data=log_model.coef_[0])
coef.sort_values(inplace=True)
sns.barplot(x=coef.index, y=coef.values, palette="bright")

# Performans deÄŸerlendirmesi
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay, classification_report

legend_pred = log_model.predict(scaled_X_test)

# Model doÄŸruluÄŸunu ve sÄ±nÄ±flandÄ±rma raporunu yazdÄ±r
print(f"Accuracy: {accuracy_score(y_test, legend_pred)}")
print(classification_report(y_test, legend_pred))

# Konfizyon matrisi
ConfusionMatrixDisplay.from_estimator(log_model, scaled_X_test, y_test)

# Precision-Recall ve ROC eÄŸrisi
from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay
PrecisionRecallDisplay.from_estimator(log_model, scaled_X_test, y_test)
RocCurveDisplay.from_estimator(log_model, scaled_X_test, y_test)

# Yeni bir PokÃ©mon ile tahmin
poke_1 = [[620, 150, 130, 150, 170, 100, 160, 2]]
poke_scaled_1 = scaler.transform(poke_1)
print("Prediction:", log_model.predict(poke_scaled_1))  # PokÃ©mon efsanevi mi?
print("Probability:", log_model.predict_proba(poke_scaled_1)[0, 1] * 100)  # PokÃ©mon efsanevi olma olasÄ±lÄ±ÄŸÄ±

# HatalÄ± tahminler
wrong = (y_test != legend_pred)
wrong_df = pd.DataFrame(wrong)
wrong_df[wrong_df["Legendary"] == True]  # YanlÄ±ÅŸ tahmin edilen efsanevi PokÃ©mon'lar
df.loc[[667, 737]]  # YanlÄ±ÅŸ tahminler Ã¼zerinde analiz








		
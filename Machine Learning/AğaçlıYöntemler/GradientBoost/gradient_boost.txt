						🚀 Gradient Boosting: Güçlü Bir Makine Öğrenmesi Yöntemi 🚀

Gradient Boosting, denetimli öğrenme problemlerinde kullanılan güçlü bir topluluk (ensemble) öğrenme yöntemidir. Küçük hata oranları ve yüksek doğruluk seviyeleri ile öne çıkan bu algoritma, özellikle karmaşık veri setlerinde başarılı sonuçlar verir. Peki, Gradient Boosting neden kullanılır ve diğer yöntemlerden farkı nedir?

🤔 Gradient Boosting Neden Kullanılır? 🤔

Gradient Boosting, modelin hatalarını minimize etmek için ardışık karar ağaçlarını eğiten bir tekniktir. Hedefi, her bir ağaç ile önceki modelin tahmin hatalarını düzeltmektir.

Kullanım nedenleri şunlardır:
✔ Yüksek doğruluk: Karmaşık veri setlerinde bile başarılı tahminler yapabilir.
✔ Özelleştirilebilirlik: Öğrenme oranı, ağaç derinliği gibi parametreler üzerinde ince ayar yapılabilir.
✔ Aykırı değerlere dayanıklılık: Decision Tree tabanlı olduğu için outlier’lara karşı daha toleranslıdır.
✔ Özellik seçimi yapabilme: Model, en önemli özellikleri belirleyerek daha verimli tahminler yapabilir.

⚖️ AdaBoost ile Gradient Boosting Arasındaki Farklar ⚖️

Gradient Boosting, AdaBoost’a benzese de temel farkları şunlardır:

🔹 Hata Güncelleme Yöntemi: AdaBoost hataları ağırlıklandırarak güncellerken, Gradient Boosting hata miktarını gradyan iniş yöntemiyle minimize eder.
🔹 Daha Esnek Modelleme: Gradient Boosting, kayıp fonksiyonunu doğrudan optimize edebilir, AdaBoost ise genellikle sınıflandırma hataları üzerinden çalışır.
🔹 Ağaç Derinliği: AdaBoost genellikle sığ ağaçlarla çalışırken, Gradient Boosting daha derin ağaçlar kullanabilir.

						🏆Gradient Boosting + Grid Search: Mükemmel İkili 🏆

Gradient Boosting’in performansını artırmak için Grid Search kullanmak oldukça önemlidir. Grid Search, modelin hiperparametrelerini en iyi sonucu verecek şekilde ayarlamak için kullanılır.

💡 Grid Search neden önemli? 💡

✅ Öğrenme oranı, ağaç sayısı, maksimum derinlik gibi parametreleri optimize eder.
✅ Aşırı öğrenmeyi (overfitting) engelleyerek modelin genelleme yeteneğini artırır.
✅ Daha doğru tahminler elde etmeyi sağlar.

						🤷‍♂️Gradient Boosting Kullanılmalı mı? 🤷‍♂️

Gradient Boosting, güçlü ve esnek bir modelleme yöntemidir. Ancak şu durumlar göz önünde bulundurulmalıdır:

✔ Büyük veri setlerinde yüksek başarı sağlar.
✔ Hesaplama maliyeti yüksektir, bu yüzden büyük veri setlerinde dikkatli kullanılmalıdır.
✔ Hiperparametre ayarlamaları zaman alabilir.

Sonuç olarak, eğer güçlü ve doğru tahminler yapmak istiyorsanız, Gradient Boosting harika bir seçimdir! Ancak, hesaplama maliyeti göz önüne alınarak uygun veri setlerinde tercih edilmelidir.


1️⃣ Veri Hazırlama
2️⃣ Eğitim ve Test Kümesine Ayırma
3️⃣ Model Seçimi ve Hiperparametre Optimizasyonu
4️⃣ Model Eğitimi ve En İyi Parametrelerin Belirlenmesi
5️⃣ Tahmin ve Performans Değerlendirmesi
6️⃣ Aşırı Öğrenme (Overfitting) Analizi
7️⃣ Özellik Önem Düzeylerinin İncelenmesi
8️⃣ Görselleştirme ve Sonuçların Yorumlanması

						📋 Bütün Adımların Açıklamaları 📋


	📊 Veri Hazırlama📊
	
✔ Veri Setinin Yüklenmesi – pd.read_csv("mushrooms.csv") ile veri seti okundu.
✔ Veri Ön İncelemesi – df.head() ile veri setinin ilk beş satırı görüntülendi.


	🔄 Train Test Split Özeti 🔄

pd.get_dummies(): Kategorik veriler sayısal verilere dönüştürüldü (one-hot encoding).

drop_first=True: İlk kategoriyi düşürerek dummy trap (gereksiz çoklu doğruluk) engellendi.

x: Bağımsız değişkenler ("class" sütunu hariç tüm sütunlar).
y: Bağımlı değişken (hedef değişken "class").

train_test_split(): Veriler eğitim (%90) ve test (%10) kümelerine ayrıldı. Test kümesi, modelin doğruluğunu değerlendirmek için kullanıldı.
random_state=9 ile aynı rastgele bölme sağlandı her seferinde.

x = pd.get_dummies(df.drop("class", axis=1), drop_first=True)
y = df["class"]
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=9)


	🔧 Grid Search ve GBOOST 🔧

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV
parametre ={
    "n_estimators":[1,3,5,10,20,50,100],
    "max_depth":[2,3,4,5,6]
    }
grad_boost = GradientBoostingClassifier()
grid = GridSearchCV(grad_boost,parametre)
grid.fit(X_train,y_train)
grid.best_params_
mantar_pred = grid.predict(X_test)

Grid Search, modelin hiperparametrelerini otomatik olarak optimize etmek için kullanılan bir tekniktir. Bu, modelin en iyi performansı elde etmesini sağlamak için farklı parametre kombinasyonlarını dener.

Kod Özeti:
parametre: Grid Search'e verilecek olan hiperparametrelerin listesi:

n_estimators: Modeldeki ağaç sayısını belirtir. Bu sayı arttıkça model daha güçlü hale gelebilir, fakat çok büyük değerler aşırı öğrenmeye (overfitting) neden olabilir.

max_depth: Ağaçların derinliğini belirler. Derinlik arttıkça model daha fazla detay öğrenir, ancak aşırı derinlik de overfitting'e yol açabilir.

GridSearchCV: Bu parametrelerle GradientBoostingClassifier modelinin en iyi parametrelerini bulmak için çalıştırılır.

grid.fit(X_train, y_train): GridSearchCV, verilen parametrelerle eğitim verisi üzerinde modelin farklı kombinasyonlarını dener.

grid.best_params_: En iyi parametrelerin çıktısı alınır.

grid.predict(X_test): Test verisi ile tahminler yapılır.


	💡 Grid Search Kullanım Nedeni 💡

Hiperparametre Optimizasyonu: Modelin en iyi performansı göstermesi için doğru parametre kombinasyonlarını bulmak amacıyla kullanılır. Bu, manuel olarak denemekten çok daha hızlı ve doğru bir yöntemdir.

Parametreleri Arttırmak ya da Azaltmak:

n_estimators (ağaç sayısı):
Arttırmak: Model daha fazla ağaç ile daha güçlü hale gelir, fakat aşırı öğrenmeye (overfitting) yol açabilir.
Azaltmak: Model daha hızlı çalışır ancak öğrenme kapasitesi düşer.

max_depth (ağaç derinliği):
Arttırmak: Model daha detaylı öğrenir, ancak aşırı büyük değerler aşırı öğrenmeye neden olabilir.
Azaltmak: Model daha basitleşir ve overfitting riski azalır, fakat doğruluk düşebilir.

Grid Search, modelin performansını optimize etmek için bu parametrelerin en iyi kombinasyonunu bulmak amacıyla kullanıldı.
 

	📊 Model Performansının Değerlendirilmesi ve Özelliklerin Önem Derecelerinin İncelenmesi 📊

# METRİC
from sklearn.metrics import ConfusionMatrixDisplay, classification_report
ConfusionMatrixDisplay.from_estimator(grid, X_test, y_test)

# Aşırı öğrenme analizi
print(classification_report(y_test, mantar_pred))

# Özelliklerin önem düzeylerinin hesaplanması
feat = grid.best_estimator_.feature_importances_
feat_df = pd.DataFrame(index=x.columns, columns=["Katsayılar"], data=feat)

# Küçük katsayıların çıkarılması
feat_df = feat_df[feat_df["Katsayılar"] > 0.001]

# Özelliklerin görselleştirilmesi
plt.figure(figsize=(12,8), dpi=120)
sns.set_style("whitegrid")
sns.set(font_scale=1.5)
sns.barplot(x=feat_df.sort_values("Katsayılar").index, y="Katsayılar", data=feat_df.sort_values("Katsayılar"))
plt.xticks(rotation=90)


1️⃣ Confusion Matrix ve Performans Metrikleri:

from sklearn.metrics import ConfusionMatrixDisplay, classification_report
ConfusionMatrixDisplay.from_estimator(grid, X_test, y_test)
print(classification_report(y_test, mantar_pred))
Confusion Matrix: Modelin doğru ve yanlış tahminlerini gösteren bir görselleştirmedir. Bu, modelin doğru ve yanlış sınıflandırmalarını ayrıntılı bir şekilde görmemize yardımcı olur.

True Positives (TP): Doğru pozitif tahminler.
False Positives (FP): Yanlış pozitif tahminler.
True Negatives (TN): Doğru negatif tahminler.
False Negatives (FN): Yanlış negatif tahminler.
Bu görselleştirme, modelin hatalarını ve doğruluk oranlarını anlamamıza yardımcı olur.

Classification Report: Modelin performansını precision, recall, f1-score ve accuracy gibi metriklerle gösterir. Bu, modelin her sınıf için ne kadar doğru tahminler yaptığını gösteren bir rapordur.

2️⃣ Aşırı Öğrenme (Overfitting) Analizi:
Verinin aşırı öğrenme yapıp yapmadığını anlamak için eğitim ve test hataları gözlemlenebilir.
Aşırı öğrenme durumunda, eğitim verisi üzerinde çok yüksek doğruluk elde edilirken, test verisi üzerinde düşük performans gözlemlenir.
Hata Oranı (error rate) belirli bir noktadan sonra durağan hale gelirse, modelin aşırı öğrenme yapmadığını ve genelleme yeteneğini koruduğunu anlayabiliriz.
AdaBoost eğitimi örneğinde, hata oranlarının belirli aralıklarla hareketli olması ve sonra durağanlaşması, modelin overfitting yapmadığını gösterir.

3️⃣ Özelliklerin Önem Düzeylerinin Hesaplanması:

feat = grid.best_estimator_.feature_importances_
feat_df = pd.DataFrame(index=x.columns, columns=["Katsayılar"], data=feat)
Feature Importance (Özellik Önem Düzeyleri): Modelin hangi özelliklere daha fazla odaklandığını gösterir. Bu değer, modelin öğrenme sürecinde hangi değişkenlerin daha fazla etkili olduğunu anlamamıza yardımcı olur.

feat_df: Önem düzeyleri sıralanarak, daha yüksek katsayıya sahip özellikler daha etkili olarak kabul edilir.

4️⃣ Önemli Özelliklerin Görselleştirilmesi:

feat_df = feat_df[feat_df["Katsayılar"] > 0.001]
plt.figure(figsize=(12,8), dpi=120)
sns.set_style("whitegrid")
sns.set(font_scale=1.5)
sns.barplot(x=feat_df.sort_values("Katsayılar").index, y="Katsayılar", data=feat_df.sort_values("Katsayılar"))
plt.xticks(rotation=90)

Görselleştirme: Özelliklerin önem düzeylerini bir bar plot ile görselleştirerek, hangi özelliklerin modelde daha etkili olduğunu daha iyi anlayabiliriz.
feat_df[feat_df["Katsayılar"] > 0.001]: Küçük katsayıya sahip özellikler görselleştirmeden çıkarıldı, böylece daha anlamlı özelliklere odaklanıldı.

Sonuç:
Confusion Matrix ve classification report ile modelin doğruluğu ve hataları değerlendirildi.
Özelliklerin önem düzeyleri hesaplanarak modelde en etkili olanlar belirlendi ve görselleştirildi. Bu sayede modelin hangi özelliklere dayalı olarak daha iyi sonuçlar verdiğini görebildik.


					🔧 Genel Kodlar 🔧

# Gerekli kütüphanelerin import edilmesi
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import ConfusionMatrixDisplay, classification_report

# Verinin yüklenmesi
df = pd.read_csv("mushrooms.csv")
df.head()

# Veri hazırlığı
x = pd.get_dummies(df.drop("class", axis=1), drop_first=True)
y = df["class"]

# Eğitim ve test kümesine ayırma
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=9)

# GridSearchCV ile hiperparametre optimizasyonu ve Gradient Boosting modelinin eğitilmesi
parametre = {
    "n_estimators": [1, 3, 5, 10, 20, 50, 100],
    "max_depth": [2, 3, 4, 5, 6]
}
grad_boost = GradientBoostingClassifier()
grid = GridSearchCV(grad_boost, parametre)
grid.fit(X_train, y_train)

# En iyi parametrelerin belirlenmesi
print("En iyi parametreler:", grid.best_params_)

# Test verisi ile tahmin yapılması
mantar_pred = grid.predict(X_test)

# Model performansının değerlendirilmesi
ConfusionMatrixDisplay.from_estimator(grid, X_test, y_test)
print(classification_report(y_test, mantar_pred))

# Özelliklerin önem düzeylerinin hesaplanması
feat = grid.best_estimator_.feature_importances_
feat_df = pd.DataFrame(index=x.columns, columns=["Katsayılar"], data=feat)

# Küçük katsayıların çıkarılması
feat_df = feat_df[feat_df["Katsayılar"] > 0.001]

# Özelliklerin görselleştirilmesi
plt.figure(figsize=(12, 8), dpi=120)
sns.set_style("whitegrid")
sns.set(font_scale=1.5)
sns.barplot(x=feat_df.sort_values("Katsayılar").index, y="Katsayılar", data=feat_df.sort_values("Katsayılar"))
plt.xticks(rotation=90)
plt.show()

					⚠️ Dikkat Edilmesi Gerekenler ⚠️

🔄 Parametre Aralıkları

Grid Search için belirlediğiniz parametre aralıklarını çok geniş tutmaktan kaçının. Aksi takdirde model çok uzun sürede eğitilebilir ve aşırı işlem gücü gerektirebilir. Aralıkları mantıklı ve verimli bir şekilde seçmek önemlidir.

⚡ Performans İzleme ⚡

Modelin doğruluğunu değerlendirirken Confusion Matrix ve classification_report kullanmak çok önemlidir. Bu metrikler modelin doğru ve yanlış tahminlerini anlamanızı sağlar.

⚖️ Aşırı Öğrenme (Overfitting) Uyarısı ⚖️

Eğitim ve test hatalarını gözlemlerken, aşırı öğrenme (overfitting) yapıp yapmadığınızı kontrol edin. Eğitim hatası çok düşük, ancak test hatası yüksekse, model aşırı öğrenme yapmış olabilir. Daha küçük parametreler ile tekrar deneyebilirsiniz.
 
🎨 Görselleştirme 🎨

Özelliklerin önem düzeylerini bar plot ile görselleştirirken, önemsiz özelliklerin çıkarılmasına dikkat edin. Bu sayede sadece etkili olan özellikleri görselde daha net görebilirsiniz.

💡 Eğitim Süresi

Modelin eğitim süresi çok uzun oluyorsa, modelin optimize edilmesi gerekebilir. Hiperparametreleri ayarlarken dikkatli olun ve işlem süresini optimize edin.



















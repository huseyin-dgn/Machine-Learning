						ğŸš€ Gradient Boosting: GÃ¼Ã§lÃ¼ Bir Makine Ã–ÄŸrenmesi YÃ¶ntemi ğŸš€

Gradient Boosting, denetimli Ã¶ÄŸrenme problemlerinde kullanÄ±lan gÃ¼Ã§lÃ¼ bir topluluk (ensemble) Ã¶ÄŸrenme yÃ¶ntemidir. KÃ¼Ã§Ã¼k hata oranlarÄ± ve yÃ¼ksek doÄŸruluk seviyeleri ile Ã¶ne Ã§Ä±kan bu algoritma, Ã¶zellikle karmaÅŸÄ±k veri setlerinde baÅŸarÄ±lÄ± sonuÃ§lar verir. Peki, Gradient Boosting neden kullanÄ±lÄ±r ve diÄŸer yÃ¶ntemlerden farkÄ± nedir?

ğŸ¤” Gradient Boosting Neden KullanÄ±lÄ±r? ğŸ¤”

Gradient Boosting, modelin hatalarÄ±nÄ± minimize etmek iÃ§in ardÄ±ÅŸÄ±k karar aÄŸaÃ§larÄ±nÄ± eÄŸiten bir tekniktir. Hedefi, her bir aÄŸaÃ§ ile Ã¶nceki modelin tahmin hatalarÄ±nÄ± dÃ¼zeltmektir.

KullanÄ±m nedenleri ÅŸunlardÄ±r:
âœ” YÃ¼ksek doÄŸruluk: KarmaÅŸÄ±k veri setlerinde bile baÅŸarÄ±lÄ± tahminler yapabilir.
âœ” Ã–zelleÅŸtirilebilirlik: Ã–ÄŸrenme oranÄ±, aÄŸaÃ§ derinliÄŸi gibi parametreler Ã¼zerinde ince ayar yapÄ±labilir.
âœ” AykÄ±rÄ± deÄŸerlere dayanÄ±klÄ±lÄ±k: Decision Tree tabanlÄ± olduÄŸu iÃ§in outlierâ€™lara karÅŸÄ± daha toleranslÄ±dÄ±r.
âœ” Ã–zellik seÃ§imi yapabilme: Model, en Ã¶nemli Ã¶zellikleri belirleyerek daha verimli tahminler yapabilir.

âš–ï¸ AdaBoost ile Gradient Boosting ArasÄ±ndaki Farklar âš–ï¸

Gradient Boosting, AdaBoostâ€™a benzese de temel farklarÄ± ÅŸunlardÄ±r:

ğŸ”¹ Hata GÃ¼ncelleme YÃ¶ntemi: AdaBoost hatalarÄ± aÄŸÄ±rlÄ±klandÄ±rarak gÃ¼ncellerken, Gradient Boosting hata miktarÄ±nÄ± gradyan iniÅŸ yÃ¶ntemiyle minimize eder.
ğŸ”¹ Daha Esnek Modelleme: Gradient Boosting, kayÄ±p fonksiyonunu doÄŸrudan optimize edebilir, AdaBoost ise genellikle sÄ±nÄ±flandÄ±rma hatalarÄ± Ã¼zerinden Ã§alÄ±ÅŸÄ±r.
ğŸ”¹ AÄŸaÃ§ DerinliÄŸi: AdaBoost genellikle sÄ±ÄŸ aÄŸaÃ§larla Ã§alÄ±ÅŸÄ±rken, Gradient Boosting daha derin aÄŸaÃ§lar kullanabilir.

						ğŸ†Gradient Boosting + Grid Search: MÃ¼kemmel Ä°kili ğŸ†

Gradient Boostingâ€™in performansÄ±nÄ± artÄ±rmak iÃ§in Grid Search kullanmak oldukÃ§a Ã¶nemlidir. Grid Search, modelin hiperparametrelerini en iyi sonucu verecek ÅŸekilde ayarlamak iÃ§in kullanÄ±lÄ±r.

ğŸ’¡ Grid Search neden Ã¶nemli? ğŸ’¡

âœ… Ã–ÄŸrenme oranÄ±, aÄŸaÃ§ sayÄ±sÄ±, maksimum derinlik gibi parametreleri optimize eder.
âœ… AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi (overfitting) engelleyerek modelin genelleme yeteneÄŸini artÄ±rÄ±r.
âœ… Daha doÄŸru tahminler elde etmeyi saÄŸlar.

						ğŸ¤·â€â™‚ï¸Gradient Boosting KullanÄ±lmalÄ± mÄ±? ğŸ¤·â€â™‚ï¸

Gradient Boosting, gÃ¼Ã§lÃ¼ ve esnek bir modelleme yÃ¶ntemidir. Ancak ÅŸu durumlar gÃ¶z Ã¶nÃ¼nde bulundurulmalÄ±dÄ±r:

âœ” BÃ¼yÃ¼k veri setlerinde yÃ¼ksek baÅŸarÄ± saÄŸlar.
âœ” Hesaplama maliyeti yÃ¼ksektir, bu yÃ¼zden bÃ¼yÃ¼k veri setlerinde dikkatli kullanÄ±lmalÄ±dÄ±r.
âœ” Hiperparametre ayarlamalarÄ± zaman alabilir.

SonuÃ§ olarak, eÄŸer gÃ¼Ã§lÃ¼ ve doÄŸru tahminler yapmak istiyorsanÄ±z, Gradient Boosting harika bir seÃ§imdir! Ancak, hesaplama maliyeti gÃ¶z Ã¶nÃ¼ne alÄ±narak uygun veri setlerinde tercih edilmelidir.


1ï¸âƒ£ Veri HazÄ±rlama
2ï¸âƒ£ EÄŸitim ve Test KÃ¼mesine AyÄ±rma
3ï¸âƒ£ Model SeÃ§imi ve Hiperparametre Optimizasyonu
4ï¸âƒ£ Model EÄŸitimi ve En Ä°yi Parametrelerin Belirlenmesi
5ï¸âƒ£ Tahmin ve Performans DeÄŸerlendirmesi
6ï¸âƒ£ AÅŸÄ±rÄ± Ã–ÄŸrenme (Overfitting) Analizi
7ï¸âƒ£ Ã–zellik Ã–nem DÃ¼zeylerinin Ä°ncelenmesi
8ï¸âƒ£ GÃ¶rselleÅŸtirme ve SonuÃ§larÄ±n YorumlanmasÄ±

						ğŸ“‹ BÃ¼tÃ¼n AdÄ±mlarÄ±n AÃ§Ä±klamalarÄ± ğŸ“‹


	ğŸ“Š Veri HazÄ±rlamağŸ“Š
	
âœ” Veri Setinin YÃ¼klenmesi â€“ pd.read_csv("mushrooms.csv") ile veri seti okundu.
âœ” Veri Ã–n Ä°ncelemesi â€“ df.head() ile veri setinin ilk beÅŸ satÄ±rÄ± gÃ¶rÃ¼ntÃ¼lendi.


	ğŸ”„ Train Test Split Ã–zeti ğŸ”„

pd.get_dummies(): Kategorik veriler sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼ (one-hot encoding).

drop_first=True: Ä°lk kategoriyi dÃ¼ÅŸÃ¼rerek dummy trap (gereksiz Ã§oklu doÄŸruluk) engellendi.

x: BaÄŸÄ±msÄ±z deÄŸiÅŸkenler ("class" sÃ¼tunu hariÃ§ tÃ¼m sÃ¼tunlar).
y: BaÄŸÄ±mlÄ± deÄŸiÅŸken (hedef deÄŸiÅŸken "class").

train_test_split(): Veriler eÄŸitim (%90) ve test (%10) kÃ¼melerine ayrÄ±ldÄ±. Test kÃ¼mesi, modelin doÄŸruluÄŸunu deÄŸerlendirmek iÃ§in kullanÄ±ldÄ±.
random_state=9 ile aynÄ± rastgele bÃ¶lme saÄŸlandÄ± her seferinde.

x = pd.get_dummies(df.drop("class", axis=1), drop_first=True)
y = df["class"]
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=9)


	ğŸ”§ Grid Search ve GBOOST ğŸ”§

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV
parametre ={
    "n_estimators":[1,3,5,10,20,50,100],
    "max_depth":[2,3,4,5,6]
    }
grad_boost = GradientBoostingClassifier()
grid = GridSearchCV(grad_boost,parametre)
grid.fit(X_train,y_train)
grid.best_params_
mantar_pred = grid.predict(X_test)

Grid Search, modelin hiperparametrelerini otomatik olarak optimize etmek iÃ§in kullanÄ±lan bir tekniktir. Bu, modelin en iyi performansÄ± elde etmesini saÄŸlamak iÃ§in farklÄ± parametre kombinasyonlarÄ±nÄ± dener.

Kod Ã–zeti:
parametre: Grid Search'e verilecek olan hiperparametrelerin listesi:

n_estimators: Modeldeki aÄŸaÃ§ sayÄ±sÄ±nÄ± belirtir. Bu sayÄ± arttÄ±kÃ§a model daha gÃ¼Ã§lÃ¼ hale gelebilir, fakat Ã§ok bÃ¼yÃ¼k deÄŸerler aÅŸÄ±rÄ± Ã¶ÄŸrenmeye (overfitting) neden olabilir.

max_depth: AÄŸaÃ§larÄ±n derinliÄŸini belirler. Derinlik arttÄ±kÃ§a model daha fazla detay Ã¶ÄŸrenir, ancak aÅŸÄ±rÄ± derinlik de overfitting'e yol aÃ§abilir.

GridSearchCV: Bu parametrelerle GradientBoostingClassifier modelinin en iyi parametrelerini bulmak iÃ§in Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r.

grid.fit(X_train, y_train): GridSearchCV, verilen parametrelerle eÄŸitim verisi Ã¼zerinde modelin farklÄ± kombinasyonlarÄ±nÄ± dener.

grid.best_params_: En iyi parametrelerin Ã§Ä±ktÄ±sÄ± alÄ±nÄ±r.

grid.predict(X_test): Test verisi ile tahminler yapÄ±lÄ±r.


	ğŸ’¡ Grid Search KullanÄ±m Nedeni ğŸ’¡

Hiperparametre Optimizasyonu: Modelin en iyi performansÄ± gÃ¶stermesi iÃ§in doÄŸru parametre kombinasyonlarÄ±nÄ± bulmak amacÄ±yla kullanÄ±lÄ±r. Bu, manuel olarak denemekten Ã§ok daha hÄ±zlÄ± ve doÄŸru bir yÃ¶ntemdir.

Parametreleri ArttÄ±rmak ya da Azaltmak:

n_estimators (aÄŸaÃ§ sayÄ±sÄ±):
ArttÄ±rmak: Model daha fazla aÄŸaÃ§ ile daha gÃ¼Ã§lÃ¼ hale gelir, fakat aÅŸÄ±rÄ± Ã¶ÄŸrenmeye (overfitting) yol aÃ§abilir.
Azaltmak: Model daha hÄ±zlÄ± Ã§alÄ±ÅŸÄ±r ancak Ã¶ÄŸrenme kapasitesi dÃ¼ÅŸer.

max_depth (aÄŸaÃ§ derinliÄŸi):
ArttÄ±rmak: Model daha detaylÄ± Ã¶ÄŸrenir, ancak aÅŸÄ±rÄ± bÃ¼yÃ¼k deÄŸerler aÅŸÄ±rÄ± Ã¶ÄŸrenmeye neden olabilir.
Azaltmak: Model daha basitleÅŸir ve overfitting riski azalÄ±r, fakat doÄŸruluk dÃ¼ÅŸebilir.

Grid Search, modelin performansÄ±nÄ± optimize etmek iÃ§in bu parametrelerin en iyi kombinasyonunu bulmak amacÄ±yla kullanÄ±ldÄ±.
 

	ğŸ“Š Model PerformansÄ±nÄ±n DeÄŸerlendirilmesi ve Ã–zelliklerin Ã–nem Derecelerinin Ä°ncelenmesi ğŸ“Š

# METRÄ°C
from sklearn.metrics import ConfusionMatrixDisplay, classification_report
ConfusionMatrixDisplay.from_estimator(grid, X_test, y_test)

# AÅŸÄ±rÄ± Ã¶ÄŸrenme analizi
print(classification_report(y_test, mantar_pred))

# Ã–zelliklerin Ã¶nem dÃ¼zeylerinin hesaplanmasÄ±
feat = grid.best_estimator_.feature_importances_
feat_df = pd.DataFrame(index=x.columns, columns=["KatsayÄ±lar"], data=feat)

# KÃ¼Ã§Ã¼k katsayÄ±larÄ±n Ã§Ä±karÄ±lmasÄ±
feat_df = feat_df[feat_df["KatsayÄ±lar"] > 0.001]

# Ã–zelliklerin gÃ¶rselleÅŸtirilmesi
plt.figure(figsize=(12,8), dpi=120)
sns.set_style("whitegrid")
sns.set(font_scale=1.5)
sns.barplot(x=feat_df.sort_values("KatsayÄ±lar").index, y="KatsayÄ±lar", data=feat_df.sort_values("KatsayÄ±lar"))
plt.xticks(rotation=90)


1ï¸âƒ£ Confusion Matrix ve Performans Metrikleri:

from sklearn.metrics import ConfusionMatrixDisplay, classification_report
ConfusionMatrixDisplay.from_estimator(grid, X_test, y_test)
print(classification_report(y_test, mantar_pred))
Confusion Matrix: Modelin doÄŸru ve yanlÄ±ÅŸ tahminlerini gÃ¶steren bir gÃ¶rselleÅŸtirmedir. Bu, modelin doÄŸru ve yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rmalarÄ±nÄ± ayrÄ±ntÄ±lÄ± bir ÅŸekilde gÃ¶rmemize yardÄ±mcÄ± olur.

True Positives (TP): DoÄŸru pozitif tahminler.
False Positives (FP): YanlÄ±ÅŸ pozitif tahminler.
True Negatives (TN): DoÄŸru negatif tahminler.
False Negatives (FN): YanlÄ±ÅŸ negatif tahminler.
Bu gÃ¶rselleÅŸtirme, modelin hatalarÄ±nÄ± ve doÄŸruluk oranlarÄ±nÄ± anlamamÄ±za yardÄ±mcÄ± olur.

Classification Report: Modelin performansÄ±nÄ± precision, recall, f1-score ve accuracy gibi metriklerle gÃ¶sterir. Bu, modelin her sÄ±nÄ±f iÃ§in ne kadar doÄŸru tahminler yaptÄ±ÄŸÄ±nÄ± gÃ¶steren bir rapordur.

2ï¸âƒ£ AÅŸÄ±rÄ± Ã–ÄŸrenme (Overfitting) Analizi:
Verinin aÅŸÄ±rÄ± Ã¶ÄŸrenme yapÄ±p yapmadÄ±ÄŸÄ±nÄ± anlamak iÃ§in eÄŸitim ve test hatalarÄ± gÃ¶zlemlenebilir.
AÅŸÄ±rÄ± Ã¶ÄŸrenme durumunda, eÄŸitim verisi Ã¼zerinde Ã§ok yÃ¼ksek doÄŸruluk elde edilirken, test verisi Ã¼zerinde dÃ¼ÅŸÃ¼k performans gÃ¶zlemlenir.
Hata OranÄ± (error rate) belirli bir noktadan sonra duraÄŸan hale gelirse, modelin aÅŸÄ±rÄ± Ã¶ÄŸrenme yapmadÄ±ÄŸÄ±nÄ± ve genelleme yeteneÄŸini koruduÄŸunu anlayabiliriz.
AdaBoost eÄŸitimi Ã¶rneÄŸinde, hata oranlarÄ±nÄ±n belirli aralÄ±klarla hareketli olmasÄ± ve sonra duraÄŸanlaÅŸmasÄ±, modelin overfitting yapmadÄ±ÄŸÄ±nÄ± gÃ¶sterir.

3ï¸âƒ£ Ã–zelliklerin Ã–nem DÃ¼zeylerinin HesaplanmasÄ±:

feat = grid.best_estimator_.feature_importances_
feat_df = pd.DataFrame(index=x.columns, columns=["KatsayÄ±lar"], data=feat)
Feature Importance (Ã–zellik Ã–nem DÃ¼zeyleri): Modelin hangi Ã¶zelliklere daha fazla odaklandÄ±ÄŸÄ±nÄ± gÃ¶sterir. Bu deÄŸer, modelin Ã¶ÄŸrenme sÃ¼recinde hangi deÄŸiÅŸkenlerin daha fazla etkili olduÄŸunu anlamamÄ±za yardÄ±mcÄ± olur.

feat_df: Ã–nem dÃ¼zeyleri sÄ±ralanarak, daha yÃ¼ksek katsayÄ±ya sahip Ã¶zellikler daha etkili olarak kabul edilir.

4ï¸âƒ£ Ã–nemli Ã–zelliklerin GÃ¶rselleÅŸtirilmesi:

feat_df = feat_df[feat_df["KatsayÄ±lar"] > 0.001]
plt.figure(figsize=(12,8), dpi=120)
sns.set_style("whitegrid")
sns.set(font_scale=1.5)
sns.barplot(x=feat_df.sort_values("KatsayÄ±lar").index, y="KatsayÄ±lar", data=feat_df.sort_values("KatsayÄ±lar"))
plt.xticks(rotation=90)

GÃ¶rselleÅŸtirme: Ã–zelliklerin Ã¶nem dÃ¼zeylerini bir bar plot ile gÃ¶rselleÅŸtirerek, hangi Ã¶zelliklerin modelde daha etkili olduÄŸunu daha iyi anlayabiliriz.
feat_df[feat_df["KatsayÄ±lar"] > 0.001]: KÃ¼Ã§Ã¼k katsayÄ±ya sahip Ã¶zellikler gÃ¶rselleÅŸtirmeden Ã§Ä±karÄ±ldÄ±, bÃ¶ylece daha anlamlÄ± Ã¶zelliklere odaklanÄ±ldÄ±.

SonuÃ§:
Confusion Matrix ve classification report ile modelin doÄŸruluÄŸu ve hatalarÄ± deÄŸerlendirildi.
Ã–zelliklerin Ã¶nem dÃ¼zeyleri hesaplanarak modelde en etkili olanlar belirlendi ve gÃ¶rselleÅŸtirildi. Bu sayede modelin hangi Ã¶zelliklere dayalÄ± olarak daha iyi sonuÃ§lar verdiÄŸini gÃ¶rebildik.


					ğŸ”§ Genel Kodlar ğŸ”§

# Gerekli kÃ¼tÃ¼phanelerin import edilmesi
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import ConfusionMatrixDisplay, classification_report

# Verinin yÃ¼klenmesi
df = pd.read_csv("mushrooms.csv")
df.head()

# Veri hazÄ±rlÄ±ÄŸÄ±
x = pd.get_dummies(df.drop("class", axis=1), drop_first=True)
y = df["class"]

# EÄŸitim ve test kÃ¼mesine ayÄ±rma
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=9)

# GridSearchCV ile hiperparametre optimizasyonu ve Gradient Boosting modelinin eÄŸitilmesi
parametre = {
    "n_estimators": [1, 3, 5, 10, 20, 50, 100],
    "max_depth": [2, 3, 4, 5, 6]
}
grad_boost = GradientBoostingClassifier()
grid = GridSearchCV(grad_boost, parametre)
grid.fit(X_train, y_train)

# En iyi parametrelerin belirlenmesi
print("En iyi parametreler:", grid.best_params_)

# Test verisi ile tahmin yapÄ±lmasÄ±
mantar_pred = grid.predict(X_test)

# Model performansÄ±nÄ±n deÄŸerlendirilmesi
ConfusionMatrixDisplay.from_estimator(grid, X_test, y_test)
print(classification_report(y_test, mantar_pred))

# Ã–zelliklerin Ã¶nem dÃ¼zeylerinin hesaplanmasÄ±
feat = grid.best_estimator_.feature_importances_
feat_df = pd.DataFrame(index=x.columns, columns=["KatsayÄ±lar"], data=feat)

# KÃ¼Ã§Ã¼k katsayÄ±larÄ±n Ã§Ä±karÄ±lmasÄ±
feat_df = feat_df[feat_df["KatsayÄ±lar"] > 0.001]

# Ã–zelliklerin gÃ¶rselleÅŸtirilmesi
plt.figure(figsize=(12, 8), dpi=120)
sns.set_style("whitegrid")
sns.set(font_scale=1.5)
sns.barplot(x=feat_df.sort_values("KatsayÄ±lar").index, y="KatsayÄ±lar", data=feat_df.sort_values("KatsayÄ±lar"))
plt.xticks(rotation=90)
plt.show()

					âš ï¸ Dikkat Edilmesi Gerekenler âš ï¸

ğŸ”„ Parametre AralÄ±klarÄ±

Grid Search iÃ§in belirlediÄŸiniz parametre aralÄ±klarÄ±nÄ± Ã§ok geniÅŸ tutmaktan kaÃ§Ä±nÄ±n. Aksi takdirde model Ã§ok uzun sÃ¼rede eÄŸitilebilir ve aÅŸÄ±rÄ± iÅŸlem gÃ¼cÃ¼ gerektirebilir. AralÄ±klarÄ± mantÄ±klÄ± ve verimli bir ÅŸekilde seÃ§mek Ã¶nemlidir.

âš¡ Performans Ä°zleme âš¡

Modelin doÄŸruluÄŸunu deÄŸerlendirirken Confusion Matrix ve classification_report kullanmak Ã§ok Ã¶nemlidir. Bu metrikler modelin doÄŸru ve yanlÄ±ÅŸ tahminlerini anlamanÄ±zÄ± saÄŸlar.

âš–ï¸ AÅŸÄ±rÄ± Ã–ÄŸrenme (Overfitting) UyarÄ±sÄ± âš–ï¸

EÄŸitim ve test hatalarÄ±nÄ± gÃ¶zlemlerken, aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) yapÄ±p yapmadÄ±ÄŸÄ±nÄ±zÄ± kontrol edin. EÄŸitim hatasÄ± Ã§ok dÃ¼ÅŸÃ¼k, ancak test hatasÄ± yÃ¼ksekse, model aÅŸÄ±rÄ± Ã¶ÄŸrenme yapmÄ±ÅŸ olabilir. Daha kÃ¼Ã§Ã¼k parametreler ile tekrar deneyebilirsiniz.
 
ğŸ¨ GÃ¶rselleÅŸtirme ğŸ¨

Ã–zelliklerin Ã¶nem dÃ¼zeylerini bar plot ile gÃ¶rselleÅŸtirirken, Ã¶nemsiz Ã¶zelliklerin Ã§Ä±karÄ±lmasÄ±na dikkat edin. Bu sayede sadece etkili olan Ã¶zellikleri gÃ¶rselde daha net gÃ¶rebilirsiniz.

ğŸ’¡ EÄŸitim SÃ¼resi

Modelin eÄŸitim sÃ¼resi Ã§ok uzun oluyorsa, modelin optimize edilmesi gerekebilir. Hiperparametreleri ayarlarken dikkatli olun ve iÅŸlem sÃ¼resini optimize edin.



















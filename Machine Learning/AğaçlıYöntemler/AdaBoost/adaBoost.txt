ğŸ“Š AdaBoost Nedir?
AdaBoost (Adaptive Boosting), zayÄ±f sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ± (model parÃ§alarÄ±nÄ±) bir araya getirerek gÃ¼Ã§lÃ¼ bir sÄ±nÄ±flandÄ±rÄ±cÄ± oluÅŸturmayÄ± amaÃ§layan bir algoritmadÄ±r.

ğŸ’¡ Ne Ä°ÅŸe Yarar?
AdaBoost, farklÄ± sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ± birleÅŸtirerek daha doÄŸru sonuÃ§lar elde etmek iÃ§in kullanÄ±lÄ±r. Her bir modelin hata payÄ±nÄ± gÃ¶z Ã¶nÃ¼nde bulundurarak, yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lan Ã¶rneklere daha fazla aÄŸÄ±rlÄ±k verir ve bÃ¶ylece doÄŸruluÄŸu artÄ±rÄ±r.

ğŸ”„ DiÄŸer AÄŸaÃ§ Modellerinden FarkÄ± Nedir?
ZayÄ±f Ã–ÄŸreniciler: AdaBoost, her defasÄ±nda zayÄ±f bir model oluÅŸturur (Ã¶rneÄŸin karar aÄŸaÃ§larÄ±), ancak her yeni model, Ã¶nceki modellerin hatalarÄ±nÄ± dÃ¼zeltmeye odaklanÄ±r.
AÄŸaÃ§lar ArasÄ± Ä°liÅŸki: DiÄŸer aÄŸaÃ§ modelleri genellikle baÄŸÄ±msÄ±zdÄ±r (Ã¶rneÄŸin, rastgele orman), AdaBoost'ta ise aÄŸaÃ§lar birbiriyle etkileÅŸim iÃ§inde olup ardÄ±ÅŸÄ±k Ã§alÄ±ÅŸÄ±r.

ğŸš€ Neden OluÅŸturulmuÅŸtur?
AdaBoost, zayÄ±f modelleri gÃ¼Ã§lendirmek ve daha doÄŸru tahminler yapmak iÃ§in geliÅŸtirilmiÅŸtir. Hedefi, tek baÅŸÄ±na yetersiz kalan basit modelleri birleÅŸtirerek gÃ¼Ã§lÃ¼ bir sÄ±nÄ±flandÄ±rÄ±cÄ± oluÅŸturmaktÄ±r.

ğŸ”‘ Ana Ã–zellikler
AÄŸÄ±rlÄ±klÄ± Ã–ÄŸrenme: Model, yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lan Ã¶rnekleri daha fazla dikkate alÄ±r.
HÄ±zlÄ± ve Etkili: ZayÄ±f modellerin gÃ¼cÃ¼nden faydalanarak daha verimli sonuÃ§lar alÄ±r.
Esneklik: Ã‡eÅŸitli sÄ±nÄ±flandÄ±rÄ±cÄ±larla kullanÄ±labilir.
Yani, AdaBoost aslÄ±nda "zayÄ±f modellerin birleÅŸimiyle gÃ¼Ã§lÃ¼ bir model oluÅŸturma" fikrini savunur! ğŸŒŸ

				 ğŸ’¡ ADA BOOST ğŸ’¡

1ï¸âƒ£ Veri HazÄ±rlama
2ï¸âƒ£ Veri GÃ¶rselleÅŸtirme
3ï¸âƒ£ Model EÄŸitimi ve DeÄŸerlendirme
4ï¸âƒ£ Model Ä°yileÅŸtirme ve Hata Analizi
5ï¸âƒ£ Final Model ve SonuÃ§lar

				ğŸ› ï¸ Veri HazÄ±rlama ğŸ› ï¸

Veri hazÄ±rlama, modelleme sÃ¼recinin en Ã¶nemli aÅŸamalarÄ±ndan biridir. Bu adÄ±mda, veriyi anlamak, eksiklikleri tespit etmek ve veriyi uygun formata getirmek iÃ§in Ã§eÅŸitli iÅŸlemler yapÄ±lÄ±r.

ğŸ“Š Gerekli kÃ¼tÃ¼phanelerin yÃ¼klenmesi ğŸ“Š

Ä°lk olarak, gerekli kÃ¼tÃ¼phaneler (numpy, pandas, seaborn, matplotlib) import edilir. Bu kÃ¼tÃ¼phaneler veri analizi ve gÃ¶rselleÅŸtirme iÃ§in kullanÄ±lÄ±r.

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

ğŸ„ Veri kÃ¼mesinin yÃ¼klenmesi ğŸ„

df = pd.read_csv("mushrooms.csv")

Veri kÃ¼mesi, pandas kÃ¼tÃ¼phanesinin read_csv fonksiyonu ile yÃ¼klenir. Bu veri kÃ¼mesi, mantar tÃ¼rleri hakkÄ±nda bilgileri iÃ§ermektedir.

ğŸ“ Veri Ã§erÃ§evesinin genel yapÄ±sÄ±nÄ±n incelenmesi ğŸ“

df.info()

df.info() komutu, veri Ã§erÃ§evesinin genel yapÄ±sÄ±nÄ± gÃ¶sterir. Veri tipi, eksik veriler ve sÃ¼tun sayÄ±sÄ± gibi bilgileri saÄŸlar.

âŒ Eksik verilerin kontrol edilmesi âŒ

df.isna().sum().sum()

Eksik (NaN) verileri kontrol etmek iÃ§in isna().sum() fonksiyonu kullanÄ±lÄ±r. EÄŸer veri setinde eksik deÄŸerler varsa, bunlar sum() ile toplu ÅŸekilde hesaplanabilir.

ğŸ”„ Veri Ã¶zetinin Ã§Ä±karÄ±lmasÄ± ğŸ”„

df.describe().transpose()

Veri setindeki sayÄ±sal deÄŸiÅŸkenler hakkÄ±nda Ã¶zet istatistikleri gÃ¶rmek iÃ§in describe() fonksiyonu kullanÄ±lÄ±r. transpose() ile bu bilgilerin dÃ¼zenini deÄŸiÅŸtirerek daha okunabilir hale getirebiliriz.

ğŸ§®Benzersiz deÄŸerlerin sÄ±ralanmasÄ± ğŸ§®

df.describe().T.sort_values(by="unique")

Benzersiz (unique) deÄŸerleri daha iyi anlamak iÃ§in bu komut kullanÄ±lÄ±r. Veriyi benzersiz deÄŸerlere gÃ¶re sÄ±ralar.

ğŸ” Veri satÄ±rlarÄ±nÄ±n incelenmesi ğŸ”

df.iloc[3]

Veri Ã§erÃ§evesindeki 3. satÄ±rÄ± gÃ¶rmek iÃ§in kullanÄ±lÄ±r. Bu, veriyi daha yakÄ±ndan incelememize yardÄ±mcÄ± olur.

ğŸ“‘ EÅŸsiz deÄŸerlerin ve sayÄ±larÄ±nÄ±n gÃ¶sterilmesi ğŸ“‘

pd.concat({"EÅŸsiz deÄŸer": df.apply(pd.unique), "sayÄ±sÄ±": df.nunique()}, axis=1)

apply(pd.unique) her sÃ¼tundaki eÅŸsiz deÄŸerleri, nunique() ise her sÃ¼tundaki benzersiz deÄŸerlerin sayÄ±sÄ±nÄ± verir. Bu sayÄ±lar, veri setini daha iyi analiz etmek iÃ§in kullanÄ±lÄ±r.

âš–ï¸ SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ±n kontrol edilmesi âš–ï¸

df["class"].value_counts()

class sÃ¼tunundaki sÄ±nÄ±flarÄ±n daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rmek iÃ§in value_counts() fonksiyonu kullanÄ±lÄ±r. Bu, verinin dengesiz olup olmadÄ±ÄŸÄ±nÄ± anlamamÄ±za yardÄ±mcÄ± olabilir.


				ğŸ“Š GÃ¶rselleÅŸtirme ğŸ“Š

Veri setinin daha iyi anlaÅŸÄ±labilmesi ve analize daha kolay eriÅŸebilmek iÃ§in Ã§eÅŸitli gÃ¶rselleÅŸtirme teknikleri kullanÄ±lÄ±r. Bu adÄ±mda, verileri gÃ¶rsel hale getirerek anlamak Ã§ok daha kolay hale gelir.

ğŸ§® EÅŸsiz DeÄŸerlerin GÃ¶rselleÅŸtirilmesi ğŸ§®

Ä°lk gÃ¶rselleÅŸtirmede, her bir sÃ¼tundaki benzersiz deÄŸerlerin sayÄ±sÄ±nÄ± gÃ¶rselleÅŸtiren bir Ã§ubuk grafik oluÅŸturulur. Bu, veri setindeki kategorik deÄŸiÅŸkenlerin Ã§eÅŸitliliÄŸini anlamamÄ±za yardÄ±mcÄ± olur.

sns.barplot(data=df.describe().transpose().reset_index().sort_values("unique"), x="index", y="unique")
plt.xticks(rotation=90)

sns.barplot() Seaborn kÃ¼tÃ¼phanesinin Ã§ubuk grafik Ã§izme fonksiyonudur. Burada, index ve unique sÃ¼tunlarÄ± kullanÄ±larak her sÃ¼tundaki benzersiz deÄŸerlerin sayÄ±sÄ± Ã§ubuk grafik ile gÃ¶sterilir.

df.describe() fonksiyonu, DataFrame'in sayÄ±sal Ã¶zetini verir.

.transpose() ile bu Ã¶zetin satÄ±r ve sÃ¼tunlarÄ± tersine Ã§evrilir ve daha anlaÅŸÄ±lÄ±r hale gelir.

.reset_index() mevcut index'i bir sÃ¼tun olarak dÃ¶ndÃ¼rÃ¼r ve daha kolay sÄ±ralama yapÄ±lmasÄ±nÄ± saÄŸlar.

.sort_values("unique") ile veri benzersiz deÄŸerlerin sayÄ±sÄ±na gÃ¶re sÄ±ralanÄ±r.

plt.xticks(rotation=90) X eksenindeki etiketlerin okunabilirliÄŸini arttÄ±rmak iÃ§in dÃ¶ndÃ¼rÃ¼lÃ¼r.

SonuÃ§ olarak, her sÃ¼tundaki benzersiz deÄŸer sayÄ±sÄ±nÄ± gÃ¶steren bir Ã§ubuk grafik elde edilir. ğŸ“Š

âš–ï¸ Class DeÄŸiÅŸkeninin DaÄŸÄ±lÄ±mÄ± âš–ï¸

Ä°kinci gÃ¶rselleÅŸtirmede ise, class sÃ¼tunundaki deÄŸerlerin daÄŸÄ±lÄ±mÄ± gÃ¶rselleÅŸtirilir. Bu tÃ¼r bir grafik, sÄ±nÄ±flar arasÄ±nda dengesiz bir daÄŸÄ±lÄ±m olup olmadÄ±ÄŸÄ±nÄ± anlamaya yardÄ±mcÄ± olur.

sns.countplot(data=df, x="class")
sns.countplot() fonksiyonu, belirtilen sÃ¼tundaki her bir deÄŸerin kaÃ§ kere tekrar ettiÄŸini gÃ¶steren bir sayÄ±m grafiÄŸi oluÅŸturur.

Burada, class sÃ¼tunundaki her bir sÄ±nÄ±fÄ±n sayÄ±sÄ± gÃ¶rselleÅŸtirilir.
Bu, verinin sÄ±nÄ±flar arasÄ±nda dengesiz olup olmadÄ±ÄŸÄ±nÄ± anlamamÄ±za olanak saÄŸlar. Ã–zellikle sÄ±nÄ±flar arasÄ±nda bÃ¼yÃ¼k farklar varsa, modelleme aÅŸamasÄ±nda bu dengeyi dikkate almak gerekebilir. âš–ï¸



				ğŸ”„ Train-Test Split ğŸ”„

Modelleme sÃ¼recinde, verinin eÄŸitim (train) ve test (test) setlerine ayrÄ±lmasÄ±, modelin genelleme yeteneÄŸini test etmek iÃ§in kritik Ã¶neme sahiptir. Bu adÄ±mda, veriyi eÄŸitim ve test setlerine ayÄ±rarak modelin performansÄ±nÄ± daha doÄŸru bir ÅŸekilde deÄŸerlendirebiliriz.

ğŸ¯ Ã–zelliklerin ve hedef deÄŸiÅŸkenin ayrÄ±lmasÄ± ğŸ¯

x = df.drop("class", axis=1)
y = df["class"]

Veri kÃ¼mesindeki Ã¶zellikler (x) ve hedef deÄŸiÅŸken (y) ayrÄ±lÄ±r. class sÃ¼tunu hedef deÄŸiÅŸken olarak kabul edilir, diÄŸer tÃ¼m sÃ¼tunlar ise Ã¶zellikler olarak kullanÄ±lÄ±r.

ğŸ”¢Kategorik verilerin sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi ğŸ”¢

x = pd.get_dummies(x, drop_first=True)
x.columns

Kategorik deÄŸiÅŸkenler, modelin anlayabileceÄŸi sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmelidir. Bunun iÃ§in get_dummies() fonksiyonu kullanÄ±lÄ±r. drop_first=True parametresi, her kategori iÃ§in bir sÃ¼tun ekleyip birini Ã§Ä±karÄ±r ve multicollinearity (Ã§oklu doÄŸrusal iliÅŸki) sorununu engeller.

ğŸ“Š Veri setinin eÄŸitim ve test olarak ayrÄ±lmasÄ± ğŸ“Š

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=9)

train_test_split() fonksiyonu ile veri seti eÄŸitim ve test setlerine ayrÄ±lÄ±r. Burada test_size=0.1 ile verilerin %10'u test iÃ§in, geri kalan %90'Ä± ise eÄŸitim iÃ§in ayrÄ±lÄ±r. random_state=9 parametresi, iÅŸlemin her seferinde aynÄ± sonuÃ§larÄ± vermesini saÄŸlar.


			ğŸ¤– Model EÄŸitimi ve DeÄŸerlendirme ğŸ¤–

Veri hazÄ±rlama ve gÃ¶rselleÅŸtirme aÅŸamalarÄ±ndan sonra, modelin eÄŸitilmesi ve test edilmesi sÃ¼recine geÃ§ilir. Bu adÄ±mda, model eÄŸitim verisiyle Ã¶ÄŸrenir ve test verileriyle performansÄ± deÄŸerlendirilir.

ğŸ“š AdaBoost Modelinin EÄŸitilmesi ğŸ“š

AdaBoost, zayÄ±f sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ± birleÅŸtirerek gÃ¼Ã§lÃ¼ bir sÄ±nÄ±flandÄ±rÄ±cÄ± oluÅŸturmayÄ± saÄŸlayan bir topluluk Ã¶ÄŸrenme algoritmasÄ±dÄ±r. Ä°lk olarak, AdaBoost sÄ±nÄ±fÄ±nÄ± Ã§aÄŸÄ±rÄ±p eÄŸitim iÃ§in hazÄ±r hale getireceÄŸiz.

from sklearn.ensemble import AdaBoostClassifier
model = AdaBoostClassifier(n_estimators=3)

n_estimators=3 parametresi, modelde kullanÄ±lacak zayÄ±f sÄ±nÄ±flandÄ±rÄ±cÄ± sayÄ±sÄ±nÄ± belirler (bu Ã¶rnekte 3 adet).

ğŸ“ Modelin EÄŸitilmesi ğŸ“

Modeli eÄŸitmek iÃ§in, eÄŸitim verilerini kullanarak fit() fonksiyonu ile modelin parametrelerini optimize ederiz.

model.fit(X_train, y_train)

ğŸ”® Test Verisi ile Tahmin Yapma ğŸ”®
EÄŸitilen model, test verileri Ã¼zerinde tahminlerde bulunarak performansÄ±nÄ± Ã¶lÃ§eriz.

mantar_pred = model.predict(X_test)


				ğŸ§‘â€ğŸ’» Model DeÄŸerlendirme ğŸ§‘â€ğŸ’»

ğŸ”¢ Confusion Matrix ğŸ”¢

Confusion Matrix, modelin doÄŸruluÄŸunu ve yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rmalarÄ±nÄ± gÃ¶rsel olarak anlamamÄ±za yardÄ±mcÄ± olur. Bu matriste, doÄŸru tahminler ve yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rmalar gÃ¶sterilir.

from sklearn.metrics import ConfusionMatrixDisplay

Ä°lk olarak ConfusionMatrixDisplay.from_estimator() fonksiyonu ile confusion matrix gÃ¶rseli oluÅŸturulur. Normal olmayan (raw) ve normalize edilmiÅŸ (true) sonuÃ§lar gÃ¶rselleÅŸtirilir.

ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)
ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, normalize="true")

Ä°lk komut, orijinal confusion matrix'i gÃ¶sterirken, ikinci komut normalize edilmiÅŸ formda confusion matrix'i sunar. Normalize edilmiÅŸ matrix, doÄŸruluÄŸun yÃ¼zdelik dilimlerdeki daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶sterir.

ğŸ“Š Classification Report ğŸ“Š

classification_report() fonksiyonu, modelin her sÄ±nÄ±f iÃ§in doÄŸruluk (accuracy), geri Ã§aÄŸÄ±rma (recall), kesinlik (precision) ve F1 skorlarÄ±nÄ± gÃ¶sterir. Bu metrikler, modelin her sÄ±nÄ±f Ã¼zerindeki performansÄ±nÄ± anlamamÄ±za yardÄ±mcÄ± olur.

print(classification_report(y_test, mantar_pred))

classification_report() fonksiyonu, test verisi Ã¼zerinde yapÄ±lan tahminleri ve gerÃ§ek sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rarak modelin her sÄ±nÄ±f iÃ§in performansÄ±nÄ± gÃ¶sterir. YÃ¼ksek precision ve recall deÄŸerleri, modelin doÄŸru tahminlerde bulunduÄŸunu gÃ¶sterir.


			ğŸ“Š En Ä°yi DeÄŸeri Bulmak ğŸ“Š

Modelin performansÄ±nÄ± optimize etmek iÃ§in farklÄ± parametrelerle denemeler yapÄ±labilir. Bu adÄ±mda, modelin n_estimators parametresi Ã¼zerinde deÄŸiÅŸiklikler yaparak en uygun deÄŸeri bulmaya Ã§alÄ±ÅŸÄ±yoruz.

ğŸ”¢ Hata OranÄ± Hesaplama ğŸ”¢

n_estimators parametresi, modelin oluÅŸturacaÄŸÄ± zayÄ±f sÄ±nÄ±flandÄ±rÄ±cÄ± sayÄ±sÄ±nÄ± belirtir. Bu deÄŸeri 1 ile 30 arasÄ±nda deÄŸiÅŸtirerek, her bir n_estimators deÄŸeri iÃ§in modelin baÅŸarÄ±mÄ±nÄ± Ã¶lÃ§eriz.

hata_oranÄ± =[]
for mantar_est in range(1,30):
    model = AdaBoostClassifier(n_estimators=mantar_est)
    model.fit(X_train, y_train)
    model_deneme_pred = model.predict(X_test)
    hata = 1 - accuracy_score(y_test, model_deneme_pred)
    hata_oranÄ±.append(hata)

Bu dÃ¶ngÃ¼de, her n_estimators deÄŸeri iÃ§in model eÄŸitilir, tahmin yapÄ±lÄ±r ve hata oranÄ± hesaplanÄ±r.
En dÃ¼ÅŸÃ¼k hata oranÄ±, en iyi modelin seÃ§ilmesine yardÄ±mcÄ± olacaktÄ±r.

ğŸ’¡ Veri KÃ¼mesini Ã–rneklem SeÃ§erek KÃ¼Ã§Ã¼ltme ğŸ’¡

Veri kÃ¼mesi Ã§ok bÃ¼yÃ¼kse ve modelin eÄŸitimi zaman alÄ±yorsa, rastgele Ã¶rnekleme yaparak veri kÃ¼mesini kÃ¼Ã§Ã¼ltmek iÅŸlemi daha verimli hale getirebilir. Bu adÄ±mda, veri kÃ¼mesinin %5'ini rastgele seÃ§iyoruz.

df_sample = df.sample(frac=0.05, random_state=9)
frac=0.05: Veri kÃ¼mesinin %5'ini seÃ§er.
random_state=9: Rastgele seÃ§im iÅŸlemini sabitler, bÃ¶ylece her Ã§alÄ±ÅŸtÄ±rmada aynÄ± sonuÃ§larÄ± alÄ±rÄ±z.
Bu iÅŸlem, bÃ¼yÃ¼k veri kÃ¼mesinde daha hÄ±zlÄ± model eÄŸitimi yapmamÄ±za olanak saÄŸlar.

ğŸ” SeÃ§ilen Ã–rnek Veri KÃ¼mesinin Bilgileri ğŸ”

SeÃ§ilen kÃ¼Ã§Ã¼k Ã¶rnek veri kÃ¼mesinin genel bilgilerini gÃ¶rmek iÃ§in info() fonksiyonunu kullanÄ±yoruz.

df_sample.info()
Bu komut, Ã¶rnek veri kÃ¼mesinin yapÄ±sÄ±nÄ± ve her sÃ¼tundaki veri tiplerini gÃ¶sterir.
Bu adÄ±mlar, modelin daha verimli eÄŸitilmesi ve en uygun parametrelerin bulunmasÄ±na yardÄ±mcÄ± olur.


		ğŸ“Š Ã–zelliklerin Ã–nemliliÄŸi ve GÃ¶rselleÅŸtirilmesi ğŸ“Š

Modelin eÄŸitilmesinin ardÄ±ndan, her bir Ã¶zelliÄŸin modelin kararÄ±na ne kadar katkÄ± saÄŸladÄ±ÄŸÄ±nÄ± gÃ¶rmek Ã¶nemlidir. AdaBoost sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±, Ã¶zelliklerin Ã¶nem derecelerini belirleyebilir. Bu adÄ±mda, her bir Ã¶zelliÄŸin modeldeki aÄŸÄ±rlÄ±ÄŸÄ±nÄ± inceleyeceÄŸiz.

ğŸ”¢ Ã–zelliklerin AÄŸÄ±rlÄ±klarÄ±nÄ± Hesaplama ğŸ”¢

AdaBoost, modelde kullanÄ±lan her Ã¶zelliÄŸin (feature) Ã¶nem derecesini feature_importances_ parametresi ile hesaplar. Bu, hangi Ã¶zelliklerin daha fazla etkili olduÄŸunu anlamamÄ±za yardÄ±mcÄ± olur.

model.feature_importances_

AdaBoost sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±, bazÄ± Ã¶zelliklerin Ã¶nemini sÄ±fÄ±rlayarak, modelin daha verimli Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar. Bu, modelin yalnÄ±zca Ã¶nemli Ã¶zelliklere odaklanmasÄ±nÄ± saÄŸlar.

ğŸ“‰ Ã–zelliklerin Ã–nem Derecelerini GÃ¶sterme ğŸ“‰

Bu adÄ±mda, Ã¶zelliklerin katsayÄ±larÄ±nÄ± bir DataFrame'e alÄ±p, yalnÄ±zca pozitif katsayÄ±larÄ± gÃ¶steriyoruz. Bu sayede Ã¶nemli Ã¶zellikleri daha iyi analiz edebiliriz.

feature_df = pd.DataFrame(index=x.columns, columns=["KatsayÄ±"], data=model.feature_importances_)

Bu, her bir Ã¶zelliÄŸin modeldeki Ã¶nem derecesini bir "KatsayÄ±" olarak tutar. Daha sonra, sÄ±fÄ±rdan bÃ¼yÃ¼k olanlarÄ± filtreliyoruz.

ğŸ” Ã–zellikleri SÄ±ralama ğŸ”

Ã–zelliklerin katsayÄ±larÄ±nÄ± bÃ¼yÃ¼klÃ¼k sÄ±rasÄ±na gÃ¶re sÄ±ralÄ±yoruz. Bu, hangi Ã¶zelliklerin modelde daha fazla etkiye sahip olduÄŸunu anlamamÄ±za yardÄ±mcÄ± olur.

feature_df = feature_df[feature_df["KatsayÄ±"] > 0]
feature_df = feature_df.sort_values("KatsayÄ±")

Burada, yalnÄ±zca Ã¶nemli olan Ã¶zellikleri gÃ¶steriyoruz ve bu Ã¶zellikleri sÄ±ralayarak hangi Ã¶zelliklerin modelde daha fazla rol oynadÄ±ÄŸÄ±nÄ± net bir ÅŸekilde gÃ¶rebiliriz.

ğŸ“Š Ã–zelliklerin GÃ¶rselleÅŸtirilmesi ğŸ“Š

Ã–zelliklerin Ã¶nem derecelerini gÃ¶rselleÅŸtirmek, hangi Ã¶zelliklerin model iÃ§in kritik olduÄŸunu daha kolay anlamamÄ±za olanak tanÄ±r.

sns.barplot(x=feature_df.index, y="KatsayÄ±", data=feature_df)
plt.xticks(rotation=90)
Bu barplot, her bir Ã¶zelliÄŸin modeldeki Ã¶nem derecesini gÃ¶rsel olarak gÃ¶sterir. Ã–zelliklerin isimleri x ekseninde, Ã¶nem dereceleri ise y ekseninde yer alÄ±r.

ğŸ”¬ Kategorik Ã–zelliklerin DaÄŸÄ±lÄ±mÄ±nÄ± GÃ¶rselleÅŸtirme ğŸ”¬

Kategorik Ã¶zelliklerin sÄ±nÄ±flara gÃ¶re daÄŸÄ±lÄ±mÄ±nÄ± incelemek, verinin dengesini gÃ¶rmek iÃ§in faydalÄ±dÄ±r. Bu adÄ±mda, odor ve spore-print-color gibi kategorik deÄŸiÅŸkenlerin sÄ±nÄ±flara gÃ¶re daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rselleÅŸtiriyoruz.

sns.countplot(x="odor", hue="class", data=df)
sns.countplot(x="spore-print-color", hue="class", data=df)
Bu gÃ¶rseller, "odor" ve "spore-print-color" Ã¶zelliklerinin farklÄ± sÄ±nÄ±flar arasÄ±ndaki daÄŸÄ±lÄ±mlarÄ±nÄ± gÃ¶sterecektir.


		ğŸš€ Final Modelin EÄŸitilmesi ve DeÄŸerlendirilmesi ğŸš€
	
Modelin son halini almak iÃ§in parametreleri en iyi ÅŸekilde ayarladÄ±ktan sonra, final modelini eÄŸitiyoruz. AdaBoostClassifier ile en uygun n_estimators deÄŸeri olarak 18'i seÃ§tik. Bu, modelin baÅŸarÄ±mÄ±nÄ± en iyi ÅŸekilde yansÄ±tan deÄŸeri saÄŸladÄ±.

ğŸ”§ Final Modelin EÄŸitilmesi ğŸ”§

En son modelin eÄŸitimini, en uygun parametrelerle yapÄ±yoruz. Bu adÄ±mda, AdaBoostClassifier sÄ±nÄ±fÄ±ndan bir model oluÅŸturup, eÄŸitim verileri ile modelimizi eÄŸitiyoruz.

final_model = AdaBoostClassifier(n_estimators=18)
final_model.fit(X_train, y_train)

Model, 18 zayÄ±f sÄ±nÄ±flandÄ±rÄ±cÄ± (n_estimators=18) ile eÄŸitim aldÄ±. Bu, modelin kararlarÄ±nÄ± oluÅŸtururken kullanacaÄŸÄ± zayÄ±f sÄ±nÄ±flandÄ±rÄ±cÄ± sayÄ±sÄ±nÄ± belirler.

ğŸ”® Test Verisi Ãœzerinden Tahmin Yapmak ğŸ”®

EÄŸitilen final modelini test verisi Ã¼zerinde kullanarak tahminler yapÄ±yoruz. Bu adÄ±mda, modelin performansÄ±nÄ± gÃ¶rmek amacÄ±yla tahminler elde ediyoruz.


final_pred = final_model.predict(X_test)

Bu komut, test verisi Ã¼zerinden modelin tahminlerini elde eder ve her bir test Ã¶rneÄŸi iÃ§in hangi sÄ±nÄ±fa ait olduÄŸunu tahmin eder.

ğŸ“Š Confusion Matrix GÃ¶rselleÅŸtirilmesi ğŸ“Š

Modelin baÅŸarÄ±mÄ±nÄ± daha ayrÄ±ntÄ±lÄ± gÃ¶rmek iÃ§in Confusion Matrix kullanÄ±yoruz. Bu, modelin doÄŸru ve yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rmalarÄ±nÄ± gÃ¶sterir. Normalize edilmemiÅŸ ve normalize edilmiÅŸ hallerini gÃ¶rselleÅŸtiriyoruz.

ConfusionMatrixDisplay.from_estimator(final_model, X_test, y_test)
ConfusionMatrixDisplay.from_estimator(final_model, X_test, y_test, normalize="true")

Ä°lk grafik, ham sayÄ±larla Confusion Matrix'i gÃ¶sterirken, normalize edilmiÅŸ grafik, her sÄ±nÄ±fÄ±n doÄŸruluÄŸunu gÃ¶sterir.

ğŸ“‹ SÄ±nÄ±flandÄ±rma Raporu ğŸ“‹

Modelin her sÄ±nÄ±f iÃ§in doÄŸruluk (accuracy), geri Ã§aÄŸÄ±rma (recall), kesinlik (precision) ve F1 skoru gibi metriklerini gÃ¶rmek iÃ§in classification_report() fonksiyonunu kullanÄ±yoruz.

print(classification_report(y_test, final_pred))

Bu rapor, modelin performansÄ±nÄ± ayrÄ±ntÄ±lÄ± olarak gÃ¶sterir. YÃ¼ksek precision ve recall deÄŸerleri, modelin doÄŸru tahminlerde bulunduÄŸunu gÃ¶sterir.

				ğŸ”„ GENEL TEKRAR ğŸ”„

# KÃ¼tÃ¼phanelerin import edilmesi

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Veriyi yÃ¼kleyelim ve genel bilgilerimizi gÃ¶relim

df = pd.read_csv("mushrooms.csv")
df.info()
df.isna().sum().sum()
df.describe().transpose()

# Benzersiz deÄŸerlerin sayÄ±sÄ±nÄ± analiz edelim

df.describe().T.sort_values(by="unique")

# EÅŸsiz deÄŸerler ve sayÄ±larÄ±

pd.concat({"EÅŸsiz deÄŸer": df.apply(pd.unique), "sayÄ±sÄ±": df.nunique()}, axis=1)

# 'class' sÃ¼tunundaki deÄŸerlerin sayÄ±sÄ±nÄ± gÃ¶rselleÅŸtirelim

sns.countplot(data=df, x="class")
df["class"].value_counts()

# Her sÃ¼tundaki benzersiz deÄŸer sayÄ±sÄ±nÄ± Ã§ubuk grafikle gÃ¶rselleÅŸtirelim

sns.barplot(data=df.describe().transpose().reset_index().sort_values("unique"), x="index", y="unique")
plt.xticks(rotation=90)

# Veri kÃ¼mesinin eÄŸitim ve test verisine bÃ¶lÃ¼nmesi

x = df.drop("class", axis=1)
y = df["class"]
x = pd.get_dummies(x, drop_first=True)

# EÄŸitim ve test verilerine ayÄ±rma

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=9)

# AdaBoost modelini oluÅŸturma ve eÄŸitme

from sklearn.ensemble import AdaBoostClassifier
model = AdaBoostClassifier(n_estimators=3)
model.fit(X_train, y_train)
mantar_pred = model.predict(X_test)

# Modelin deÄŸerlendirilmesi

from sklearn.metrics import classification_report, ConfusionMatrixDisplay, accuracy_score
ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)
ConfusionMatrixDisplay.from_estimator(model, X_test, y_test, normalize="true")
print(classification_report(y_test, mantar_pred))

# En iyi model iÃ§in n_estimators parametresini ayarlama

hata_oranÄ± = []
for mantar_est in range(1, 30):
    model = AdaBoostClassifier(n_estimators=mantar_est)
    model.fit(X_train, y_train)
    model_deneme_pred = model.predict(X_test)
    hata = 1 - accuracy_score(y_test, model_deneme_pred)
    hata_oranÄ±.append(hata)

# Veri kÃ¼mesinin %5'ini rastgele seÃ§me (Ã¶rnekleme)

df_sample = df.sample(frac=0.05, random_state=9)
df_sample.info()

# Hata oranÄ± grafiklerini Ã§izme

plt.plot(range(1, 30), hata_oranÄ±)

# Modelin Ã¶zelliklerin Ã¶nem derecelerini inceleme

model.feature_importances_
feature_df = pd.DataFrame(index=x.columns, columns=["KatsayÄ±"], data=model.feature_importances_)
feature_df = feature_df[feature_df["KatsayÄ±"] > 0]
feature_df = feature_df.sort_values("KatsayÄ±")
sns.barplot(x=feature_df.index, y="KatsayÄ±", data=feature_df)
plt.xticks(rotation=90)

# Final modelin eÄŸitilmesi

final_model = AdaBoostClassifier(n_estimators=18)
final_model.fit(X_train, y_train)
final_pred = final_model.predict(X_test)

# Final modelin deÄŸerlendirilmesi

ConfusionMatrixDisplay.from_estimator(final_model, X_test, y_test)
ConfusionMatrixDisplay.from_estimator(final_model, X_test, y_test, normalize="true")
print(classification_report(y_test, final_pred))

 			âš ï¸ Dikkat Edilmesi Gerekenler âš ï¸

Veri TemizliÄŸi ve Ã–n Ä°ÅŸleme ğŸ§¹: Verinin eksiksiz ve doÄŸru olduÄŸundan emin olun. Eksik veriler varsa bunlarÄ± ele almak iÃ§in uygun yÃ¶ntemler (Ã¶rneÄŸin, doldurma, Ã§Ä±karma) kullanÄ±lmalÄ±.

Model SeÃ§imi ve Parametre Ayarlama âš™ï¸: AdaBoost gibi modellerin parametreleri dikkatlice ayarlanmalÄ±dÄ±r (Ã¶rneÄŸin, n_estimators parametresi). En iyi parametreyi bulmak iÃ§in testler yapÄ±lmalÄ±dÄ±r.

Modelin DeÄŸerlendirilmesi ğŸ“Š: Modelin baÅŸarÄ±mÄ±nÄ± sadece doÄŸruluk (accuracy) ile deÄŸil, aynÄ± zamanda Confusion Matrix ve sÄ±nÄ±flandÄ±rma raporuyla deÄŸerlendirin. Bu, modelin her sÄ±nÄ±f iÃ§in ne kadar doÄŸru tahmin yaptÄ±ÄŸÄ± hakkÄ±nda daha fazla bilgi verir.

Ã–zelliklerin Ã–nem Dereceleri ğŸ”: Modelin hangi Ã¶zelliklere daha fazla Ã¶nem verdiÄŸini inceleyerek, gerekirse Ã¶zellik mÃ¼hendisliÄŸi yaparak gereksiz Ã¶zellikleri Ã§Ä±karabilirsiniz.

Test Verisi KullanÄ±mÄ± ğŸ§ª: Modelin aÅŸÄ±rÄ± uyum (overfitting) yapmadÄ±ÄŸÄ±ndan emin olmak iÃ§in test verisi Ã¼zerinden doÄŸru deÄŸerlendirme yapÄ±lmalÄ±dÄ±r. EÄŸitim verisi ile test verisinin karÄ±ÅŸmamasÄ±na dikkat edin.


		ğŸŒ³ğŸ”¥ Random Forest ve AdaBoost'ta get_dummies() KullanÄ±mÄ± ğŸŒ³ğŸ”¥

Makine Ã¶ÄŸrenmesi modellerinde, Ã¶zellikle Random Forest ğŸŒ² ve AdaBoost âš¡ gibi algoritmalarda, baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin (X) tamamen sayÄ±sal olmasÄ± gerekir. Ancak, hedef deÄŸiÅŸken (y) her zaman sayÄ±sal olmak zorunda deÄŸildir.

Bu yÃ¼zden bazen pd.get_dummies() fonksiyonunu kullanarak kategorik deÄŸiÅŸkenleri sayÄ±sal hale getiriyoruz. Ancak, hangi deÄŸiÅŸken iÃ§in get_dummies() uygulanmasÄ± gerektiÄŸi modele baÄŸlÄ±dÄ±r.

1ï¸âƒ£ Random Forest'ta get_dummies() KullanÄ±mÄ± 1ï¸âƒ£

âœ… Random Forest modeli, baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin (X) numerik olmasÄ±nÄ± zorunlu kÄ±lar. Bu yÃ¼zden X iÃ§in get_dummies() uygulamak gerekir.

âŒ Hedef deÄŸiÅŸken (y) iÃ§in get_dummies() kullanmamÄ±za gerek yoktur. Ã‡Ã¼nkÃ¼ RandomForestClassifier zaten kategorik y ile Ã§alÄ±ÅŸabilir.

	ğŸš« YanlÄ±ÅŸ ama Ã§alÄ±ÅŸÄ±r ğŸš«

y = pd.get_dummies(df["Class"], drop_first=True)  # (Bunu yapmamÄ±za gerek yoktu!)

âœ… DoÄŸru ve yeterli olan:


y = df["Class"]  # Y zaten kategorik olduÄŸu iÃ§in ekstra dÃ¶nÃ¼ÅŸÃ¼m gerekmiyor.
ğŸ”¹ SonuÃ§:

âœ… X iÃ§in get_dummies() kullanmak ÅŸart.
ğŸš« y iÃ§in get_dummies() gereksiz, Ã§Ã¼nkÃ¼ sklearn zaten kategorik deÄŸerleri iÅŸleyebiliyor.

2ï¸âƒ£ AdaBoost'ta get_dummies() KullanÄ±mÄ±; 2ï¸âƒ£

âœ… AdaBoost modeli iÃ§in de baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin (X) tamamen sayÄ±sal olmasÄ± gerekir. Bu yÃ¼zden yine get_dummies() iÅŸlemi X iÃ§in uygulanmalÄ±dÄ±r.

âŒ Ancak, y iÃ§in get_dummies() kullanmamÄ±za gerek yoktur. Ã‡Ã¼nkÃ¼ AdaBoost, hedef deÄŸiÅŸkenin kategorik olmasÄ±nÄ± zaten destekler.

âœ… DoÄŸru kullanÄ±m:

x = pd.get_dummies(df.drop("class", axis=1), drop_first=True)  # X iÃ§in sayÄ±sal dÃ¶nÃ¼ÅŸÃ¼m ÅŸart
y = df["class"]  # Y doÄŸrudan kategorik olabilir, ekstra dÃ¶nÃ¼ÅŸÃ¼m gerekmiyor.

ğŸ”¹ SonuÃ§:

âœ… X iÃ§in get_dummies() kullanmak ÅŸart.
ğŸš« y iÃ§in get_dummies() gereksiz, Ã§Ã¼nkÃ¼ AdaBoost zaten kategorik y ile Ã§alÄ±ÅŸabiliyor.

ğŸ¯ Genel SonuÃ§: Ne YapmalÄ±yÄ±z? ğŸ¯

âœ… BaÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) â†’ Her zaman sayÄ±sal olmalÄ±! Bu yÃ¼zden pd.get_dummies(X) kullanÄ±lÄ±r.
âœ… Hedef deÄŸiÅŸken (y) â†’ Scikit-learn modelleri genellikle doÄŸrudan kategorik y ile Ã§alÄ±ÅŸabilir. Bu yÃ¼zden pd.get_dummies(y) gereksizdir.

ğŸ”¹ Random Forest ğŸŒ² ve AdaBoost âš¡ iÃ§in X'i dummies'e Ã§evirmek zorunlu.
ğŸ”¹ Ancak y iÃ§in get_dummies() yapmak gereksizdir, Ã§Ã¼nkÃ¼ modeller zaten kategorik y ile Ã§alÄ±ÅŸabiliyor.

ğŸ“Œ Ã–zetle ğŸ“Œ

âœ” X iÃ§in pd.get_dummies() zorunludur.
âŒ y iÃ§in pd.get_dummies() yapmak gereksizdir!








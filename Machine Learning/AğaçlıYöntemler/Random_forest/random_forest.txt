ğŸŒ² Random Forest Nedir?
Random Forest, birÃ§ok karar aÄŸacÄ±nÄ±n (Decision Tree) birleÅŸimiyle oluÅŸan gÃ¼Ã§lÃ¼ bir makine Ã¶ÄŸrenmesi algoritmasÄ±dÄ±r. ğŸŒ³ğŸŒ³ğŸŒ³
Bu algoritma, ensemble learning yÃ¶ntemini kullanÄ±r. Yani birden fazla modelin sonucunu birleÅŸtirerek daha doÄŸru tahminler yapar. ğŸ¤ğŸ“Š

ğŸŒ³ Decision Tree Nedir?

Decision Tree, veriyi dallara ayÄ±rarak sÄ±nÄ±flandÄ±rma veya regresyon yapar. ğŸŒ¿ Her dÃ¼ÄŸÃ¼mde bir Ã¶zellik Ã¼zerinden karar verilir ve veri dallara ayrÄ±lÄ±r.

ğŸ¤” Peki, Random Forest ile Decision Tree ArasÄ±ndaki Fark Ne?

ğŸ†š KarÅŸÄ±laÅŸtÄ±rma	ğŸŒ³ Decision Tree		  ğŸŒ² Random Forest
ğŸ¯ Genel YapÄ±	Tek bir aÄŸaÃ§ kullanÄ±lÄ±r	Birden fazla karar aÄŸacÄ± kullanÄ±lÄ±r
ğŸ›¡ï¸ Overfitting	Overfittingâ€™e yatkÄ±ndÄ±r	Overfitting riski daha dÃ¼ÅŸÃ¼ktÃ¼r
ğŸ“ˆ DoÄŸruluk	Daha dÃ¼ÅŸÃ¼k olabilir	Genelde daha yÃ¼ksek doÄŸruluk saÄŸlar
ğŸ§  Karar Verme	Tek aÄŸacÄ±n sonucuna dayanÄ±r	BirÃ§ok aÄŸacÄ±n Ã§oÄŸunluk kararÄ±nÄ± alÄ±r (oylama yÃ¶ntemi)

ğŸ› ï¸ Random Forest NasÄ±l Ã‡alÄ±ÅŸÄ±r?

ğŸ“Š Veri BÃ¶lme (Bootstrapping): EÄŸitim verisinden rastgele Ã¶rnekler alÄ±nÄ±r.
ğŸŒ¿ Birden Fazla Karar AÄŸacÄ±: Her Ã¶rnek iÃ§in farklÄ± bir karar aÄŸacÄ± eÄŸitilir.
ğŸ—³ï¸ Oylama (Classification) veya Ortalama Alma (Regression):
SÄ±nÄ±flandÄ±rmada: Birden fazla aÄŸacÄ±n Ã§oÄŸunluk kararÄ± alÄ±nÄ±r. ğŸ—³ï¸
Regresyonda: AÄŸaÃ§larÄ±n tahminlerinin ortalamasÄ± alÄ±nÄ±r. ğŸ“ˆ
ğŸ’ DiÄŸer Regresyon Modellerinden AyÄ±ran Ã–zellikler:
âœ… DoÄŸruluk: Birden fazla modelin birleÅŸimi olduÄŸu iÃ§in daha kararlÄ±dÄ±r. ğŸ“Š
âœ… Overfitting AzlÄ±ÄŸÄ±: Birden fazla aÄŸacÄ±n birleÅŸimi genelde daha iyi genelleme saÄŸlar. ğŸ›¡ï¸
âœ… Ã–zellik Ã–nemi: Hangi deÄŸiÅŸkenin daha Ã¶nemli olduÄŸunu gÃ¶sterebilir. ğŸ’¡
âœ… Lineer Olmayan Verilere Uyum: KarmaÅŸÄ±k iliÅŸkileri iyi Ã¶ÄŸrenebilir. ğŸ”„

ğŸ’¡ Ne Zaman Random Forest KullanÄ±lÄ±r?

KarmaÅŸÄ±k ve bÃ¼yÃ¼k veri setlerinde ğŸ“Š
DoÄŸruluÄŸun Ã¶nemli olduÄŸu sÄ±nÄ±flandÄ±rma veya regresyon problemlerinde ğŸ¯
Veri setinde Ã§ok sayÄ±da Ã¶zellik (feature) olduÄŸunda ğŸ“ˆ
Overfittingâ€™ten kaÃ§Ä±nmak istediÄŸinizde ğŸ›¡ï¸

	ğŸ§ Penguen TÃ¼rlerini Random Forest ile SÄ±nÄ±flandÄ±rma â€“ğŸŒ²

1ï¸âƒ£ Veri HazÄ±rlÄ±ÄŸÄ± (Data Preparation) ğŸ“Š
Veriyi temizleme, eksik deÄŸerleri doldurma, Ã¶zellik mÃ¼hendisliÄŸi ve normalizasyon iÅŸlemleri yapÄ±lÄ±r.

df.isnull().sum()
df.info()
df["Class"].unique()
df["Class"].value_counts()
df.columns
df.corr(numeric_only=True)

2ï¸âƒ£ EÄŸitim ve Test Seti AyrÄ±mÄ± (Train-Test Split) âœ‚ï¸
Veriyi eÄŸitim (train) ve test (test) setlerine ayÄ±rarak modelin doÄŸruluÄŸunu test etmek iÃ§in verileri ayÄ±rmak Ã¶nemlidir.

3ï¸âƒ£ Model Kurulumu ve EÄŸitimi (Model Setup & Training) ğŸŒ²
Random Forest gibi modelin kurulumu yapÄ±lÄ±r, ardÄ±ndan eÄŸitim verileriyle model eÄŸitilir.

4ï¸âƒ£ Hiperparametre AramasÄ± (Hyperparameter Tuning) ğŸ§ª
Modelin performansÄ±nÄ± iyileÅŸtirmek iÃ§in hiperparametre aramasÄ± yapÄ±lÄ±r. Ã–rneÄŸin, aÄŸaÃ§ sayÄ±sÄ±, maksimum derinlik, minimum Ã¶rnek sayÄ±sÄ± gibi parametreler ayarlanabilir.

5ï¸âƒ£ Model DeÄŸerlendirmesi (Model Evaluation) ğŸ“Š
EÄŸitim tamamlandÄ±ktan sonra modelin baÅŸarÄ±sÄ±nÄ± test seti Ã¼zerinde deÄŸerlendirirsiniz. BaÅŸarÄ± metriÄŸi olarak doÄŸruluk (accuracy), F1 skoru, ROC eÄŸrisi gibi kriterler kullanÄ±labilir.

6ï¸âƒ£ En Ä°yi AÄŸaÃ§ SayÄ±sÄ±nÄ±n Belirlenmesi ğŸŒ³
Hiperparametre aramasÄ± ile en iyi aÄŸaÃ§ sayÄ±sÄ±nÄ± belirleyerek modelin daha iyi performans gÃ¶stermesini saÄŸlayabilirsiniz.


			ğŸ“ŠğŸ”ğŸŒ¡ï¸	Veri GÃ¶rselleÅŸtirme Ä°ÅŸlemleri ğŸ“ŠğŸ”ğŸŒ¡ï¸

1ï¸âƒ£ SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± - Count Plot ğŸ“Š

sns.countplot(x="Class", data=df)
x: Verinin hangi sÃ¼tunu kullanarak sÄ±klÄ±ÄŸÄ±nÄ± gÃ¶stereceÄŸinizi belirtir. Burada "Class" sÃ¼tunu, sÄ±nÄ±f etiketlerinin sayÄ±sÄ±nÄ± gÃ¶sterir.
data: Hangi DataFrame'den veri alacaÄŸÄ±nÄ±zÄ± belirtir.
BaÅŸlÄ±k: SÄ±nÄ±f Etiketlerine GÃ¶re DaÄŸÄ±lÄ±mÄ± GÃ¶ster

2ï¸âƒ£ Alan ve Ã‡evre ArasÄ±ndaki Ä°liÅŸki - Scatter Plot ğŸ”µ

sns.scatterplot(x="Area", y="Perimeter", data=df, alpha=0.3, hue="Class")
x ve y: Ä°ki Ã¶zellik arasÄ±ndaki iliÅŸkiyi gÃ¶rselleÅŸtirir. Burada "Area" (alan) ve "Perimeter" (Ã§evre) arasÄ±ndaki iliÅŸkiyi gÃ¶sterir.
alpha: NoktalarÄ±n ÅŸeffaflÄ±k derecesi. 0-1 arasÄ± bir deÄŸer alÄ±r, burada 0.3 kullanÄ±lmÄ±ÅŸtÄ±r, yani noktalar biraz ÅŸeffaf.
hue: Veriyi renk kategorilerine ayÄ±rÄ±r, burada "Class" kullanÄ±larak her sÄ±nÄ±f iÃ§in farklÄ± renkler atanÄ±r.

3ï¸âƒ£ Major Axis Length ve Eccentricity ArasÄ±ndaki Ä°liÅŸki - Joint Plot ğŸ”¶

sns.jointplot(kind="hex", x="Major_Axis_Length", y="Eccentricity", data=df)
kind: GÃ¶rselleÅŸtirmenin tÃ¼rÃ¼, burada "hex" kullanÄ±larak yoÄŸunluklarÄ± hexagonal harita ile gÃ¶steriyor.
x ve y: GÃ¶rselleÅŸtirilecek iki Ã¶zellik. Burada "Major_Axis_Length" (ana eksen uzunluÄŸu) ve "Eccentricity" (eksantriklik) arasÄ±ndaki iliÅŸkiyi gÃ¶steriyor.

4ï¸âƒ£ SÄ±nÄ±f Etiketlerine GÃ¶re Ã–zelliklerin Ä°liÅŸkisi - Pair Plot ğŸ”

sns.pairplot(df, hue="Class", palette="colorblind")
hue: Her bir "Class" iÃ§in farklÄ± renkler ile gÃ¶rselleÅŸtirme.
palette: Renk paleti seÃ§imi. Burada "colorblind" paleti, renk kÃ¶rlÃ¼ÄŸÃ¼ olanlar iÃ§in uygun bir palettir.

5ï¸âƒ£ Korelasyon Matrisinin GÃ¶rselleÅŸtirilmesi - Heatmap ğŸŒ¡ï¸

sns.heatmap(df.corr(numeric_only=True), annot=True, cmap="YlGnBu")
df.corr(numeric_only=True): Verinin sayÄ±sal Ã¶zelliklerinin korelasyonunu hesaplar.
annot: Her hÃ¼crenin iÃ§ine korelasyon deÄŸerlerini ekler.
cmap: Renk paleti. Burada "YlGnBu", sarÄ±, yeÅŸil ve mavi tonlarÄ±nÄ± iÃ§eriyor.


			ğŸ“Šâœ‚ï¸ EÄŸitim ve Test Setlerine AyÄ±rma ğŸ“Šâœ‚ï¸

1ï¸âƒ£ Veri HazÄ±rlÄ±ÄŸÄ± - BaÄŸÄ±msÄ±z ve BaÄŸÄ±mlÄ± DeÄŸiÅŸkenlerin AyrÄ±lmasÄ±

x = df.drop("Class", axis=1)
y = pd.get_dummies(df["Class"], drop_first=True)

x (BaÄŸÄ±msÄ±z DeÄŸiÅŸkenler):
Bu satÄ±rda, "Class" sÃ¼tunu dÄ±ÅŸÄ±ndaki tÃ¼m sÃ¼tunlar (Ã¶zellikler) baÄŸÄ±msÄ±z deÄŸiÅŸkenler olarak alÄ±nÄ±r. Yani, x veri Ã§erÃ§evesi sadece "Class" dÄ±ÅŸÄ±nda kalan sÃ¼tunlardan oluÅŸur. Bu, modelin tahmin yaparken kullanacaÄŸÄ± Ã¶zellikleri temsil eder.

y (BaÄŸÄ±mlÄ± DeÄŸiÅŸken):
y, sÄ±nÄ±f etiketlerini iÃ§erir. Fakat, "Class" sÃ¼tunu kategorik bir veri olduÄŸu iÃ§in, bunu modelin anlayacaÄŸÄ± ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rmemiz gerekir. pd.get_dummies fonksiyonu bu dÃ¶nÃ¼ÅŸÃ¼mÃ¼ saÄŸlar, yani one-hot encoding iÅŸlemi yapar.

drop_first=True parametresi, ilk kategoriyi dÃ¼ÅŸÃ¼rerek modelin gereksiz yere Ã§oklu lineer iliÅŸkiye girmesini engeller. Bu, genellikle dummy variable trap'ten kaÃ§Ä±nmak iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin, "Class" sÃ¼tununda "A", "B", "C" gibi Ã¼Ã§ sÄ±nÄ±f varsa, sadece "B" ve "C" sÄ±nÄ±flarÄ± kodlanÄ±r; "A" ise varsayÄ±lan kabul edilir.

2ï¸âƒ£ EÄŸitim ve Test Setlerine BÃ¶lme

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    x, y, test_size=0.1, random_state=9)
train_test_split:

Bu fonksiyon, verinizi eÄŸitim ve test setlerine bÃ¶ler.

x: BaÄŸÄ±msÄ±z deÄŸiÅŸkenlerin bulunduÄŸu veri seti.

y: BaÄŸÄ±mlÄ± deÄŸiÅŸkenlerin (sÄ±nÄ±flar) bulunduÄŸu veri seti.

test_size=0.1: Test setinin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ %10 olarak belirlenmiÅŸtir. Bu durumda, veri setinizin %90'Ä± eÄŸitim seti olarak kullanÄ±lacak, geri kalan %10'u ise modelin doÄŸruluÄŸunu test etmek iÃ§in ayrÄ±lacak.

random_state=9: Bu parametre, veri bÃ¶lme iÅŸlemini tekrarlanabilir hale getirir. FarklÄ± bir random_state deÄŸeri verirseniz, veri farklÄ± ÅŸekilde bÃ¶lÃ¼nÃ¼r.

Yorum: Test setinin boyutunu %10 olarak seÃ§miÅŸsiniz Ã§Ã¼nkÃ¼ veri setinizin bÃ¼yÃ¼k olduÄŸunu belirttiniz. Bu durumda, test setini kÃ¼Ã§Ã¼k tutmak mantÄ±klÄ± Ã§Ã¼nkÃ¼ modelin eÄŸitim iÃ§in daha fazla veri ile Ã§alÄ±ÅŸmasÄ± istenir.

3ï¸âƒ£ Veri Seti BoyutlarÄ±

len(X_train)
len(X_test)

len(X_train): EÄŸitim setinin veri boyutunu gÃ¶sterir. Bu, modelin eÄŸitim sÄ±rasÄ±nda kullanacaÄŸÄ± Ã¶rnek sayÄ±sÄ±nÄ± belirtir.

len(X_test): Test setinin veri boyutunu gÃ¶sterir. Bu, modelin doÄŸruluk oranÄ±nÄ± test etmek iÃ§in kullanÄ±lan Ã¶rnek sayÄ±sÄ±nÄ± belirtir.

Yorum-
EÄŸitim setiniz test setinden 9 kat daha bÃ¼yÃ¼k olacaktÄ±r, Ã§Ã¼nkÃ¼ test seti %10, eÄŸitim seti ise %90'dÄ±r.
Test setinin boyutu, eÄŸitim setine gÃ¶re Ã§ok kÃ¼Ã§Ã¼k olsa da, bu veri bÃ¼yÃ¼klÃ¼ÄŸÃ¼ yeterli olduÄŸu iÃ§in modelin doÄŸruluÄŸunu test etmek iÃ§in yeterlidir.

	      ğŸ”ğŸŒ² Hiper Orman: GridSearchCV ile RandomForest Parametre Optimizasyonu ğŸ”ğŸŒ²

Bu bÃ¶lÃ¼mde, RandomForestClassifier modelini optimize etmek iÃ§in GridSearchCV kullanarak Ã§eÅŸitli hiperparametreler Ã¼zerinde arama yapÄ±yoruz. Hedefimiz, en iyi parametre kombinasyonunu bulmak ve modelin performansÄ±nÄ± artÄ±rmaktÄ±r.


ğŸ” Kod: Hiper Orman iÃ§in Parametre Optimizasyonu ğŸ”

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# Denenecek parametreler
n_est = [9, 64, 128, 200]
max_feat = [1, 2, 3, 4]
bootstrap_sec = [True, False]
oob = [True, False]

parameters = {
    "n_estimators": n_est,
    "max_features": max_feat, 
    "bootstrap": bootstrap_sec,
    "oob_score": oob
}

# Modeli oluÅŸturuyoruz
random_forest = RandomForestClassifier()

# GridSearchCV ile parametre aramasÄ± yapÄ±yoruz
grid = GridSearchCV(random_forest, parameters)

# Modeli eÄŸitim verisiyle eÄŸitiyoruz
grid.fit(X_train, y_train)

# En iyi modeli ve parametreleri alÄ±yoruz
grid.best_estimator_

# En iyi parametreleri yazdÄ±rÄ±yoruz
grid.best_params_

# Test verisiyle tahmin yapÄ±yoruz
pilav_pred = grid.predict(X_test)


ğŸ”ğŸŒ² Parametrelerin AÃ§Ä±klamalarÄ± ğŸ”ğŸŒ²

1ï¸âƒ£ n_estimators (AÄŸaÃ§ SayÄ±sÄ±)

n_est = [9, 64, 128, 200]
AÄŸaÃ§ sayÄ±sÄ±nÄ± belirler. Random Forest modelinde kaÃ§ adet karar aÄŸacÄ± kullanÄ±lacaÄŸÄ±nÄ± ayarlar. AÄŸaÃ§ sayÄ±sÄ± arttÄ±kÃ§a model daha gÃ¼Ã§lÃ¼ hale gelir, ancak hesaplama maliyeti de artar.
Bu parametre iÃ§in farklÄ± deÄŸerler 9, 64, 128 ve 200 denenmiÅŸtir.

2ï¸âƒ£ max_features (Maksimum Ã–zellik SayÄ±sÄ±)

max_feat = [1, 2, 3, 4]
Bu parametre, her bir karar aÄŸacÄ±nÄ±n eÄŸitiminde kullanÄ±lan Ã¶zellik (feature) sayÄ±sÄ±nÄ± belirler.
Daha dÃ¼ÅŸÃ¼k bir deÄŸer, modelin daha basit hale gelmesine, daha yÃ¼ksek bir deÄŸer ise modelin daha karmaÅŸÄ±k ve hassas olmasÄ±na yol aÃ§ar. Burada 1, 2, 3 ve 4 Ã¶zellikleri denenmiÅŸtir.

max_features="sqrt" 
Bu parametre, Ã¶zellikle rastgele orman (Random Forest) gibi modellerde, her bÃ¶lme iÃ§in kullanÄ±lacak Ã¶zellik sayÄ±sÄ±nÄ±n toplam Ã¶zellik sayÄ±sÄ±nÄ±n karekÃ¶kÃ¼ kadar olmasÄ±nÄ± belirler. Bu, modelin Ã§eÅŸitliliÄŸini artÄ±rmaya ve aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi (overfitting) Ã¶nlemeye yardÄ±mcÄ± olur.

3ï¸âƒ£ bootstrap (Veri SeÃ§imi YÃ¶ntemi)

bootstrap_sec = [True, False]
Bootstrap parametresi, her aÄŸaÃ§ iÃ§in eÄŸitim verisinin nasÄ±l seÃ§ileceÄŸini belirler.
True: Her aÄŸaÃ§ iÃ§in rastgele veriler seÃ§ilir (veri Ã¶rneklemesi).
False: Her aÄŸaÃ§, tÃ¼m veriyi kullanÄ±r.
Bu seÃ§enek, modelin Ã§eÅŸitliliÄŸini artÄ±rmak ve aÅŸÄ±rÄ± uyumdan kaÃ§Ä±nmak iÃ§in Ã¶nemlidir.

4ï¸âƒ£ oob_score (Out-of-Bag Skoru)

oob = [True, False]
Out-of-Bag (OOB), yalnÄ±zca bootstrap=True olduÄŸunda Ã§alÄ±ÅŸÄ±r.
Bu parametre, eÄŸitim verisi dÄ±ÅŸÄ±nda kalan veriler ile modelin doÄŸruluÄŸunu hesaplamanÄ±zÄ± saÄŸlar. Yani, her aÄŸaÃ§ eÄŸitimde kullanÄ±lmayan verileri kullanarak doÄŸruluk Ã¶lÃ§Ã¼mÃ¼ yapar.
Bu, ekstra test verisi kullanmadan modelin baÅŸarÄ±sÄ±nÄ± deÄŸerlendirmek iÃ§in faydalÄ±dÄ±r.

 ğŸš€ SonuÃ§larÄ±n AlÄ±nmasÄ±  ğŸš€

grid.best_estimator_: Bu komut, GridSearchCV ile en iyi performansÄ± gÃ¶steren modelin hyperparametrelerle eÄŸitilmiÅŸ versiyonunu dÃ¶ndÃ¼rÃ¼r.

grid.best_params_: Bu komut, en iyi sonucu veren parametre kombinasyonlarÄ±nÄ± verir. Ã–rneÄŸin:

RandomForestClassifier(max_features=1, n_estimators=128)
Bu, en iyi performansÄ± gÃ¶steren parametrelerdir: 128 aÄŸaÃ§ ve 1 Ã¶zellik kullanarak.

Modelin Test Edilmesi:

pilav_pred = grid.predict(X_test):
Bu satÄ±r, test verisi Ã¼zerinde eÄŸitilmiÅŸ en iyi RandomForestClassifier modelini kullanarak tahmin yapar ve pilav_pred deÄŸiÅŸkenine kaydeder.

Bu iÅŸlem, hyperparametre optimizasyonu ile modelin doÄŸruluÄŸunu artÄ±rmayÄ± amaÃ§lar ve en iyi parametreler ile tahmin yapmayÄ± saÄŸlar.

		ğŸ“ŠğŸ’¡ DeÄŸerlendirme: Model PerformansÄ± Analizi ğŸ“ŠğŸ’¡

from sklearn.metrics import ConfusionMatrixDisplay, classification_report

# Confusion Matrix GÃ¶rselleÅŸtirmesi
ConfusionMatrixDisplay.from_estimator(grid, X_test, y_test, normalize="true")

# Modelin deÄŸerlendirilmesi
print(classification_report(y_test, pilav_pred))

ğŸ”¥ Confusion Matrix ve classification_report SonuÃ§larÄ± ğŸ”¥

1ï¸âƒ£ Confusion Matrix:

Confusion Matrix'in gÃ¶rselleÅŸtirilmesi ile modelin doÄŸru ve yanlÄ±ÅŸ tahminlerini daha kolay gÃ¶rselleÅŸtirebiliriz.
normalize="true" parametresi, matrisin normalize edilmesini saÄŸlar, bÃ¶ylece her sÄ±nÄ±fÄ±n model tarafÄ±ndan ne kadar doÄŸru sÄ±nÄ±flandÄ±rÄ±ldÄ±ÄŸÄ± oran olarak gÃ¶sterilir.

2ï¸âƒ£ classification_report:
Modelin precision, recall, f1-score ve accuracy gibi Ã¶nemli metriklerini gÃ¶steren bir rapordur.

Rapor SonuÃ§larÄ± ğŸ“Š

Precision: Modelin doÄŸru ÅŸekilde True veya False sÄ±nÄ±fÄ±nÄ± tahmin etme oranÄ±nÄ± gÃ¶sterir.
False: 0.94, True: 0.89
Recall: Modelin, gerÃ§ekte True veya False olanlarÄ± doÄŸru tahmin etme oranÄ±dÄ±r.
False: 0.87, True: 0.95
F1-Score: Precision ve recall'un harmonik ortalamasÄ±dÄ±r. Dengeyi Ã¶lÃ§er.
False: 0.91, True: 0.92
Accuracy: Modelin genel doÄŸruluk oranÄ±dÄ±r.
Genel doÄŸruluk: 0.91

Modelin genel doÄŸruluÄŸu %91 olarak yÃ¼ksek.
False sÄ±nÄ±fÄ±nÄ±n precision'Ä± yÃ¼ksek (0.94) ancak recall'Ä± biraz dÃ¼ÅŸÃ¼k (0.87).
True sÄ±nÄ±fÄ± daha yÃ¼ksek bir recall'a sahip (0.95), yani True sÄ±nÄ±fÄ±ndaki verileri doÄŸru sÄ±nÄ±flandÄ±rma oranÄ± Ã§ok iyi.
Bu rapor, modelin True sÄ±nÄ±fÄ± Ã¼zerinde daha iyi performans gÃ¶sterdiÄŸini, ancak False sÄ±nÄ±fÄ±ndaki bazÄ± verileri kaÃ§Ä±rabileceÄŸini gÃ¶steriyor.

		ğŸ“ˆğŸ” Estimator SayÄ±sÄ± Belirleme ve Performans DeÄŸerlendirmesi ğŸ“ˆğŸ”

KOD BÃ–LÃœMÃœ ;

from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

hata = []
yanlÄ±s_secim = []

# AÄŸaÃ§ sayÄ±sÄ±nÄ± 1'den 130'a kadar deniyoruz
for n in range(1, 130):
    rand_forest_class = RandomForestClassifier(n_estimators=n,
                                               bootstrap=True,
                                               oob_score=False,
                                               max_features=1)
    
    rand_forest_class.fit(X_train, y_train)
    pirinc_pred = rand_forest_class.predict(X_test)
    
    # Hata oranÄ±nÄ± hesaplÄ±yoruz
    error = 1 - accuracy_score(y_test, pirinc_pred)

    # YanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lan Ã¶rneklerin sayÄ±sÄ±nÄ± buluyoruz
    sample = y_test.to_numpy()
    sample = sample.reshape(1, -1)[0]
    n_missed = np.sum(pirinc_pred != sample)
---------------------------------------------------------------------------

Kodda sample Ne Ä°ÅŸe YarÄ±yor?

sample = y_test.to_numpy()
sample = sample.reshape(1,-1)[0]


Bu iki satÄ±rÄ±n yaptÄ±ÄŸÄ± ÅŸey ÅŸu:

y_test.to_numpy() â†’ y_test serisini NumPy dizisine Ã§eviriyor.
sample.reshape(1,-1)[0] â†’ Bu, normalde y_test zaten 1D (tek boyutlu) bir dizi olduÄŸu iÃ§in gereksiz ama olay ÅŸu:
EÄŸer y_test tek satÄ±r ve Ã§ok sÃ¼tundan oluÅŸan bir ÅŸeyse, bunu dÃ¼mdÃ¼z 1D dizi yapmaya Ã§alÄ±ÅŸÄ±yor.
Ama y_test zaten tek boyutlu bir seri olduÄŸundan, bu reshape iÅŸlemi boÅŸa gidiyor. 

-------------------------------------------------------------------------
    hata.append(error)
    yanlÄ±s_secim.append(n_missed)

# AÄŸaÃ§ sayÄ±sÄ±na karÅŸÄ± hata oranÄ± ve yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rma sayÄ±sÄ±nÄ± Ã§iziyoruz
plt.plot(range(1, 130), hata, label="Hata OranÄ±", color="red")
plt.plot(range(1, 130), yanlÄ±s_secim, label="YanlÄ±ÅŸ SeÃ§im SayÄ±sÄ±", color="blue")

# GÃ¶rselleÅŸtirmeyi aÃ§Ä±klayalÄ±m
plt.xlabel('AÄŸaÃ§ SayÄ±sÄ± (n_estimators)')
plt.ylabel('DeÄŸerler')
plt.title('AÄŸaÃ§ SayÄ±sÄ±na GÃ¶re Performans DeÄŸiÅŸimi')
plt.legend()

# Confusion Matrix ile son deÄŸerlendirmeyi yapÄ±yoruz
ConfusionMatrixDisplay.from_estimator(rand_forest_class, X_test, y_test)

# SÄ±nÄ±flandÄ±rma raporunu yazdÄ±rÄ±yoruz
print(classification_report(y_test, pirinc_pred))


ğŸŒ³ğŸ“‰ AÄŸaÃ§ SayÄ±sÄ±nÄ±n Performansa Etkisi ğŸŒ³ğŸ“‰
1ï¸âƒ£ Model PerformansÄ±nÄ± Ä°zleme:

Hata oranÄ± (hata) ve yanlÄ±ÅŸ seÃ§im sayÄ±sÄ± (yanlÄ±s_secim), her bir aÄŸaÃ§ sayÄ±sÄ± iÃ§in modelin baÅŸarÄ±sÄ±nÄ± izlememize yardÄ±mcÄ± olur.
AÄŸaÃ§ sayÄ±sÄ± arttÄ±kÃ§a, hata oranÄ± ve yanlÄ±ÅŸ seÃ§im sayÄ±sÄ± nasÄ±l deÄŸiÅŸiyor?

2ï¸âƒ£ Grafikler:
plt.plot(...) fonksiyonu ile aÄŸaÃ§ sayÄ±sÄ±na gÃ¶re hata oranÄ± ve yanlÄ±ÅŸ seÃ§im sayÄ±sÄ±nÄ± Ã§iziyoruz.
X ekseni: AÄŸaÃ§ sayÄ±sÄ± (1'den 130'a kadar)
Y ekseni: Hata oranÄ± ve yanlÄ±ÅŸ seÃ§im sayÄ±sÄ±.

3ï¸âƒ£ Confusion Matrix:
Confusion Matrix, modelin doÄŸru ve yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rmalarÄ±nÄ± gÃ¶rsel olarak sunar. Bu, modelin ne kadar doÄŸru tahmin yaptÄ±ÄŸÄ±nÄ± hÄ±zlÄ±ca anlamanÄ±zÄ± saÄŸlar.

4ï¸âƒ£ SÄ±nÄ±flandÄ±rma Raporu:
Precision, Recall, F1-Score ve Accuracy gibi metrikler, modelin genel baÅŸarÄ±sÄ±nÄ± gÃ¶sterir.

SonuÃ§lar:
AÄŸaÃ§ sayÄ±sÄ± arttÄ±kÃ§a hata oranÄ± ve yanlÄ±ÅŸ seÃ§im sayÄ±sÄ± nasÄ±l deÄŸiÅŸiyor, bu modelin doÄŸru aÄŸaÃ§ sayÄ±sÄ±nÄ± bulmaya yardÄ±mcÄ± olur.
Hata oranÄ±ndaki azalma ve yanlÄ±ÅŸ seÃ§im sayÄ±sÄ±ndaki dÃ¼ÅŸÃ¼ÅŸ, modelin genel doÄŸruluÄŸunun arttÄ±ÄŸÄ±nÄ± gÃ¶sterir.
Confusion Matrix ile her sÄ±nÄ±fÄ±n doÄŸru ve yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rmalarÄ±nÄ± inceleyebilirsiniz.












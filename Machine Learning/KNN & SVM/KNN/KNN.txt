					ğŸ” KNN (K-Nearest Neighbors) AlgoritmasÄ± Nedir? ğŸ”

KNN, gÃ¶zetimli Ã¶ÄŸrenme (supervised learning) yÃ¶ntemlerinden biridir ve sÄ±nÄ±flandÄ±rma ğŸ·ï¸ ve regresyon ğŸ“ˆ iÃ§in kullanÄ±lÄ±r.

âš¡ KNNâ€™in Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ± âš¡

1ï¸âƒ£ Veri NoktasÄ±na En YakÄ±n K KomÅŸuyu Bulur ğŸ”
2ï¸âƒ£ KomÅŸularÄ±n Etiketlerine GÃ¶re Karar Verir ğŸ¤
3ï¸âƒ£ SÄ±nÄ±flandÄ±rma iÃ§in En Ã‡ok Olan SÄ±nÄ±fÄ± SeÃ§er âœ…
4ï¸âƒ£ Regresyon iÃ§in Ortalama veya AÄŸÄ±rlÄ±klÄ± Ortalama AlÄ±r ğŸ“Š
 
ğŸ”¥ KNN'in AvantajlarÄ± ğŸ”¥

âœ” Kolay UygulanÄ±r ğŸ› ï¸
âœ” Parametrik Olmayan Bir YÃ¶ntemdir (Veri daÄŸÄ±lÄ±mÄ± varsayÄ±mÄ± gerekmez) ğŸ”„
âœ” Yeni verilerle kolay gÃ¼ncellenir â³

âš  KNN'in DezavantajlarÄ± âš 

âŒ BÃ¼yÃ¼k Veri Setlerinde YavaÅŸ Ã‡alÄ±ÅŸabilir ğŸ¢
âŒ Ã–zellik sayÄ±sÄ± arttÄ±kÃ§a performansÄ± dÃ¼ÅŸebilir ğŸ“‰
âŒ Ã–lÃ§eklendirme gerektirir (Ã¶rneÄŸin Min-Max Scaling veya StandartlaÅŸtÄ±rma) âš–ï¸

ğŸ¤” DiÄŸer Algoritmalardan FarkÄ±ğŸ¤”

ğŸ”¹ Karar AÄŸaÃ§larÄ± ğŸŒ³ â†’ BÃ¶lme temellidir, hiyerarÅŸik kararlar alÄ±r
ğŸ”¹ Random Forest ğŸŒ²ğŸŒ²ğŸŒ² â†’ Birden fazla karar aÄŸacÄ±nÄ±n birleÅŸimi, daha gÃ¼Ã§lÃ¼
ğŸ”¹ Gradient Boost ğŸš€ â†’ Hata azaltma odaklÄ±, aÄŸÄ±rlÄ±klÄ± Ã¶ÄŸrenme yapar
ğŸ”¹ SVM ğŸ“ â†’ En iyi ayrÄ±m Ã§izgisini (hiper dÃ¼zlemi) bulmaya Ã§alÄ±ÅŸÄ±r

ğŸ¯ KNN Ne Zaman KullanÄ±lÄ±r? ğŸ¯

âœ… KÃ¼Ã§Ã¼k veri setlerinde ğŸ“Š
âœ… Ã‡izgisel olmayan problemlerde ğŸŒ€
âœ… Etiketli veriler mevcut olduÄŸunda ğŸ·ï¸

KNN genellikle basit ama gÃ¼Ã§lÃ¼ bir algoritmadÄ±r, ancak veri boyutu bÃ¼yÃ¼dÃ¼kÃ§e daha verimli algoritmalara yÃ¶nelmek gerekir! ğŸš€ğŸ’¡

					ğŸš€ğŸ’¡ ADIMLAR ğŸš€ğŸ’¡

1ï¸âƒ£ Veri HazÄ±rlama ğŸ—‚ï¸ğŸ”
2ï¸âƒ£ KeÅŸifÃ§i Veri Analizi (EDA) ğŸ”ğŸ“‰
3ï¸âƒ£ Train-Test Split Ä°ÅŸlemi ğŸ“‚ğŸ”€
4ï¸âƒ£ Veri Ã–lÃ§ekleme ğŸ“ğŸ“Š
5ï¸âƒ£ Model OluÅŸturma ve EÄŸitme ğŸ—ï¸ğŸ¯
6ï¸âƒ£ Model DeÄŸerlendirme âœ…ğŸ“Š
7ï¸âƒ£ Parametre Ayarlama ğŸ›ï¸ğŸ”„
8ï¸âƒ£ Train-Test-Validation AyrÄ±mÄ± ğŸ“‚ğŸ“‘ğŸ”
9ï¸âƒ£ Cross Validation (Ã‡apraz DoÄŸrulama) ğŸ”„ğŸ“Š


					1ï¸âƒ£ Veri HazÄ±rlama ğŸ—‚ï¸ğŸ”

DiÄŸer eÄŸitim bÃ¶lÃ¼mlerinde anlattÄ±ÄŸÄ±mÄ±z veri hazÄ±rlama iÅŸlemleriyle aynÄ±larÄ±nÄ± yaptÄ±k.Tek fark aÅŸaÄŸÄ±da bulunan kod bloÄŸudur.

df.duplicated() Ne Ä°ÅŸe Yarar?

Bu komut, veri Ã§erÃ§evesindeki (DataFrame) duplikat (tekrarlanan) satÄ±rlarÄ±n sayÄ±sÄ±nÄ± bulur.

AdÄ±m adÄ±m:

df.duplicated()

Bu fonksiyon, veri Ã§erÃ§evesindeki her satÄ±rÄ±n diÄŸer satÄ±rlara gÃ¶re tekrarlanÄ±p tekrarlanmadÄ±ÄŸÄ±nÄ± kontrol eder.

True: EÄŸer o satÄ±r daha Ã¶nce gÃ¶rÃ¼ldÃ¼ (yani duplikat).
False: EÄŸer o satÄ±r benzersiz (tekrarÄ± yok).

				2ï¸âƒ£ KeÅŸifÃ§i Veri Analizi (EDA) ğŸ”ğŸ“‰

1. `df.iloc[:20].style.background_gradient(cmap="viridis") ğŸŒˆ

AÃ§Ä±klama: Bu komut, veri Ã§erÃ§evesinin ilk 20 satÄ±rÄ±nÄ± alÄ±r ve arka planÄ±nÄ± viridis renk paletiyle renklendirir.
Jinja2 hatasÄ±: Bu hatayÄ± daha Ã¶nce tartÄ±ÅŸtÄ±k. Jinja2 eksik olduÄŸunda bu tarz stil ayarlarÄ± Ã§alÄ±ÅŸmaz.

pip install jinja2 ile yÃ¼klenebilir.

**2. sns.heatmap(df.corr(numeric_only=True), annot=True) ğŸ”¥

AÃ§Ä±klama: Bu komut, veri Ã§erÃ§evesindeki sayÄ±sal sÃ¼tunlarÄ±n korelasyon matrisini gÃ¶rselleÅŸtirir.

df.corr(numeric_only=True): SayÄ±sal sÃ¼tunlar arasÄ±ndaki korelasyonu hesaplar. Korelasyon, iki deÄŸiÅŸken arasÄ±ndaki iliÅŸkiyi Ã¶lÃ§er (0 ile 1 arasÄ±nda).
annot=True: HÃ¼crelerin Ã¼zerine korelasyon deÄŸerlerini yazdÄ±rÄ±r.

Bu Ä±sÄ± haritasÄ±, deÄŸiÅŸkenler arasÄ±ndaki iliÅŸkinin gÃ¼cÃ¼nÃ¼ ve yÃ¶nÃ¼nÃ¼ (pozitif/negatif) renklerle gÃ¶rselleÅŸtirir.

**3. sns.countplot(x="Purchased", data=df, palette="Purples") ğŸ“Š

AÃ§Ä±klama: Bu komut, "Purchased" (satÄ±n alÄ±ndÄ± mÄ±?) deÄŸiÅŸkeninin deÄŸerlerinin daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶steren bir sÃ¼tun grafiÄŸi (count plot) oluÅŸturur.

x="Purchased": X ekseninde "Purchased" sÃ¼tununu kullanÄ±r.
palette="Purples": Grafikteki renk paletini mor tonlarÄ±nda ayarlar.

Bu grafik, "Purchased" (alÄ±ndÄ± mÄ±?) kolonundaki her bir sÄ±nÄ±fÄ±n (evet/hayÄ±r) kaÃ§ kere olduÄŸunu gÃ¶sterir.

**4. df[["Gender", "Purchased"]].value_counts() ğŸ‘©â€ğŸ¦±ğŸ‘¨â€ğŸ¦²

AÃ§Ä±klama: Bu komut, "Gender" ve "Purchased" sÃ¼tunlarÄ±nÄ±n farklÄ± kombinasyonlarÄ±nÄ± ve her bir kombinasyonun sayÄ±sÄ±nÄ± gÃ¶sterir.

Cinsiyet 1 ve almadÄ±ysa (130): Cinsiyeti 1 (muhtemelen kadÄ±n) olan ve satÄ±n almayan 130 kiÅŸi.
Cinsiyet 0 ve almadÄ±ysa (127): Cinsiyeti 0 (muhtemelen erkek) olan ve satÄ±n almayan 127 kiÅŸi.
Cinsiyet 0 ve aldÄ±ysa (77): Cinsiyeti 0 (erkek) olan ve satÄ±n alan 77 kiÅŸi.
Cinsiyet 1 ve aldÄ±ysa (66): Cinsiyeti 1 (kadÄ±n) olan ve satÄ±n alan 66 kiÅŸi.

Bu, cinsiyet ve satÄ±n alma iliÅŸkisini anlamanÄ±zÄ± saÄŸlar.

**5. sns.countplot(x="Gender", data=df, hue="Purchased") ğŸ‘©â€ğŸ¦±ğŸ‘¨â€ğŸ¦²

AÃ§Ä±klama: Bu komut, "Gender" (cinsiyet) deÄŸiÅŸkenini kullanarak cinsiyet ve satÄ±n alma arasÄ±ndaki iliÅŸkiyi gÃ¶rselleÅŸtirir.

hue="Purchased": SatÄ±n alÄ±nÄ±p alÄ±nmadÄ±ÄŸÄ±na gÃ¶re cinsiyetin daÄŸÄ±lÄ±mÄ±nÄ± renkli bir ÅŸekilde gÃ¶sterir.
Bu grafik, kadÄ±n ve erkeklerin satÄ±n alÄ±p almadÄ±klarÄ±nÄ± daha net gÃ¶rselleÅŸtirir.

**6. sns.pairplot(df, hue="Purchased") ğŸ”€

AÃ§Ä±klama: Bu komut, veri Ã§erÃ§evesindeki tÃ¼m sayÄ±sal sÃ¼tunlar arasÄ±nda ikili grafikler oluÅŸturur ve "Purchased" sÃ¼tununu renklerle gÃ¶sterir.

hue="Purchased": SatÄ±n alÄ±nÄ±p alÄ±nmadÄ±ÄŸÄ±na gÃ¶re renk kodlamasÄ± yapar.
Pairplot, her bir Ã¶zelliÄŸin diÄŸerleriyle olan iliÅŸkisini anlamak iÃ§in faydalÄ±dÄ±r ve bu durumda, satÄ±n alma ile Ã¶zellikler arasÄ±ndaki iliÅŸkileri analiz etmek iÃ§in kullanÄ±lÄ±r.

**7. sns.scatterplot(x="Age", y="EstimatedSalary", data=df, hue="Purchased") ğŸ’µ

AÃ§Ä±klama: Bu komut, YaÅŸ (Age) ve Tahmin Edilen MaaÅŸ (EstimatedSalary) arasÄ±ndaki iliÅŸkiyi daÄŸÄ±lÄ±m grafiÄŸi (scatter plot) olarak gÃ¶rselleÅŸtirir.
hue="Purchased": SatÄ±n alÄ±nÄ±p alÄ±nmadÄ±ÄŸÄ±na gÃ¶re farklÄ± renklerle gÃ¶sterir.

Bu grafik, yaÅŸ ve maaÅŸ ile satÄ±n alma arasÄ±ndaki iliÅŸkiyi gÃ¶rsel olarak analiz eder. Ã–rneÄŸin, satÄ±n alan ve almayan kiÅŸilerin yaÅŸ ve maaÅŸ daÄŸÄ±lÄ±mlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rabilirsiniz.

Ã–zet:

Heatmap ğŸ”¥: KorelasyonlarÄ± gÃ¶rselleÅŸtirir.
Countplot ğŸ“Š: Kategorik verilerin daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶sterir.
Pairplot ğŸ”€: Verinin tÃ¼m sayÄ±sal sÃ¼tunlarÄ± arasÄ±ndaki iliÅŸkileri analiz eder.
Scatterplot ğŸ’µ: Ä°ki deÄŸiÅŸken arasÄ±ndaki iliÅŸkiyi noktalarla gÃ¶sterir.
Her biri, farklÄ± gÃ¶rselleÅŸtirme teknikleri kullanarak veriyi anlamamÄ±za yardÄ±mcÄ± olur.


				3ï¸âƒ£ Train-Test Split Ä°ÅŸlemi ğŸ“‚ğŸ”€

AÃ§Ä±klama: Modelin eÄŸitim ve test sÃ¼reÃ§lerinde kullanÄ±lacak verilerin ayrÄ±lmasÄ± iÃ§in train-test split iÅŸlemi yapÄ±lÄ±r. Bu iÅŸlem, veriyi eÄŸitim verisi ve test verisi olarak ikiye ayÄ±rÄ±r. BÃ¶ylece model, eÄŸitim verisi Ã¼zerinde Ã¶ÄŸrenirken, test verisi ile doÄŸrulanabilir.

x = df.drop("Purchased", axis=1):

Bu komut, "Purchased" sÃ¼tununu veri Ã§erÃ§evesinden Ã§Ä±karÄ±r ve geri kalan Ã¶zellikleri baÄŸÄ±msÄ±z deÄŸiÅŸkenler (X) olarak alÄ±r.

y = df["Purchased"]:

Bu komut, "Purchased" sÃ¼tununu hedef deÄŸiÅŸken (baÄŸÄ±mlÄ± deÄŸiÅŸken) olarak belirler, yani modelin tahmin etmeye Ã§alÄ±ÅŸacaÄŸÄ± etiket.

from sklearn.model_selection import train_test_split:

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=9):

ğŸ“Š SonuÃ§: Bu iÅŸlem, eÄŸitim verisini (X_train ve y_train) modelin Ã¶ÄŸrenmesi iÃ§in, test verisini ise (X_test ve y_test) modelin doÄŸruluÄŸunu deÄŸerlendirmek iÃ§in ayÄ±rÄ±r. Bu sayede modelin genelleme kabiliyeti test edilir.

				4ï¸âƒ£ Veri Ã–lÃ§ekleme ğŸ“ğŸ“Š

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_test = scaler.transform(X_test)

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(scaled_X_train,y_train)
pred= knn.predict(scaled_X_test)

AÃ§Ä±klama: K-Nearest Neighbors (KNN), sÄ±nÄ±flandÄ±rma ve regresyon problemlerinde kullanÄ±lan basit ama etkili bir algoritmadÄ±r. Bu algoritma, verilerin benzerliklerine gÃ¶re sÄ±nÄ±flandÄ±rma yapar. Yani, her veri noktasÄ±nÄ±, etrafÄ±ndaki en yakÄ±n K komÅŸusuyla sÄ±nÄ±flandÄ±rÄ±r.

from sklearn.neighbors import KNeighborsClassifier:

KNN algoritmasÄ±nÄ± kullanabilmek iÃ§in KNeighborsClassifier'Ä± iÃ§eri aktarÄ±rÄ±z.
knn = KNeighborsClassifier(n_neighbors=3):

KNN modelini baÅŸlatÄ±yoruz. Burada n_neighbors=3 demek, her veri noktasÄ±nÄ±n 3 en yakÄ±n komÅŸusuna bakÄ±larak sÄ±nÄ±flandÄ±rma yapÄ±lacaÄŸÄ± anlamÄ±na gelir.

ğŸ¯ Modeli EÄŸitme ve Tahmin Yapma ğŸ¯

knn.fit(scaled_X_train, y_train):

EÄŸitim verisi ile model eÄŸitilir. Burada scaled_X_train Ã¶zellikler (girdi verisi), y_train ise hedef deÄŸiÅŸken (etiket) verisidir. Model, bu verilerle sÄ±nÄ±flandÄ±rmayÄ± Ã¶ÄŸrenir.
pred = knn.predict(scaled_X_test):

Test verisi Ã¼zerindeki tahminler yapÄ±lÄ±r. scaled_X_test test verisi, model tarafÄ±ndan sÄ±nÄ±flandÄ±rÄ±lÄ±r ve tahmin sonuÃ§larÄ± pred deÄŸiÅŸkenine atanÄ±r.

ğŸ“Š SonuÃ§: Bu iÅŸlem, verilerin Ã¶lÃ§eklendirilmesini ve ardÄ±ndan KNN algoritmasÄ±yla eÄŸitim verilerek test verisi Ã¼zerinde tahmin yapÄ±lmasÄ±nÄ± saÄŸlar. SonuÃ§ta, modelin doÄŸruluÄŸu test edilebilir ve KNN'nin sÄ±nÄ±flandÄ±rma baÅŸarÄ±sÄ± Ã¶lÃ§Ã¼lebilir.

				5ï¸âƒ£ Model DeÄŸerlendirme âœ…ğŸ“Š


AÃ§Ä±klama: Modeli eÄŸittikten sonra, modelin ne kadar iyi performans gÃ¶sterdiÄŸini anlamak iÃ§in deÄŸerlendirme yapmamÄ±z gerekir. Bu iÅŸlemde, modelin doÄŸruluÄŸunu ve tahminlerinin doÄŸru olup olmadÄ±ÄŸÄ±nÄ± kontrol ederiz. Genellikle hata oranÄ±, doÄŸruluk oranÄ± ve konfÃ¼zyon matrisi gibi metrikler kullanÄ±lÄ±r.

KonfÃ¼zyon Matrisi (Confusion Matrix) ğŸ”„

AÃ§Ä±klama: KonfÃ¼zyon matrisi, modelin doÄŸruluÄŸunu deÄŸerlendirmede yaygÄ±n olarak kullanÄ±lÄ±r. Bu matris, doÄŸru ve yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rÄ±lan Ã¶rnekleri gÃ¶steren bir tabloyu ifade eder. Bunu gÃ¶rselleÅŸtirebiliriz.

ConfusionMatrixDisplay.from_estimator(knn, scaled_X_test, y_test):

Bu komut, modelin test verisi Ã¼zerindeki tahminlerini kullanarak bir konfÃ¼zyon matrisi oluÅŸturur ve bunu gÃ¶rselleÅŸtirir.

Burada knn modelimiz, scaled_X_test test verisi ve y_test gerÃ§ek etiketlerle tahminlerde bulunur.

ğŸ“ SÄ±nÄ±flandÄ±rma Raporu (Classification Report) ğŸ“

AÃ§Ä±klama: SÄ±nÄ±flandÄ±rma raporu, modelin performansÄ±nÄ± daha ayrÄ±ntÄ±lÄ± bir ÅŸekilde sunar. Precision, Recall, F1-Score gibi metrikler iÃ§erir.

print(classification_report(y_test, pred)):

Bu komut, modelin tahminleri (pred) ve gerÃ§ek deÄŸerler (y_test) arasÄ±ndaki farklarÄ± deÄŸerlendirir. Rapor, her sÄ±nÄ±f iÃ§in metrikler saÄŸlar.


				âš ï¸Hata OranÄ± Hesaplama (Error Rate) âš ï¸

hata_oranÄ±=[]
for k in range(1,40):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(scaled_X_train,y_train)
    knn_pred = knn.predict(scaled_X_test)

    err =(1-accuracy_score(y_test , knn_pred))
    hata_oranÄ±.append(err)

ğŸ“Š GÃ¶rselleÅŸtirme; ğŸ“Š

plt.figure(figsize=(10,6),dpi=200)
plt.plot(range(1,40),hata_oranÄ±,color="purple", linestyle="dashed" ,
 marker="s" , markerfacecolor="yellow",label='Test Error')
plt.legend()
plt.ylabel('Hata OranÄ±')
plt.xlabel("K DeÄŸeri")


âœ… Hata OranÄ± Hesaplama (Error Rate) AdÄ±mlarÄ±: âœ…

-- hata_oranÄ±=[]:
Hata oranlarÄ±nÄ± saklamak iÃ§in boÅŸ bir liste oluÅŸturuluyor.

-- for k in range(1, 40):
Bu dÃ¶ngÃ¼, K deÄŸerlerini 1 ile 39 arasÄ±nda test etmek iÃ§in Ã§alÄ±ÅŸÄ±r. Bu, KNN algoritmasÄ±nda komÅŸu sayÄ±sÄ±nÄ±n etkisini gÃ¶rmeyi saÄŸlar.

-- knn = KNeighborsClassifier(n_neighbors=k):
Her K deÄŸeri iÃ§in bir KNeighborsClassifier modeli oluÅŸturulur.

-- knn.fit(scaled_X_train, y_train):
Model, eÄŸitim verisi (scaled_X_train ve y_train) Ã¼zerinde eÄŸitilir.

-- knn_pred = knn.predict(scaled_X_test):
EÄŸitilen model, test verisi Ã¼zerinde tahminler yapar.

-- err = (1 - accuracy_score(y_test, knn_pred)):
Test verisi Ã¼zerinde yapÄ±lan tahminin doÄŸruluÄŸu hesaplanÄ±r. Hata oranÄ±, 1 eksi doÄŸruluk oranÄ± olarak bulunur.

-- hata_oranÄ±.append(err):
Hesaplanan hata oranÄ±, hata_oranÄ± listesine eklenir.

ğŸ“‰ Hata OranÄ± GrafiÄŸi ğŸ“‰:

-- plt.figure(figsize=(10,6), dpi=200):
Grafik boyutlarÄ± ayarlanÄ±r ve Ã§Ã¶zÃ¼nÃ¼rlÃ¼k yÃ¼ksek tutulur.

--plt.plot(range(1, 40), hata_oranÄ±, color="purple", linestyle="dashed", marker="s", markerfacecolor="yellow", label='Test Error'):

K deÄŸerlerine karÅŸÄ±lÄ±k gelen hata oranlarÄ±, mor renkte ve kesik Ã§izgi ile Ã§izilir. Veriler, her K deÄŸeri iÃ§in nokta iÅŸaretÃ§ileriyle gÃ¶sterilir.

-- plt.legend():
Grafikteki etiketler gÃ¶sterilir.

-- plt.ylabel('Hata OranÄ±'):
Y ekseni etiketini belirler (Hata oranÄ±).

-- plt.xlabel("K DeÄŸeri"):
X ekseni etiketini belirler (K deÄŸeri).

Bu grafik, KNN modelinin K deÄŸeriyle hata oranÄ±nÄ±n nasÄ±l deÄŸiÅŸtiÄŸini gÃ¶sterir. Hata oranÄ± en dÃ¼ÅŸÃ¼k olan K deÄŸeri, modelin en iyi performansÄ± gÃ¶sterdiÄŸi deÄŸerdir.


Ã–zet:
Bu kod parÃ§asÄ±, KNN modelinin K deÄŸeri ile hata oranÄ±nÄ± gÃ¶rselleÅŸtirir.
Grafikte en iyi K deÄŸeri (en dÃ¼ÅŸÃ¼k hata oranÄ±) belirlenebilir.


-- ğŸ—ï¸  Ortaya Ã‡Ä±kan bu deÄŸerler sonucunda final modelini oluÅŸturarak deÄŸerlendirme yapabiliriz ğŸ—ï¸--

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(scaled_X_train , y_train)
pred_knn =knn.predict(scaled_X_test)

ConfusionMatrixDisplay.from_estimator(knn , scaled_X_test , pred_knn )
print(classification_report(y_test , pred_knn))

* En iyi deÄŸeri 5 olarak yazdÄ±ÄŸÄ±mÄ±zda deÄŸerler bu ÅŸekilde Ã§Ä±kÄ±yor


				ğŸ“ğŸ”§ Neden StandardScaler KullandÄ±k? ğŸ“ğŸ”§


1ï¸âƒ£ Veri Ã–lÃ§eklendirme:
KNN, mesafe hesaplamalarÄ± yaptÄ±ÄŸÄ± iÃ§in farklÄ± Ã¶zellikler arasÄ±nda bÃ¼yÃ¼k Ã¶lÃ§ek farklarÄ± varsa, bÃ¼yÃ¼k deÄŸere sahip Ã¶zellikler mesafe hesaplamasÄ±nda daha fazla aÄŸÄ±rlÄ±k taÅŸÄ±r. StandardScaler, verilerin ortalama (mean) deÄŸerini 0 ve standart sapmasÄ±nÄ± 1 yaparak, tÃ¼m Ã¶zelliklerin aynÄ± Ã¶lÃ§ekte olmasÄ±nÄ± saÄŸlar.
2ï¸âƒ£ Mesafe HesaplamalarÄ± Ä°Ã§in Ä°deal:
KNN, Euclidean distance gibi mesafeleri kullanarak tahmin yapar. StandardScaler, verilerin doÄŸru mesafelerde hesaplanmasÄ±nÄ± saÄŸlar. FarklÄ± Ã¶lÃ§eklerdeki veriler, mesafe hesaplamalarÄ±nÄ± yanÄ±ltabilir.
3ï¸âƒ£ Veri Ã‡eÅŸitliliÄŸi ve DuyarlÄ±lÄ±k:
KNN ve benzeri algoritmalar, verilerin aynÄ± Ã¶lÃ§eklerde olmasÄ±na duyarlÄ±dÄ±r. StandardScaler, verilerin daÄŸÄ±lÄ±mÄ±nÄ± deÄŸiÅŸtirmeden sadece Ã¶lÃ§eklerini normalize eder, bÃ¶ylece modelin performansÄ± artar.
SonuÃ§:
StandardScaler, KNN gibi algoritmalarÄ±n doÄŸru Ã§alÄ±ÅŸmasÄ± ve en iyi sonuÃ§larÄ± vermesi iÃ§in verilerin aynÄ± Ã¶lÃ§ekte olmasÄ±nÄ± saÄŸlar.


				ğŸ¤”ğŸ”¢ Get Dummies Neden KullanÄ±lmadÄ±? ğŸ¤”ğŸ”¢

1ï¸âƒ£ SayÄ±sal Verilerle Ã‡alÄ±ÅŸÄ±yoruz:

Get Dummies genellikle kategorik verileri sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±lÄ±r. Yani, "cinsiyet", "ÅŸehir", "Ã¼rÃ¼n kategorisi" gibi kategorik sÃ¼tunlarÄ± 0 ve 1'lere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
Ancak burada kullandÄ±ÄŸÄ±mÄ±z veri, sayÄ±sal Ã¶zelliklerden oluÅŸuyor (Ã¶rneÄŸin, yaÅŸ, maaÅŸ gibi). Bu nedenle Get Dummies'e gerek yoktur, Ã§Ã¼nkÃ¼ sayÄ±sal veriler zaten modelin Ã§alÄ±ÅŸabilmesi iÃ§in uygun formattadÄ±r.

2ï¸âƒ£ Ã–zellikler Zaten SayÄ±sal:

Veri Ã§erÃ§evesinde, "Purchased" gibi kategorik deÄŸiÅŸkenler var ancak bu deÄŸiÅŸken zaten hedef deÄŸiÅŸken (y) olarak ayrÄ±ldÄ±ÄŸÄ± iÃ§in sayÄ±sal veriler Ã¼zerinde iÅŸlem yapÄ±yoruz. Get Dummies'e ihtiyacÄ±mÄ±z yok Ã§Ã¼nkÃ¼ biz ÅŸu an sayÄ±sal Ã¶zelliklerle (X) ilgileniyoruz.

3ï¸âƒ£ Modelde Kategorik Veriler Yok:

EÄŸer veri setinde "Gender", "City" gibi kategorik deÄŸiÅŸkenler olsaydÄ±, Get Dummies ile bunlarÄ± sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rmemiz gerekebilirdi. Ancak ÅŸu an elimizde kategorik Ã¶zellikler olmadÄ±ÄŸÄ±ndan, bu adÄ±mÄ± atlayabiliyoruz.

Ã–zet:
Get Dummies sadece kategorik verilerle Ã§alÄ±ÅŸÄ±rken gereklidir. SayÄ±sal veriler Ã¼zerinde StandardScaler gibi tekniklerle devam edilebilir. Bu sebeple burada Get Dummies kullanÄ±lmadÄ±.










